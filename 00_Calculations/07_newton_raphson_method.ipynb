{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>\n",
    "\n",
    "# Алгоритм Ньютона-Рафсона\n",
    "\n",
    "### Modules - Root Finding\n",
    "<section class=\"post-meta\">\n",
    "By Magnus A. Gjennestad, Vegard Hagen, Aksel Kvaal, Morten Vassvik, Trygve B. Wiig and Peter Berg\n",
    "</section>\n",
    "Last edited: March 11th 2018 \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Вопрос:__\n",
    "\n",
    "Существует ли более эффективный (более быстрый) метод поиска корня $x_0$ функции $f(x)$, отличный от алгоритма деления пополам?\n",
    "\n",
    "__Пример 1:__\n",
    "\n",
    "Опять же, мы хотели бы знать, где функция $g(x) = x$ пересекает функцию $h(x) = e^{−x}$ (см. Модуль по алгоритму деления пополам). И опять же, нам нужно решить\n",
    "$$x = e^{-x}.$$\n",
    "Это эквивалентно поиску корня $x_0$ функции $f(x) = e^{−x} − x = 0$:\n",
    "$$f(x_0)=e^{−x_0} −x_0 =0.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set common figure parameters\n",
    "newparams = {'figure.figsize': (16, 6), 'axes.grid': True,\n",
    "             'lines.linewidth': 1.5, 'lines.linewidth': 2,\n",
    "             'font.size': 14}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы строим график $f$, мы видим, что он должен иметь один уникальный корень около $x = 0,6$, как показано на графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 2, 100)\n",
    "def f(x): return np.exp(-x)-x\n",
    "\n",
    "plt.plot(x, f(x))\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "#plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем найти этот корень (кроме как с помощью метода деления пополам)?\n",
    "\n",
    "Идея состоит в том , чтобы начать с предположения $x_1$ и соответствующей точки на графике $(x_1, f(x_1))$. Давайте выберем $x_1 = -0,5$. Затем мы \"следуем\" за линией, касательной к графику в этой точке, пока не достигнем оси x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "def f(x): return np.exp(-x)-x\n",
    "\n",
    "x1 = -0.5\n",
    "dfdx_x1 = -np.exp(-x1)-1  # Производная от f(x) в точке x1\n",
    "x2 = x1-f(x1)/dfdx_x1     # Ноль касательной\n",
    "\n",
    "# Plot function\n",
    "plt.plot(x, f(x))\n",
    "\n",
    "# Plot lines:\n",
    "plt.plot([x1,x1], [f(x1),0], 'r')\n",
    "plt.plot([x1,x2], [0, 0], 'r')\n",
    "plt.plot([x1,x2], [f(x1),0], 'r')\n",
    "plt.plot([x2,x2], [f(x2),0], 'g')\n",
    "\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.text(-0.2, -0.5, r'$\\Delta x$')\n",
    "plt.text(-0.7, 1, r'$f(x_1)$')\n",
    "plt.text(x1, 2.5, r'$1$')\n",
    "plt.text(x2, 0.5, r'$2$')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересечение касательной линии и оси $x$дает нам новую оценку корня, $x_2$. Как мы видим, теперь мы действительно ближе к настоящему корню.\n",
    "\n",
    "Мы можем повторить эту процедуру, т.е. следовать по касательной к $x_2$ линии, пока снова не достигнем оси $x$. Это дает наше следующее предположение $x_3$ и так далее.\n",
    "\n",
    "Из предыдущего графика мы видим, что разница $\\Delta x$ (где $\\Delta x = x_\\mathrm{next} − x_\\mathrm{cur})$ между текущей догадкой, $x_\\mathrm{cur}$, и следующей догадкой, $x_\\mathrm{next}$, связана с наклоном касательной линии, $f'(x_\\mathrm{cur})$, через (обратите внимание на знак минус)\n",
    "$$f′(x_\\mathrm{cur}) = −\\frac{f(x_\\mathrm{cur})}{\\Delta x}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это дает\n",
    "$$x_\\mathrm{next} =x_\\mathrm{cur} +\\Delta x = x_\\mathrm{cur} − \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})}.$$\n",
    "Эта процедура называется __Алгоритм Ньютона-Рафсона__ (также называемый [метод Ньютона](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%9D%D1%8C%D1%8E%D1%82%D0%BE%D0%BD%D0%B0)) и может быть сформулирована следующим образом:\n",
    "1. Предположение значения $x_\\mathrm{cur}$ корня функции $f(x)$. Иногда построение графика помогает угадать значение (см. Выше).\n",
    "2. Если существует более одного корня, попробовать выбрать значение, близкое к интересующему корню.\n",
    "3. Установить $x_\\mathrm{next} = x_\\mathrm{cur} − \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})}$ в качестве следующей оценки корня.\n",
    "4. Задать $x_\\mathrm{cur} = x_\\mathrm{next}$.\n",
    "5. Повторять шаги 3 и 4 до тех пор, пока не будет достигнута требуемая точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность может зависить от двух явлений:\n",
    "1. Когда алгоритм сходится, $\\Delta x$ в конечном счете уменьшается с каждой итерацией. Вопрос в следующем: при каком значении $\\Delta x$ мы должны остановить нашу итерационную процедуру?\n",
    "2. Насколько близко $f(x_\\mathrm{cur})$ к нулю?\n",
    "\n",
    "Примечание: В каждом случае мы не можем быть уверены, насколько мы действительно близки к фактическому корню $x_0$. Это во многом связано с поведением функции $f$ вблизи $x_0$.\n",
    "- В случае 1 $\\Delta x$ в принципе может снова увеличиться во время следующей итерации.\n",
    "- В случае 2 величина $f(x_\\mathrm{cur})$ в принципе может снова увеличиться на следующей итерации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если корень лежит в области, где $f(x)$ почти линейна, алгоритм будет сходиться быстро, намного быстрее, чем алгоритм деления пополам.\n",
    "\n",
    "Однако, как правило, нет никакой гарантии, что алгоритм сходится. При применении алгоритма Ньютона-Рафсона часто возникают два явления. Давайте обсудим их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проблема № 1:__\n",
    "Производная $f'(x_\\mathrm{cur})$ иногда может становиться очень маленькой, делая $\\Delta x = − \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})}$ очень большим. Это имеет место вблизи локальных минимумов и максимумов или в точке (горизонтального)\n",
    "перегиба.\n",
    "\n",
    "Следующая догадка $x_\\mathrm{next}$ находится далеко от фактического корня. Компьютерный код может остановиться из-за слишком больших по своей природе чисел. Либо $x_\\mathrm{next}$ может попасть в область другого корня, что явно помешает нахождению интересующего значения.\n",
    "В этом случае первоначальное предположение должно быть изменено. Или мы можем ограничить размер шага $\\Delta x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проблема № 2:__\n",
    "Алгоритм не сходится и не расходится. Скорее, он остается в непосредственной близости от корня, колеблясь в бесконечном цикле вокруг фактического корня, не приближаясь к нему.\n",
    "\n",
    "Опять же, первоначальное предположение должно быть изменено. Или нам нужно еще уменьшить размер шага (релаксацию): мы можем заменить $\\Delta x$ на $\\gamma \\Delta x$, где $0 < \\gamma < 1$.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда может быть полезно сначала использовать более медленный, но надежный метод деления пополам, чтобы приблизиться достаточно близко к фактическому корню, чтобы обеспечить хорошее начальное предположение для более быстрого метода Ньютона-Рафсона. Последний же обеспечивает лучшую конвергенцию.\n",
    "\n",
    "Еще один полезный трюк - аппроксимировать производную $f′(x_\\mathrm{cur})$ как \n",
    "$$f′(x_\\mathrm{cur}) \\approx \\frac{f(x_\\mathrm{cur} + \\delta x)−f(x_\\mathrm{cur})}{\\delta x}$$\n",
    "для некоторого небольшого значения $\\delta x$. Это удобно, когда производная не может быть легко вычислена в аналитической форме и требуется численная оценка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Пример 2:__\n",
    "\n",
    "Мы хотим решить уравнение\n",
    "$$ 2 - x^4 = \\tanh(x)$$\n",
    "для $x > 0$. Следовательно, нам нужно решить\n",
    "$$f(x) = 2 - x^4 - \\tanh(x).$$\n",
    "Наш алгоритм \n",
    "$$\n",
    "\\begin{align}\n",
    "x_\\mathrm{next} = x_\\mathrm{cur} - \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})} = \\frac{2-x_\\mathrm{cur}^4-\\tanh(x_\\mathrm{cur})}{-4 x_\\mathrm{cur}^3-\\frac{1}{\\cosh(x_\\mathrm{cur})^2}}.\n",
    "\\end{align}\n",
    "$$\n",
    "Построение графика $f(x)$ помогает нам сделать первоначальное предположение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1.5, 100)\n",
    "def f(x): return 2 - x**4 - np.tanh(x)\n",
    "\n",
    "plt.plot(x, f(x))\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "#plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы выбираем $x_\\mathrm{cur} = x_1 = 1.0$.\n",
    "\n",
    "Теперь мы находим следующие последовательные оценки для корня на протяжении первых 5 итераций (до 12 значащих цифр):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "x_cur = 1.0\n",
    "print(x_cur)\n",
    "\n",
    "for i in range(N):\n",
    "    x_cur = x_cur-(2-x_cur**4-np.tanh(x_cur))/(-4*x_cur**3-1/(np.cosh(x_cur))**2)\n",
    "    print(x_cur)\n",
    "    \n",
    "print(r'Значение на последней итерации, f(x_cur) = %s' % f(x_cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в этом случае достаточно 5 итераций!\n",
    "Алгоритму деления пополам потребуется гораздо больше итераций для той же точности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение $f(x)$ для нашей окончательной оценки корня равно\n",
    "$$f(1.05053505396) =  -2.22044604925 \\times 10^{-16}.$$\n",
    "Очень хорошая оценка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__\n",
    "Метод Ньютона может быть распространен на более высокие измерения, т.е. иметь $k$ переменных и $k$ функций, корни которых нам нужно найти одновременно. Это особенно актуально для численных решений дифференциальных уравнений. Однако эти тонкости метода Ньютона не будут рассмотриваться в этом модуле."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
