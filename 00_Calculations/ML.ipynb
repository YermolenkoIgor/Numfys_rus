{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть с нуля\n",
    "### Modules - Modern\n",
    "<section class=\"post-meta\">\n",
    "By Sondre Duna Lundemo, Jenny Lunde, Niels Henrik Aase, Thorvald M. Ballestad, Jon Andreas Støvneng and Brynjulf Owren.\n",
    "</section>\n",
    "\n",
    "Last edited: March 1st, 2021\n",
    "\n",
    "---\n",
    "\n",
    "Этот блокнот даст представление о том, как строится полносвязанная нейронная сеть и как работают различные компоненты. По всей записной книжке будут представлены фрагменты кода для каждого компонента в сети, чтобы легче увидеть связь между уравнениями и реализациями. Ближе к концу все компоненты будут собраны в классы, чтобы сделать код более функциональным и аккуратным. Задача основана на отрывке из курса TMA4320 - Введение в научные вычисления в НТНУ.\n",
    "\n",
    "#### Замечание:\n",
    "Если вы не знакомы с объектно-ориентированным программированием, не паникуйте! То, как классы используются в этой записной книжке, будет легко понято кем-то с небольшим опытом программирования; вы можете думать о том, что это практический способ сбора определенных переменных вместе с функциями, которые вы используете для управления ими. Если вы хотите узнать больше, вы можете, например, прочитать больше <a href=\"https://docs.python.org/3/tutorial/classes.html\">здесь</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наброски задачи\n",
    "\n",
    "Использование нейронных сетей оказало большое влияние на проблемы, связанные с искусственным интеллектом. Общий характер метода позволяет ему превосходно выполнять самые разнообразные задачи, начиная от полезных приложений, таких как распознавание изображений и самоуправляемые автомобили, и заканчивая менее полезными приложениями, например, в видеоиграх (*Очень спорно*). Еще одним важным примером использования нейронных сетей является решение задач классификации. Такого рода проблемы также возникают в физических науках, поэтому использование нейронных сетей в некоторых случаях может также дать представление об этих областях, понимание, которое недоступно, если ограничиться обычными методами, используемыми в численном анализе. В будущем блокноте мы рассмотрим такую проблему, используя обширное оборудование, предоставляемое в различных пакетах Python для машинного обучения. Однако в данном случае мы будем реализовывать алгоритмы с нуля, чтобы получить представление о механике нейронной сети. \n",
    "\n",
    "Хотя проблема не обязательно должна заключаться в классификации изображений, чтобы сделать работу сети менее абстрактной, мы часто будем ссылаться на входные данные сети как на _image_. Мы представляем, что каждый пиксель изображения имеет скалярное значение, скажем, представляющее значение в оттенках серого. Чтобы избежать использования матриц в качестве представления входных данных, мы складываем строки изображения друг на друга, чтобы создать входной вектор, размеры которого обязательно будут произведением количества пикселей в каждом направлении изображения. В случае двоичной классификации метка, связанная с каждым изображением, равна либо $0$, либо $1$, и она представляет какую-то категорию. Если, например, проблема заключалась в том, чтобы определить, изображен ли на изображении волк или хаски, мы могли бы выбрать обозначение $0$ для категории волка, и $1$ , для категории хаски."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Что такое искусственная нейронная сеть?\n",
    "\n",
    "Искусственная нейронная сеть (artificial neural network - ANN) - это набор функций, которые объединяются для имитации биологической нейронной сети [[1]](#Biological_net). Точно так же, как биологическая нейронная сеть, ANN состоит из множества нейронов, соединенных вместе, образуя сложную сеть. В ANN нейроны структурированы слоями. Первый называется входным слоем, последний слой называется выходным слоем, и между ними есть несколько скрытых слоев$^1$. Количество скрытых слоев, также известное как глубина сети, будет варьироваться в зависимости от сложности проблемы, которую вы хотите решить с помощью сети. Каждый слой содержит нейроны, и количество нейронов варьируется от сети к сети, а также может варьироваться от слоя к слою в данной сети. \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/fully_connected.PNG\" alt=\"Fully Connected Neural Network\" style=\"width: 500px;\">\n",
    "    <i>Этот рисунок представляет собой визуализацию сети, сделанной в этом блокноте. Сеть полностью подключена, и количество нейронов одинаково для всех слоев, кроме выходного слоя.</i>\n",
    "    <img src=\"images/not_fully_connected.PNG\" alt=\"Not fully Connected Neural Network\" style=\"width: 500px;\">\n",
    "    <i>На этом рисунке показана более общая нейронная сеть. Сеть не полностью подключена, и количество нейронов варьируется от слоя к слою.</i>\n",
    "</center>\n",
    "\n",
    "В этом блокноте мы рассмотрим ANN, в которой число нейронов в каждом слое постоянно. Более конкретно, сеть, которую мы будем использовать, называется ResNet и впервые была упомянута в <a href = \"https://arxiv.org/abs/1512.03385\"> статье </a> Каймина Хэ, Сянъю Чжана, Шаоцина Жэнь и Цзянь Суна. Для простоты число нейронов будет равно размеру входных данных. Мы также ограничим наше внимание полностью связанными нейронными сетями, то есть любой нейрон сети связан со всеми нейронами в следующем слое. Эти упрощения сделаны только для того, чтобы упростить общую структуру для реализации и понимания, но важно подчеркнуть, что выбор более сложных структур может повысить производительность в реальных приложениях. Для таких целей использование хорошо документированных и надежных пакетов Python, таких как PyTorch или TensorFlow, несомненно, проще и лучше, чем пытаться реализовать алгоритмы самостоятельно.\n",
    "\n",
    "Хотя полносвязная сеть намного проще в реализации, она является более дорогостоящей в вычислительном отношении, чем сеть, которая не полностью связана. Еще одним преимуществом выбора более сложной структуры является то, что она позволяет по-разному обрабатывать подмножества данных. Таким образом, можно в некотором смысле вывести сеть на правильный путь. Кроме того, более сложные структуры допускают более сложные и нелинейные связи между нейронами.\n",
    "\n",
    "## Обозначения\n",
    "В этом блокноте будет введено множество переменных. Вот их обзор. \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        K = & \\texttt{ num_layers} && \\text{ Количество слоев.} \\\\\n",
    "        I = & \\texttt{ num_images} && \\text{ Количество изображений.}  \\\\\n",
    "        d = & \\texttt{ dimension} && \\text{ Размерность входных данных.} \\\\\n",
    "        Y = & \\texttt{ Y} && \\text{ Все выходные значения, } y \\text{, в матрице размера [num layes + 1, num neurons]. } Y[0] \\text{ входной слой} \\\\ \n",
    "        W = & \\texttt{ weight} &&\\text{ Все веса, } w \\text{, в матрице размера [num layers, num neurons, num neurons].} \\\\\n",
    "        B = & \\texttt{ bias_vec} &&\\text{ Все смещения, } b \\text{, в матрице размера [num layers, num neurons].} \\\\\n",
    "        \\mu = & \\texttt{ mu}  &&\\text{ Переменная, соответствующая смещению в выходном слое.}\\\\\n",
    "        \\omega = & \\texttt{ omega}  &&\\text{ Переменная, соответствующая весу в выходном слое.}\\\\\n",
    "        h = & \\texttt{ steplength}  &&\\text{ Длина шага.} \\\\\n",
    "        Z_i = & \\texttt{ Z}  &&\\text{ Вывод с последнего слоя, \"догадка\" сети.} \\\\\n",
    "        c_i = & \\texttt{ c}  &&\\text{ Правильное значение для вывода.}\\\\\n",
    "        \\mathcal{J} = & \\texttt{ cost_function}  &&\\text{ Ошибка сети.}\\\\\n",
    "        U = & \\texttt{ U}  &&\\text{ Коллекция всех переменных} W \\text{, } b\\text{, } \\omega \\text{ и } \\mu \\text{.}\\\\\n",
    "        \\sigma = & \\texttt{ sigma}  &&\\text{ Сигмовидная функция, обычно используется в качестве функции активации.} \\\\\n",
    "        \\eta = & \\texttt{ eta}  &&\\text{ Функция проекции для выходного слоя.} \\\\\n",
    "        \\sigma ' = & \\texttt{ sigma_derivative}  &&\\text{ Производная функции активации.} \\\\\n",
    "        \\eta ' = & \\texttt{ eta_derivative}  &&\\text{ Производная от проекционной функции.} \\\\\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Поскольку то, что мы в конечном итоге получаем, по сути, представляет собой набор множества переменных, которыми мы хотим манипулировать различными способами и в определенных порядках, удобно собирать их в классе. В этом блокноте мы создали три класса, которые мы будем называть $\\texttt{Network}$, $\\texttt{Param}$ и $\\texttt{Gradient_descent}$, и содержание классов будет объяснено по пути. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Как работает слой в Сети?\n",
    "\n",
    "Далее $k$ будет обозначать индекс произвольного слоя, $n$ - произвольный индекс нейрона и $i$ - произвольный индекс входных векторов в сеть. $K$ обозначает общее количество слоев, а $N$ - общее количество узлов в каждом слое.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/layer_in_nn_2.PNG\" alt=\"A layer in the network\" style=\"width: 250px;\">\n",
    "    <i>На этом рисунке показано, как предыдущий слой является входным для узла в текущем слое. Переменная $k$ является номером текущего слоя и соответствует надстрочному индексу $y$. Индекс $y$ равен $n$, что говорит нам, какому нейрону в слое $y_n$ соответствует элемент.\n",
    "    </i>\n",
    "</center>\n",
    "\n",
    "Каждый слой принимает на вход результат работы предыдущего слоя, за исключением первого слоя, который принимает вход в сеть. В полносвязном слое каждый нейрон принимает выходные данные от каждого нейрона в предыдущем слое в качестве входных данных. В нейроне каждый вход умножается на индивидуальный вес, а затем все они суммируются. Смещение добавляется к сумме, а затем результаты передаются через функцию активации, прежде чем они будут отправлены в качестве выходных данных на следующий слой вместе с выходными данными от каждого другого нейрона в том же слое. Почему нейрон так устроен? Как уже упоминалось в начале, ANN создается для имитации биологической нейронной сети, и в биологической нейронной сети различные стимулы \"возбуждают\" разные нейроны, и сигнал передается определенным нейронам. В ANN выходное значение нейрона может быть интерпретировано так, как если бы он был \"активирован\" или нет. Значения, близкие к 1, означают \"активацию\", в то время как значения, близкие к 0, представляют неактивный нейрон$^2$. Обозначая входы в первый слой $y^{(0)}_n$, веса каждого входа в нейрон, a в первом слое $w_{0,n}^{(0)}$, смещение $b_0^{(0)}$ и функцию активации $f$, выход нейрона $1$ будет равен \n",
    "\n",
    "$$\n",
    "y^{(1)}_0 = y^{(0)}_0 + h f\\big( w_{0,0}^{(0)} y^{(0)}_0 + w_{0,1}^{(0)} y^{(0)}_1 + w_{0,2}^{(0)} y^{(0)}_2 + \\dots + w_{0,N-1}^{(0)} y^{(0)}_{N-1} + b_0^{(0)} \\big) \\text{.}\n",
    "$$ \n",
    "\n",
    "$h$ - длина шага и представляет собой число от 0 до 1. Это комбинация выходного значения каждого нейрона в предыдущем слое и их соответствующих весов, которые влияют на сумму в текущем нейроне. Смещение может подтолкнуть значение вверх или вниз, чтобы эффективно создать порог для активации. После преобразования входных данных через скрытые слои они передаются через функцию активации, которая проецирует выходные данные на скаляр между 0 и 1 в случае двоичной классификации. Одним из примеров функции активации является сигмовидная функция: \n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}.\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Чтобы упростить нотацию и вычисления, матрицы и векторы используются для компактного сбора весов и смещений. Пусть входными данными первого слоя являются вектор $y^{(0)}$, $W^{(0)}$ - матрица с весами в первом слое и $b^{(0)}$ - смещения в первом слое. $W$ состоит из векторов с весами от каждого нейрона в слое. Выходные данные первого слоя затем отображаются в матричных обозначениях\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        \\begin{bmatrix}\n",
    "        y^{(1)}_0\\\\\n",
    "        y^{(1)}_1\\\\\n",
    "        \\vdots \\\\\n",
    "        y^{(1)}_{N-1}\\\\\n",
    "        \\end{bmatrix} =\n",
    "        \\begin{bmatrix}\n",
    "        y^{(0)}_0\\\\\n",
    "        y^{(0)}_1\\\\\n",
    "        \\vdots \\\\\n",
    "        y^{(0)}_{N-1}\\\\\n",
    "        \\end{bmatrix}\n",
    "        +\n",
    "        h \\sigma \\left(\n",
    "        \\begin{bmatrix}\n",
    "        w^{(0)}_{0,0} & w^{(0)}_{0,1} & \\dots & w^{(0)}_{0,N-1} \\\\\n",
    "        w^{(0)}_{1,0} & w^{(0)}_{1,1} & \\dots & w^{(0)}_{1,N-1} \\\\\n",
    "        &\\vdots \\\\ \n",
    "        w^{(0)}_{N-1,0} & w^{(0)}_{N-1,1} & \\dots & w^{(0)}_{N-1,N-1} \\\\\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        y^{(0)}_0\\\\\n",
    "        y^{(0)}_1\\\\\n",
    "        \\vdots \\\\\n",
    "        y^{(0)}_{N-1}\\\\\n",
    "        \\end{bmatrix}\n",
    "        +\n",
    "        \\begin{bmatrix}\n",
    "        b^{(0)}_0\\\\\n",
    "        b^{(0)}_1\\\\\n",
    "        \\vdots \\\\\n",
    "        b^{(0)}_{N-1}\\\\\n",
    "        \\end{bmatrix}\n",
    "        \\right)\n",
    "        \\text{,}\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "$$\n",
    "или написано более компактно\n",
    "\n",
    "$$\n",
    "y^{(1)} = y^{(0)} + h \\sigma \\left(W^{(0)}y^{(0)} + b^{(0)}\\right) \\text{,}\n",
    "$$\n",
    "\n",
    "где сигмоидная функция$^3$, $\\sigma$, применяется поэлементно. В полносвязной нейронной сети каждый нейрон в одном слое соединен с каждым нейроном в следующем слое, и приведенное выше матричное уравнение дает выход каждого скрытого слоя в сети. Для вычислительных целей удобно отправлять каждый входной вектор через преобразование одновременно. В нашей нотации это равносильно \n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{Y}_{k} = \\mathbf{Y}_{k-1} + h \\sigma \\left( W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1}\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Функции активации\n",
    "Функции активации - это то, что отличает нейронную сеть от линейной регрессии. Без обработки выходных данных каждого слоя с помощью нелинейной функции активации всегда можно было бы создать один слой, равный сумме любого другого набора слоев того же размера, и глубина сети была бы незначительной. С помощью функций активации сеть может устанавливать нелинейные соединения между входом и выходом. Другой аспект функции активации заключается в том, что становится более ясно, активен или неактивен нейрон. Можно было бы подумать, что лучшим способом показать это будет двоичная функция активации, которая выводит 1, если она активна, и 0, но тогда градиент функции будет плохо определен. Станет ясно, что это очень прискорбно, когда мы обсудим тренировку сети, где градиент функции активации играет решающую роль. Существует множество вариантов функций активации, некоторые из наиболее известных: сигмоидная функция, гиперболический тангенс и функция ReLU.\n",
    "\n",
    "### Сигмоида\n",
    "Сигмовидная функция является хорошо известной функцией активации, и она принимает значения от 0 до 1. Это непрерывная функция, которая упрощает вычисления градиента. Одним из недостатков этой функции является то, что называется \"исчезающими градиентами\". то есть, когда абсолютное значение входных данных принимает большое значение, градиент сигмоидной функции становится очень маленьким. Как мы увидим позже, градиент функции активации является важной частью обучения сети, и исчезающие градиенты заставят сеть учиться очень медленно [[2]](#activation_functions). Эта функция также может использоваться в выходном слое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages:\n",
    "import pickle  # Сериализация объектов Python.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns  # Библиотека статистической графики.\n",
    "from IPython.display import Image\n",
    "from matplotlib import rc\n",
    "from tqdm import tqdm  # Модные измерители прогресса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common plotting parameters\n",
    "fontsize = 22\n",
    "newparams = {\n",
    "    \"axes.titlesize\": fontsize,\n",
    "    \"axes.labelsize\": fontsize,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"lines.markersize\": 7,\n",
    "    \"figure.figsize\": (13, 7),\n",
    "    \"ytick.labelsize\": fontsize,\n",
    "    \"xtick.labelsize\": fontsize,\n",
    "    \"legend.fontsize\": fontsize,\n",
    "    \"legend.handlelength\": 1.5,\n",
    "    \"figure.titlesize\": fontsize,\n",
    "    \"figure.dpi\": 400,\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x)/(np.exp(x) + 1)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return 1/np.square(np.exp(x/2)+np.exp(-x/2))\n",
    "\n",
    "x = np.linspace(-10,10,200)\n",
    "plt.plot(x, sigmoid(x),label=r\"$\\sigma (x) = \\frac{\\exp{x}}{\\exp{x} +1}$\")\n",
    "plt.plot(x, sigmoid_derivative(x),label=r\"$\\sigma '(x) = \\left(\\frac{1}{ \\exp{\\left(\\frac{x}{2}\\right)} + \\exp{\\left(-\\frac{x}{2}\\right)}}\\right)^2$\")\n",
    "plt.title(\"Sigmoid function\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гибридный тангенс\n",
    "\n",
    "Форма гиперболического тангенса аналогична сигмоидной функции, но она принимает значения от $-1$ до $1$. Согласно [[3]](#ann_training), центрирование значений вокруг 0 облегчит обучение сети, и это часто дает лучшие результаты, чем сигмоидальная функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(2*x)-1)/(np.exp(2*x)+1)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 4/np.square(np.exp(x)+np.exp(-x))\n",
    "\n",
    "x = np.linspace(-10,10,200)\n",
    "plt.plot(x, tanh(x),label=r\"$\\eta (x) = \\tanh{x}$\")\n",
    "plt.plot(x, tanh_derivative(x),label=r\"$\\eta '(x) = \\frac{1}{\\cosh^2{x}}$\")\n",
    "plt.title(\"Hyperbolic tangent\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "ReLU - это сокращение от выпрямленной линейной единицы и она менее затратна в вычислительном отношении, чем сигмоидные и гиперболические касательные функции. Она возвращает 0, если входное значение отрицательное, и само значение, если входное значение положительное. Эта функция не имеет верхнего предела для выходных значений, но она четко показывает, когда нейрон неактивен. Существуют версии ReLU, в которых не все отрицательные значения становятся нулевыми, например, дырявый ReLU, который имеет небольшой линейный наклон на отрицательной стороне. Для некоторых проблем полезно выводить ноль для отрицательных значений, потому что это ясно показывает, что нейрон неактивен, но некоторые нейроны могут в конечном итоге выводить только 0, и нейрон не вносит свой вклад в сеть[[4]](#ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def leakyReLU(x, a):\n",
    "    return np.maximum(x*a, x)\n",
    "\n",
    "def ReLU_derivative(x):\n",
    "    return np.heaviside(x,0)\n",
    "\n",
    "def leakyReLU_derivative(x, a):\n",
    "    return a + np.heaviside(x,0) * (1-a)\n",
    "\n",
    "x = np.linspace(-10,10,200)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].plot(x, ReLU(x), label = \"ReLU\")\n",
    "axs[0].plot(x, ReLU_derivative(x), label = \"Derivative of ReLU\", ls = \"-\")\n",
    "axs[1].plot(x, leakyReLU(x,0.1), label = \"leaky ReLU\")\n",
    "axs[1].plot(x, leakyReLU_derivative(x, 0.1), label = \"Derivative of leaky ReLU\", ls = \"-\")\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[0].set_title('ReLU')\n",
    "axs[1].set_title('Leaky ReLU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выходной слой\n",
    "\n",
    "Наиболее важной частью выходного слоя является уменьшение размера входных данных. В этом блокноте задача представляет собой задачу двоичной классификации, а желаемый результат - число от 0 до 1. Для других типов задач выход может быть, например, вектором или действительными числами. В то время как большая часть сети может оставаться неизменной для других проблем, важно адаптировать выходной уровень, чтобы получить желаемые размеры и значения. Типичным выходным слоем является \n",
    "\n",
    "$$\n",
    "Z = \\eta (\\mathbf{Y}_K^T \\omega + \\mu \\mathbf{1}).\n",
    "$$\n",
    "\n",
    "Здесь $\\omega$ является вектором и выполняет ту же работу, что и веса в скрытом слое. $\\mu$ является одномерным вектором (т. е. скаляром) и выполняет работу смещения, а $\\mathbf{1}$ обозначает вектор той же размерности, что и $\\omega$, содержащий только единицы. $\\eta$ - это функция масштабирования. Для целей двоичной классификации $\\eta$ обычно выводит десятичное число от 0 до 1, а сигмоидная функция является одной из многих функций, которые можно использовать. Если желательно вывести вектор, $\\omega$ будет матрицей, $\\mu$ будет вектором, а $\\eta$ будет работать поэлементно. Вывод $Z$ является предположением сети и реализуется следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод, принадлежащий сетевому классу.\n",
    "# self = Network\n",
    "# U = Параметр, принадлежащий классу Param\n",
    "\n",
    "def projection(self):\n",
    "    self.Z = self.eta(Y[-1].T@self.U.omega + self.U.mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения нейронной сети это значение сравнивается с истинным значением, обозначаемым $c$, для расчета ошибки сети. То есть насколько далека была догадка. При запуске все параметры по существу свободны, поэтому мы ожидаем, что предположение будет близким к случайному. Чтобы улучшить догадку, идея состоит в том, чтобы изменить веса, смещения, $\\omega$ и $\\mu$ таким образом, чтобы минимизировать ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как обучается сеть?\n",
    "\n",
    "Если сеть уже обучена, она может принять решение, \"съев\" входные данные, обработав их через скрытые слои и, в конечном счете, через выходной слой, из которого она принимает решение. Прежде чем это станет возможным, сеть должна быть обучена. Обучение нейронной сети означает, что каждый вес и смещение настраиваются на проблему, которую вы хотите решить, чтобы сделать решения как можно более точными. Это делается в основном в два этапа: прямое распространение и обратное распространение.\n",
    "\n",
    "### Прямое распространение\n",
    "\n",
    "При прямом распространении мы отправляем входные данные и позволяем сети сделать предположение. В начале обучения эти предположения будут в основном случайными, так как веса и смещения не адаптированы к набору данных. Предположение делается путем простой отправки входных данных через все слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод, принадлежащий сетевому классу.\n",
    "# self = Network\n",
    "# U = Параметр, принадлежащий классу Param\n",
    "\n",
    "def forward_prop(self):\n",
    "    for i in range(self.num_layers):\n",
    "        self.Y[i+1,:,:] = self.steplength*self.sigma(self.U.weight[i,:,:]@self.Y[i,:,:] + self.U.bias_vec[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обратное распространение\n",
    "\n",
    "Когда предположение было сделано, ошибка между предположением и истинным значением измеряется с помощью функции затрат. Целью следующего шага будет использование информации об ошибке для улучшения последующих догадок. Нормальный выбор для функции затрат, $\\mathcal{J}$, - это квадратное отклонение догадок и истинных значений\n",
    "\n",
    "$$\n",
    "\\mathcal{J} = \\frac{1}{2} \\sum_{i=1}^{I} \\vert Z_i - c_i \\vert^2 = \\frac{1}{2} \\| \\mathbf{Z} - \\mathbf{c} \\|^2.\n",
    "$$\n",
    "\n",
    "Когда речь идет о входных данных $\\mathbf{Y}_k$, как указано, функция ошибок является просто функцией параметров сети. Для простоты мы собираем все параметры в одну переменную под названием $\\mathbf{U} = [(W_k, b_k)_{k=0}^{K-1},\\omega,\\mu]$. Мы хотим найти значения параметров $\\mathbf{U}$, которые минимизируют $\\mathcal{J}$. Поскольку $\\mathcal{J}$ быстрее всего уменьшается локально в направлении $-\\nabla J (\\mathbf{U})$, мы обновляем наши параметры в соответствии с алгоритмом градиентного спуска, где одним из простейших алгоритмов является итерация \n",
    "\n",
    "$$\n",
    "\\mathbf{U}^{(j+1)} = \\mathbf{U}^{(j)} - \\tau \\nabla J (\\mathbf{U}^{(j)}) \\text{,}\n",
    "$$\n",
    "\n",
    "где $\\tau$ известен как параметр обучения. При обратном распространении вычисляется градиент функции затрат по отношению ко всем переменным и используется для обновления весов, чтобы минимизировать стоимость сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method belonging to network\n",
    "# self = Network\n",
    "\n",
    "def calculate_cost(self):\n",
    "    self.cost = 1/2*np.sum(np.square(self.Z-self.c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет градиентов\n",
    "\n",
    "Чтобы найти параметры, которые минимизируют стоимость $\\mathcal{J}$, мы используем итерационную схему, включающую локальный градиент стоимости $\\nabla \\mathcal{J}(\\mathbf{U}^{(j)})$. Далее мы выведем простейшие компоненты градиента и обратимся к приложению для вывода более сложных. Возможно, самым простым является тот, который относится к скалярному $\\mu$, используемому в выходном слое.\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{\\partial \\mathcal{J}}{\\partial \\mu} = \\sum_{i=1}^{I} \\frac{\\partial \\mathcal{J}}{\\partial Z_i} \\frac{\\partial Z_i}{\\partial \\mu} &= \\sum_{i=1}^{I} [\\eta'(\\mathbf{Y}_K^T \\omega + \\mu \\mathbf{1})]_i (Z_i-c_i) \\\\ &= \\eta'(\\mathbf{Y}_K^T \\omega + \\mu \\mathbf{1})^T (\\mathbf{Z}- \\mathbf{c}).\n",
    "\\end{align}\n",
    "\n",
    "Вычисление градиента относительно $\\mu$ выполняется следующим образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method belonging to Parameters\n",
    "# self = Param\n",
    "\n",
    "def gradient_mu(self,network):\n",
    "    first_factor = network.eta_derivative(network.Y[self.num_layers,:,:].T @ self.omega + self.mu * network.one).T\n",
    "    second_factor = network.Z - network.c\n",
    "\n",
    "    return first_factor @ second_factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично получим\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{\\partial \\mathcal{J}}{\\partial \\omega} &= \\sum_{i=1}^{I}  \\frac{\\partial \\mathcal{J}}{\\partial Z_i} \\frac{\\partial Z_i}{\\partial \\omega} = \\sum_{i=1}^{I} \\sum_{j=1}^{d} (Z_i - c_i) [ \\eta'(\\mathbf{Y}_K^T \\omega + \\mu \\mathbf{1})]_i \\mathbf{Y}^T_{K,ij} \\\\\n",
    "    &= \\mathbf{Y}_K^T \\left( \\left( \\mathbf{Z} - \\mathbf{c} \\right) \\odot \\eta'(\\mathbf{Y}_K^T \\omega + \\mu \\mathbf{1}) \\right),\n",
    "\\end{align}\n",
    "\n",
    "где мы ввели произведение Адамара (поэлементное) $\\odot$, определяемое $(A \\odot B)_{ij} = A_{ij} \\cdot B_{ij}$. В numpy мы можем вычислить произведение Адамара двух массивов, $\\texttt{X}$ и $\\texttt{Y}$ (с одинаковой формой), используя `np.multiply(X,Y)` или просто `X * Y`, где обычное умножение матрицы выполняется с помощью оператора `@` или `np.dot(,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method belonging to Parameters\n",
    "# self = Param\n",
    "\n",
    "def gradient_omega(self,network):\n",
    "    \n",
    "    first_factor = network.Y[self.num_layers,:,:]\n",
    "    second_factor = np.multiply((network.Z - network.c),network.eta_derivative(first_factor.T @ self.omega + self.mu * self.one))\n",
    "\n",
    "    return first_factor @ second_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление градиента по отношению к смещению и весам немного запутаннее, поэтому мы представляем результаты только здесь и приводим подробности в приложении. Оказывается полезным вычислить градиент по отношению к $\\mathbf{Y}_k$, чтобы получить эти градиенты. Мы обозначим $\\mathbf{P}$ и представим следующие тождества, соединяющие $\\mathbf{P}$ последнего слоя с предыдущими. \n",
    "\n",
    "\\begin{equation}\\label{eq:P_K}\n",
    "\\mathbf{P}_K = \\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_K} = \\omega \\otimes \\left[(\\mathbf{Z} - \\mathbf{c}) \\odot \\eta'\\left( \\mathbf{Y}_{K} ^{T} \\omega + \\mu \\mathbf{1}\\right) \\right]^T \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\\label{eq:P_k-1}\n",
    "\\mathbf{P}_{k-1} = \\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_{k-1}} = \\mathbf{P}_{k} + h W_{k-1}^{T} \\cdot \\left[ \\sigma' \\left(W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1} \\right) \\odot \\mathbf{P}_{k}\\right] \n",
    "\\end{equation}\n",
    "\n",
    "Здесь $\\otimes$ обозначает внешнее произведение. Используя их, мы можем выразить градиент по отношению к весам и смещениям следующим образом \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{J}}{\\partial W_k} = h \\left( \\mathbf{P}_{k+1} \\odot \\sigma' \\left( W_k \\mathbf{Y}_k + b_k \\right) \\right) \\cdot \\mathbf{Y}_{k}^{T},\n",
    "\\end{equation}\n",
    "\n",
    "и  \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{J}}{\\partial b_k} = h \\left( \\mathbf{P}_{k+1} \\odot \\sigma' \\left( W_k \\mathbf{Y}_k + b_k \\right) \\right) \\cdot \\mathbf{1}.\n",
    "\\end{equation}\n",
    "\n",
    "Обратите внимание, что для их вычисления требуется сначала вычислить $\\mathbf{P}_K$ на основе $\\mathbf{Y}_K$, который получается прямым распространением. После этого можно вычислить $\\mathbf{P}_{k}$ для $k<K$, и все компоненты $\\mathbf{P}$ необходимы для вычисления градиентов относительно всех весов и смещений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method belonging to Parameters\n",
    "# self = Param\n",
    "\n",
    "def calculate_P_K(self,network):\n",
    "\n",
    "    first_factor  = network.Z - network.c\n",
    "    second_factor = network.eta_derivative((network.Y[self.num_layers,:,:]).T @ self.omega + self.mu * network.one) \n",
    "    third_factor = np.multiply(first_factor,second_factor)\n",
    "\n",
    "    self.P[self.num_layers,:,:] =  np.outer(self.omega, third_factor.T)\n",
    "        \n",
    "def calculate_P(self,network):\n",
    "    for k in range(self.num_layers,0,-1):\n",
    "        first_factor  = network.steplength * self.weight[k-1,:,:].T \n",
    "        second_factor = np.multiply(network.sigma_derivative(self.weight[k-1,:,:] @ network.Y[k-1,:,:] + self.bias_vec[k-1]),self.P[k,:,:])\n",
    "\n",
    "        self.P[k-1,:,:]  = self.P[k,:,:] + first_factor @ second_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method belonging to Parameters\n",
    "# self = Param\n",
    "\n",
    "def gradient_weight(self,network,index):\n",
    "\n",
    "    first_factor  = network.steplength * np.multiply(self.P[index+1,:,:],network.sigma_derivative(self.weight[index,:,:] @ network.Y[index,:,:] + self.bias_vec[index]))\n",
    "    second_factor = network.Y[index,:,:].T\n",
    "    \n",
    "    return first_factor @ second_factor \n",
    "\n",
    "def gradient_bias_vec(self,network,index):\n",
    "\n",
    "    first_factor  = network.steplength * np.multiply(self.P[index+1,:,:],network.sigma_derivative(self.weight[index,:,:] @ network.Y[index,:,:] + self.bias_vec[index]))\n",
    "    second_factor  = network.one\n",
    "\n",
    "    return np.reshape(first_factor @ second_factor,(self.dimension,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация параметров\n",
    "\n",
    "При инициализации параметров $\\mathbf{U}$ в сети можно наивно думать, что простой выбор - инициализировать все параметры  нулями с помощью `np.zeros()`, но это не очень хороший вариант. Если все значения весов равны нулю, градиент будет равен единице для всех весов, и градиент не будет меняться для всех весов, и сеть будет работать как линейная модель [[5]](#initialization_of_weights). Существует много способов улучшить модель, инициализируя параметры таким образом, чтобы улучшить обучение, но мы сохраним ее простой и инициализируем параметры с использованием нормального распределения. В следующей ячейке мы создали класс для всех параметров в $\\mathbf{U}$ и их градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param(object):\n",
    "    \"\"\"Параметры нейронной сети.\n",
    "    \n",
    "    Инициализирует параметры случайными числами.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    K : int\n",
    "        number of layers\n",
    "    d : int\n",
    "        dimension of input 'images'\n",
    "    I : int\n",
    "        number of input input 'images'\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    num_layers : int\n",
    "        number of layers in total\n",
    "    dimension  : int\n",
    "        dimension of input 'image'\n",
    "    num_images : int\n",
    "        number of input images \n",
    "        \n",
    "    mu         : float\n",
    "        mu in projection/output layer\n",
    "    omega      : np.array\n",
    "        omega in projection/output layer. shape: dimension x 1\n",
    "    weight     : np.array\n",
    "        weights. shape : num_layers x dimension x dimension\n",
    "    bias_vec   : np.array\n",
    "        bias. shape: num_layers x dimension x num_images   \n",
    "    P          : np.array\n",
    "        P-matrix. shape: num_layers + 1 x dimension x num_images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,K,d,I):\n",
    "        self.num_layers = K\n",
    "        self.dimension  = d\n",
    "        self.num_images = I\n",
    "        \n",
    "        self.mu         =  np.random.normal()\n",
    "        self.omega      =  np.random.randn(self.dimension,1)\n",
    "        self.weight     =  np.random.randn(self.num_layers,self.dimension,self.dimension)\n",
    "        self.bias_vec   =  np.random.randn(self.num_layers,self.dimension,1)\n",
    "        \n",
    "        self.P          =  np.zeros((self.num_layers+1,self.dimension,self.num_images))\n",
    "        \n",
    "    def gradient_mu(self,network):\n",
    "        \"\"\"Вычисляет градиент относительно mu\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "        Returns\n",
    "        -------\n",
    "            _ : float\n",
    "                The gradient with respect to mu\n",
    "        \"\"\"\n",
    "        \n",
    "        first_factor = network.eta_derivative(network.Y[self.num_layers,:,:].T @ self.omega + \n",
    "                                              self.mu * network.one).T\n",
    "        second_factor = network.Z - network.c\n",
    "    \n",
    "        return first_factor @ second_factor \n",
    "    \n",
    "    def gradient_omega(self,network):\n",
    "        \"\"\"Вычисляет градиент по отношению к омеге\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "        Returns\n",
    "        -------\n",
    "            _ : np.array\n",
    "                The gradient with respect to omega\n",
    "        \"\"\"\n",
    "    \n",
    "        first_factor = network.Y[self.num_layers,:,:]\n",
    "        second_factor = np.multiply((network.Z - network.c),\n",
    "                                    network.eta_derivative(first_factor.T @ self.omega + self.mu * network.one)) \n",
    "\n",
    "        return first_factor @ second_factor\n",
    "    \n",
    "    def calculate_P_K(self,network):\n",
    "        \"\"\"Вычисляет P_K\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "        \"\"\"\n",
    "    \n",
    "        first_factor  = network.Z - network.c\n",
    "        second_factor = network.eta_derivative((network.Y[self.num_layers,:,:]).T @ self.omega + \n",
    "                                               self.mu * network.one) \n",
    "        third_factor = np.multiply(first_factor,second_factor)\n",
    "        \n",
    "        self.P[self.num_layers,:,:] = np.outer(self.omega, third_factor.T)\n",
    "        \n",
    "    def calculate_P(self,network):\n",
    "        \"\"\"Вычисляет P \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        for k in range(self.num_layers,0,-1):\n",
    "            first_factor  = network.steplength * self.weight[k-1,:,:].T \n",
    "            second_factor = np.multiply(network.sigma_derivative(self.weight[k-1,:,:] @ network.Y[k-1,:,:] \n",
    "                                                                 + self.bias_vec[k-1]),self.P[k,:,:])\n",
    "\n",
    "            self.P[k-1,:,:]  =  self.P[k,:,:] + first_factor @ second_factor\n",
    "            \n",
    "    def gradient_weight(self,network,index):\n",
    "        \"\"\"Вычисляет градиент по отношению к весу\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "        Returns\n",
    "        -------\n",
    "            _ : np.array\n",
    "                The gradient with respect to the weight\n",
    "        \"\"\"\n",
    "  \n",
    "        first_factor  = network.steplength * np.multiply(self.P[index+1,:,:],\n",
    "                        network.sigma_derivative(self.weight[index,:,:] @ network.Y[index,:,:] +\n",
    "                                                  self.bias_vec[index]))\n",
    "        second_factor = network.Y[index,:,:].T\n",
    "        return first_factor @ second_factor \n",
    "        \n",
    "    def gradient_bias_vec(self,network,index):\n",
    "        \"\"\"Вычисляет градиент по отношению к смещению\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            network : Network\n",
    "                The network of which this instance is a member\n",
    "        Returns\n",
    "        -------\n",
    "            _ : np.array\n",
    "                The gradient with respect to the bias\n",
    "        \"\"\"\n",
    "\n",
    "        first_factor  = network.steplength * np.multiply(self.P[index+1,:,:],\n",
    "                        network.sigma_derivative(self.weight[index,:,:] @ network.Y[index,:,:] +\n",
    "                                                 self.bias_vec[index]))\n",
    "        second_factor  = network.one\n",
    "        \n",
    "        return np.reshape(first_factor @ second_factor,(self.dimension,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм обучения\n",
    "\n",
    "Прежде чем объяснить методы градиентного спуска, мы дадим краткое описание процесса обучения:\n",
    "\n",
    "for $i$ in range(num_iterations): <br>\n",
    "$\\hspace{1cm}$ for $k$ in range($K$): <br>\n",
    "$\\hspace{2cm}$ Вычислить $Y_k$ <br>\n",
    "$\\hspace{1cm}$ Вычислить $P_K$ <br>\n",
    "$\\hspace{1cm}$ Вычислить градиент $\\omega$ и $\\mu$ <br>\n",
    "$\\hspace{1cm}$ for $k$ in range(K-1, 1, -1): <br>\n",
    "$\\hspace{2cm}$ Вычислить $P_{k-1}$ <br>\n",
    "$\\hspace{1cm}$ for $k$ in range(K-1): <br>\n",
    "$\\hspace{2cm}$ Вычислить градиент $W_k$ и $b_k$ <br>\n",
    "$\\hspace{1cm}$ Обновление $\\mathbf{U}$ по методу градиентного спуска <br>\n",
    "\n",
    "В этом блокноте мы решили создать класс для каждого метода градиентного спуска. Чтобы гарантировать, что различные классы для градиентных спусков работают в сети, мы определили три функции, которые должны содержать все классы градиентного спуска. Это `update_first()`, `update_second()` и `update_params()`. `update_first()` вычисляет градиенты $\\mu$ и $\\omega$, `update_second()` вычисляет градиенты $W$ и $b$, а `update_params()` обновляет все значения $U$ в соответствии с методом градиентного спуска. Реализация этих функций будет показана в следующем разделе. Реализация алгоритма обучения показана ниже. Строки кода, за которыми следует \"##\", не способствуют трансированию, но используются для построения графика для проверки сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method beloning to the Network class\n",
    "# self = Network\n",
    "\n",
    "\n",
    "def train(self,h = 0.1,tau = 0.01):\n",
    "\n",
    "    self.cost_per_iter = np.zeros(self.iterations-1)\n",
    "    self.validation_cost_per_iter = np.zeros(self.iterations-1) ##\n",
    "    self.steplength = h\n",
    "    self.tau = tau\n",
    "\n",
    "    for i in tqdm(range(self.iterations)): #tqdm creates a progressbar\n",
    "\n",
    "        self.forward_prop(self.Y)\n",
    "\n",
    "        self.Z = self.projection(self.Y)\n",
    "        self.U.calculate_P_K(self)\n",
    "\n",
    "        self.gradient_descent.update_first(self)\n",
    "        self.U.calculate_P(self)\n",
    "\n",
    "        self.gradient_descent.update_second(self)\n",
    "\n",
    "        self.Z = self.projection(self.Y)\n",
    "\n",
    "        self.gradient_descent.update_params(self,i)\n",
    "\n",
    "        self.Z = self.projection(self.Y)\n",
    "\n",
    "        if i != 0:\n",
    "            self.cost_per_iter[i - 1] = self.cost_function()\n",
    "            pred = self.predict(self.validation_data, integers = False) ##\n",
    "            self.validation_cost_per_iter[i-1] = 1/2*(np.linalg.norm(pred-self.validation_labels))**2 ##\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация\n",
    "\n",
    "Как уже упоминалось, мы хотим найти значения $\\mathbf{U}$, которые минимизируют $\\mathcal{J}$. Есть много способов сделать это, и мы представим два метода: простой градиентный спуск и градиентный спуск Адама.\n",
    "\n",
    "#### Обычная ваниль\n",
    "\n",
    "Простой ванильный градиентный спуск является одним из простейших алгоритмов градиентного спуска и обновляет $\\mathbf{U}$ с итерацией \n",
    "\n",
    "$$\n",
    "\\mathbf{U}^{(j+1)} = \\mathbf{U}^{(j)} - \\tau \\nabla J (\\mathbf{U}^{(j)}) \\text{.}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    \"\"\"Виртуальный класс для методов градиентного спуска для сети. \n",
    "    Все методы градиентного спуска должны иметь эту форму, чтобы быть совместимыми с классом сети\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    network : Network\n",
    "        Сеть, объектом которой является данный экземпляр \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, network):\n",
    "        self.gradient_mu = np.zeros(np.shape(network.U.mu))\n",
    "        self.gradient_omega = np.zeros(np.shape(network.U.omega))\n",
    "        self.gradient_bias_vec = np.zeros(np.shape(network.U.bias_vec))\n",
    "        self.gradient_weight = np.zeros(np.shape(network.U.weight))\n",
    "    \n",
    "    def update_first(self, network):\n",
    "        \"\"\"Обновляет градиенты wrt mu и omega\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Network\n",
    "            Сеть, объектом которой является данный экземпляр \n",
    "        \"\"\"\n",
    "        self.gradient_mu = network.U.gradient_mu(network)\n",
    "        self.gradient_omega = network.U.gradient_omega(network)\n",
    "        \n",
    "    def update_second(self, network):\n",
    "        \"\"\"Обновление градиентов весов wrt и смещений\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Network\n",
    "            Сеть, объектом которой является данный экземпляр \n",
    "        \"\"\"\n",
    "        for k in range(network.num_layers):\n",
    "            self.gradient_weight[k] = network.U.gradient_weight(network, k)\n",
    "            self.gradient_bias_vec[k] = network.U.gradient_bias_vec(network, k)\n",
    "            \n",
    "    def update_params(self, network, j):\n",
    "        \"\"\"Обновляет параметры сети после вычисления градиентов \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Network\n",
    "            Сеть, объектом которой является данный экземпляр \n",
    "        j    : int\n",
    "            iteration of training.\n",
    "            \n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class Plain_vanilla(GradientDescent):\n",
    "    \"\"\"Класс простой ванильный градиентный спуск. \n",
    "    Наследует класс формы GradientDescent\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    network : Network\n",
    "        Сеть, объектом которой является данный экземпляр \n",
    "    tau : float\n",
    "        длина шага, используемая в алгоритме простой ванили\n",
    "    \"\"\"\n",
    "    def __init__(self, network, tau=0.01):\n",
    "        GradientDescent.__init__(self, network)\n",
    "        self.tau = tau    \n",
    "            \n",
    "    def update_params(self, network, j):\n",
    "        \"\"\"Обновляет параметры сети после вычисления градиентов \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Network\n",
    "            Сеть, объектом которой является данный экземпляр \n",
    "        iter    : int\n",
    "            итерация обучения. Здесь это не имеет значения, но важно для адамовского спуска.\n",
    "        \"\"\"\n",
    "        network.U.mu = network.U.mu - self.tau * self.gradient_mu\n",
    "        network.U.omega = network.U.omega - self.tau * self.gradient_omega\n",
    "        network.U.weight = network.U.weight - self.tau * self.gradient_weight    \n",
    "        network.U.bias_vec = network.U.bias_vec - self.tau * self.gradient_bias_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Адамов спуск\n",
    "\n",
    "Алгоритм спуска Адама не так прост, как простой градиентный. Одно из различий между этими двумя алгоритмами заключается в том, что обычная ваниль использует одну и ту же длину шага на протяжении всего процесса обучения, в то время как Адам адаптирует длину шага к градиенту. Мы не будем углубляться в то, как работает Адам, но вы можете прочитать об этом подробнее <a href = \"https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\" target =_blank >здесь</a>.\n",
    "\n",
    "Это алгоритм для метода градиентного спуска Адама:\n",
    "\n",
    "\n",
    "$v_0 = 0$, $m_0 = 0$ <br>\n",
    "for $j = 1$,$2$, $\\dots$ <br>\n",
    "    $\\hspace{1cm} g_j = \\nabla_{\\mathbf{U}} \\mathcal{J}(\\mathbf{U}^{(j)})$ <br>\n",
    "    $\\hspace{1cm} m_j = \\beta_1 m_{j-1} + (1-\\beta_1) g_j$ <br>\n",
    "    $\\hspace{1cm} v_j = \\beta_2 v_{j-1} + (1-\\beta_2)(g_j \\odot g_j)$ <br>\n",
    "    $\\hspace{1cm} \\hat{m}_j = \\frac{m_j}{1-\\beta_1^j}$ <br>\n",
    "    $\\hspace{1cm} \\hat{v}_j = \\frac{v_j}{1-\\beta_2^j}$ <br>\n",
    "    $\\hspace{1cm} \\mathbf{U}^{(j+1)} = \\mathbf{U}^{(j)} - \\alpha \\frac{\\hat{m}_j}{\\sqrt{\\hat{v}_j} + \\epsilon}$\n",
    "\n",
    "\n",
    "где $\\beta_1$, $\\beta_2$, $\\alpha$ и $\\epsilon$ - параметры, которые можно изменить для оптимизации производительности алгоритма.\n",
    "$\\odot$ по-прежнему является произведением Адамара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(GradientDescent):\n",
    "    \"\"\"Класс градиентного спуска Адама. \n",
    "    Наследует класс формы GradientDescent\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    network : Network\n",
    "        Сеть, объектом которой является данный экземпляр \n",
    "    tau : float\n",
    "        длина шага, используемая в алгоритме Adam\n",
    "    \"\"\"\n",
    "    def __init__(self,network,tau = 0.01):\n",
    "        GradientDescent.__init__(self, network)\n",
    "        self.tau = tau\n",
    "        \n",
    "    def update_params(self,network,j):\n",
    "        \"\"\"Обновляет параметры сети после вычисления градиентов \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Network\n",
    "            Сеть, объектом которой является данный экземпляр \n",
    "        j    : int\n",
    "            итерация обучения   \n",
    "        \"\"\" \n",
    "        \n",
    "        beta_1  = 0.9\n",
    "        beta_2  = 0.999\n",
    "        alpha   = self.tau\n",
    "        epsilon = 1e-8\n",
    "\n",
    "        if j == 0:\n",
    "            self.m = 0\n",
    "            self.v = 0\n",
    "        else:\n",
    "            g_j = np.asarray([self.gradient_mu,self.gradient_omega,\n",
    "                              self.gradient_weight,self.gradient_bias_vec], dtype=object)\n",
    "\n",
    "            self.m = beta_1 * self.m + (1-beta_1) * g_j\n",
    "            self.v = beta_2 * self.v + (1-beta_2) * np.multiply(g_j,g_j)\n",
    "\n",
    "            m_hat = self.m /(1-beta_1**j) \n",
    "            v_hat = self.v /(1-beta_2**j)\n",
    "\n",
    "            network.U.mu = network.U.mu - alpha * m_hat[0] /(np.sqrt(v_hat[0]) + epsilon)\n",
    "            network.U.omega = network.U.omega - alpha * m_hat[1] /(np.sqrt(v_hat[1]) + epsilon)\n",
    "            network.U.weight = network.U.weight - alpha * m_hat[2] /(np.sqrt(v_hat[2]) + epsilon)    \n",
    "            network.U.bias_vec = network.U.bias_vec - alpha * m_hat[3] /(np.sqrt(v_hat[3]) + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка сети\n",
    "\n",
    "Прежде чем мы соберем весь класс сети, представим некоторые полезные функции при работе с машинным обучением. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение и загрузка моделей\n",
    "\n",
    "Нейронная сеть, созданная здесь, довольно проста, и она обучается относительно быстро. Для более глубоких сетей, которые применяются к более сложным задачам, обычно требуется больше работать с поиском хороших параметров, например, количества слоев, количества итераций и размера различных слоев. Время, необходимое для обучения модели, также может быть значительно больше, чем для этой сети. Вот некоторые из причин, по которым полезно иметь возможность сохранять и загружать модели во время разработки сети. Когда вы сможете сохранять и загружать свои модели, вам будет легче сравнивать модели, не тренируя их каждый раз. Для удобства мы также включаем методы для этого с помощью простой сети. \n",
    "Мы решили использовать словари Python для сохранения моделей. Таким образом, можно сохранить все функции формы в массивах numpy в одном документе. Мы также сохраняем словарь в двоичном файле с помощью функции `pickle.dump`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Методы, относящиеся к классу сети.\n",
    "# self = Network\n",
    "\n",
    "def save_model(self, filename):\n",
    "    \"\"\"Сохраняет обученную модель. Сохраняет все значения, необходимые для прогнозирования с помощью модели. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        Имя двоичного файла для создания модели.\n",
    "    \"\"\"\n",
    "    # Создание вложенных словарей для структурирования данных\n",
    "    parameters = {}\n",
    "    parameters['weight'] = self.U.weight\n",
    "    parameters['bias_vec'] = self.U.bias_vec\n",
    "    parameters['mu'] = self.U.mu\n",
    "    parameters['omega'] = self.U.omega\n",
    "\n",
    "    dimensions = {}\n",
    "    dimensions['K'] = self.num_layers\n",
    "    dimensions['d'] = self.dimension\n",
    "    dimensions['I'] = self.num_images\n",
    "    dimensions['iterations'] = self.iterations \n",
    "\n",
    "    functions = {}\n",
    "    functions['sigma'] = self.sigma\n",
    "    functions['sigma_derivative'] = self.sigma_derivative\n",
    "    functions['eta'] = self.eta\n",
    "    functions['eta_derivative'] = self.eta_derivative\n",
    "\n",
    "    # Соберет все словари в одном\n",
    "    network_dict = {}\n",
    "    network_dict['parameters'] = parameters\n",
    "    network_dict['dimensions'] = dimensions\n",
    "    network_dict['functions'] = functions\n",
    "\n",
    "    # Сохранит словарь как бинарный файл\n",
    "    # 'w' для записи, 'b' открыть как двоичный файл (по умолчанию используется текстовый файл)\n",
    "    with open(filename, 'wb') as outfile:\n",
    "        pickle.dump(network_dict, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_model(self, filename):\n",
    "    \"\"\"Загружает обученную модель. Устанавливает все значения, необходимые для прогнозирования с помощью модели. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    filename : string\n",
    "        Имя двоичного файла для загрузки формы модели. Файл должен содержать словарь.\n",
    "    \"\"\"\n",
    "    # Открыть файл как двоичный файл\n",
    "    # \"r\" для чтения, \"b\", чтобы открыть файл в виде двоичного файла (по умолчанию это текстовый файл)\n",
    "    file_to_read = open(filename, \"rb\")\n",
    "\n",
    "    # Считывает двоичный файл с помощью pickle\n",
    "    network_dict = pickle.load(file_to_read)\n",
    "\n",
    "    self.num_layers = network_dict['dimensions']['K']\n",
    "    self.dimension = network_dict['dimensions']['d']\n",
    "    self.num_images = network_dict['dimensions']['I']\n",
    "    self.iterations = network_dict['dimensions']['iterations']\n",
    "\n",
    "    # Initalize U with random values\n",
    "    self.U = Param(self.num_layers, self.dimension, self.num_images)\n",
    "\n",
    "    # Set the right values for U\n",
    "    self.U.weight = network_dict['parameters']['weight']\n",
    "    self.U.bias_vec = network_dict['parameters']['bias_vec']\n",
    "    self.U.mu = network_dict['parameters']['mu']\n",
    "    self.U.omega = network_dict['parameters']['omega']\n",
    "\n",
    "    self.sigma = network_dict['functions']['sigma']\n",
    "    self.sigma_derivative = network_dict['functions']['sigma_derivative']\n",
    "    self.eta = network_dict['functions']['eta']\n",
    "    self.eta_derivative = network_dict['functions']['eta_derivative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структурирование сети\n",
    "\n",
    "Как видно из этого блокнота, нейронная сеть состоит из множества переменных и функций, и для того, чтобы все было аккуратно и читабельно, важно структурировать код. Мы решили разделить реализацию параметров и сети на два отдельных класса, а также сохранить отдельный класс для метода градиентного спуска. Обратите внимание, что, конечно, есть много способов сделать это, которые будут работать одинаково хорошо. В следующей ячейке кода мы собрали класс `Network`. Большинство функций и переменных уже были введены, но функции, предназначенные для тестирования сети, будут объяснены в следующих разделах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, K=None, d=None, I=None, \n",
    "                 num_iterations = None, \n",
    "                 activation_functions_list = None, \n",
    "                 gradient_descent_method = None, \n",
    "                 gradient_descent_input = [], \n",
    "                 filename = '', data = None,\n",
    "                 rstate = 42\n",
    "                ):\n",
    "        \"\"\"Инициализирует сеть. Типы инициализации: из файла с заданными переменными или из набора данных.\n",
    "        -------\n",
    "        Из файла с установленными переменными:\n",
    "        Input\n",
    "        ------\n",
    "        filename : string\n",
    "            имя файла со всеми данными, необходимыми для прогнозирования. Должен:\n",
    "                - Быть двоичным файлом\n",
    "                - Содержать словарь Python в формате, указанном в Network.save_model()\n",
    "        -------\n",
    "        Из набора данных\n",
    "        Input\n",
    "        -----\n",
    "        K : int\n",
    "            Количество слоев\n",
    "        d : int\n",
    "            Количество нейронов в слое\n",
    "        I : int\n",
    "            Количество входов\n",
    "        activation_functions_list : список функций\n",
    "            [функция активации, производная функции активации, функция активации выходного слоя, \n",
    "            производная функции активации выходного слоя]\n",
    "        gradient_descent_method : GradientDescent\n",
    "            Класс для градиентного спуска \n",
    "        gradient_descent_input : list\n",
    "            Список дополнительных документов к gradient_descent_methon. Default = []\n",
    "        rstate : int\n",
    "            Random state for numpy. Чтобы сделать выходные данные воспроизводимыми\n",
    "            \n",
    "            \n",
    "        Attributes\n",
    "        ----------\n",
    "            U                : Param\n",
    "                Параметры сети.\n",
    "            num_layers       : int\n",
    "                Общее количество слоев\n",
    "            dimension        : int\n",
    "                Размер входного \"изображения\"\n",
    "            num_images       : int\n",
    "                Количество входных изображений \n",
    "            gradient_descent : GradientDescent\n",
    "                Метод градиентного спуска\n",
    "            one              : np.array\n",
    "                Array of ones. shape: num_images x 1\n",
    "            Y                : np.array\n",
    "                Матрица, содержащая изображение, преобразованное через K слоев. \n",
    "                shape: num_layers + 1 x dimension x num_images\n",
    "            Z                : np.array\n",
    "                Массив, содержащий проекцию последнего слоя в каждой итерации. размер: dimension x 1\n",
    "            c                : np.array\n",
    "                Истинные метки изображений. размер: dimension x 1\n",
    "            sigma            : function\n",
    "                Сигмовидная функция - функция активации для использования при преобразовании через скрытые слои\n",
    "            sigma_derivative : function\n",
    "                Производная сигмовидной функции\n",
    "            eta              : function\n",
    "                Функция активации для проецирования последнего слоя на скалярное значение.\n",
    "            eta_derivative   : function \n",
    "                Производная функции eta\n",
    "            iterations       : int\n",
    "                Количество итераций, выполняемых во время транса\n",
    "        \"\"\"\n",
    "        if filename != '':\n",
    "            self.load_model(filename)\n",
    "            np.random.RandomState(rstate)\n",
    "        else:\n",
    "            np.random.RandomState(rstate)\n",
    "\n",
    "            self.U = Param(K,d,I)\n",
    "            self.num_layers = K\n",
    "            self.dimension = d\n",
    "            self.num_images = I\n",
    "            self.gradient_descent = gradient_descent_method(self, *gradient_descent_input)\n",
    "            self.one = np.ones((I,1))\n",
    "            self.Y = np.zeros((K+1,d,I))\n",
    "            self.Z = np.zeros((d,1))\n",
    "            \n",
    "            self.get_dataset(data[0],data[1], data[2],  data[3])\n",
    "            \n",
    "            self.Y[0,:,:] = self.training_data\n",
    "            self.c = self.training_labels\n",
    "            self.sigma, self.sigma_derivative = activation_functions_list[0], activation_functions_list[1]\n",
    "            self.eta, self.eta_derivative = activation_functions_list[2], activation_functions_list[3]\n",
    "            self.iterations = num_iterations\n",
    "    \n",
    "    def get_dataset(self, X, y, X_train, y_train):\n",
    "        \"\"\"Функция загрузки набора данных для обучения и тестирования\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X       : np.array\n",
    "            test 'images'. shape : dimension x num_images\n",
    "        y       : np.array\n",
    "            test labels. shape : num_images x 1\n",
    "        X_train : np.array\n",
    "            train 'images'. shape : dimension x num_images\n",
    "        y_train : np.array\n",
    "            test labels. shape : num_images x 1\n",
    "        \"\"\"\n",
    "        \n",
    "        self.training_data = X_train\n",
    "        self.training_labels = y_train\n",
    "        self.validation_data = X\n",
    "        self.validation_labels = y\n",
    "        \n",
    "    def cost_function(self):\n",
    "        \"\"\"Calculates the least square error of the current output form the network.\"\"\"\n",
    "        return 1/2*(np.linalg.norm(self.Z-self.c))**2\n",
    "    \n",
    "    def projection(self,Y):\n",
    "        \"\"\"Calculates output. Uses the last values of Y and send them through the outputlayer.\"\"\"\n",
    "        return self.eta(Y[-1].T@self.U.omega + self.U.mu)\n",
    "    \n",
    "    def forward_prop(self,Y):\n",
    "        \"\"\"Forward propagation. Calculates all values of Y based on weights and biases.\"\"\"\n",
    "        for i in range(self.num_layers):\n",
    "            Y[i+1,:,:] = Y[i,:,:] +  self.steplength*self.sigma(self.U.weight[i,:,:]@Y[i,:,:] + self.U.bias_vec[i])  \n",
    "        \n",
    "    def train(self, h=0.1, tau=0.01):\n",
    "        \"\"\"Training of the network\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : float\n",
    "            steplength\n",
    "        \"\"\"\n",
    "        \n",
    "        # REVIEWER'S NOTE, REMOVE BEFORE PUBLISH!\n",
    "        # Empty parameter list in docstring.\n",
    "        self.cost_per_iter = np.zeros(self.iterations-1)\n",
    "        self.validation_cost_per_iter = np.zeros(self.iterations-1)\n",
    "        self.steplength = h\n",
    "        self.tau = tau\n",
    "\n",
    "        for i in tqdm(range(self.iterations)):  # tqdm creates a progressbar\n",
    "            \n",
    "            self.forward_prop(self.Y)\n",
    "            \n",
    "            self.Z = self.projection(self.Y)\n",
    "            self.U.calculate_P_K(self)\n",
    "            \n",
    "            self.gradient_descent.update_first(self)\n",
    "            self.U.calculate_P(self)\n",
    "            \n",
    "            self.gradient_descent.update_second(self)\n",
    "            \n",
    "            self.Z = self.projection(self.Y)\n",
    "            \n",
    "            self.gradient_descent.update_params(self,i)\n",
    "            \n",
    "            self.Z = self.projection(self.Y)\n",
    "            \n",
    "            if i != 0:\n",
    "                self.cost_per_iter[i - 1] = self.cost_function()\n",
    "                pred = self.predict(self.validation_data, integers = False)\n",
    "                self.validation_cost_per_iter[i-1] = 1/2*(np.linalg.norm(pred-self.validation_labels))**2\n",
    "\n",
    "                \n",
    "    def predict(self, X, integers=True):\n",
    "        \"\"\"Makes a prediction based on current weights and biases.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Input to network\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        prediction : np.array\n",
    "            Output of the network\n",
    "        \"\"\"\n",
    "        Y_pred = np.zeros((self.num_layers+1,self.dimension,len(X[0])))\n",
    "        Y_pred[0,:,:] = X\n",
    "        self.forward_prop(Y_pred)\n",
    "        \n",
    "        prediction = self.projection(Y_pred)\n",
    "        \n",
    "        if integers == True:\n",
    "            prediction[prediction>=0.5] = 1\n",
    "            prediction[prediction<0.5] = 0\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "    def evolution(self, filename=\"\"):\n",
    "        \"\"\"Function for plotting how the performance of the model evolves.\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        \n",
    "        filename : string\n",
    "            default = \"\" : does not save figure, else filename\n",
    "            specifies the name of the file to which the plot will be saved.\n",
    "        \"\"\"\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.title(r\"\\textbf{Cost as a function of iteration}\")\n",
    "        \n",
    "        plt.plot(\n",
    "            np.arange(self.iterations-1),\n",
    "            self.cost_per_iter,\n",
    "            label = r\"$\\mathcal{J}(\\mathbf{U}^{(j)})$\"\n",
    "        )\n",
    "        \n",
    "        plt.xlabel(r\"$j$\")\n",
    "        plt.ylabel(r\"$\\mathcal{J}(\\mathbf{U}^{(j)})$\")\n",
    "        plt.grid(ls =\"--\")\n",
    "        \n",
    "        plt.yscale(\"log\")  # Logarithmic scale of y-axis to better see how it evolves with j.\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        \n",
    "        if filename != \"\":\n",
    "            fig.savefig(filename)\n",
    "        \n",
    "    def compare_evolution(self, other, label1, label2, filename=\"\"):\n",
    "        \"\"\"Function for plotting the performance of the model compared to another\n",
    "        model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        other : Network\n",
    "            trained network of the same type. Most meaningful to compare if it is \n",
    "            trained with the same amount of iterations.\n",
    "            \n",
    "        label1 : string\n",
    "            label of self\n",
    "        \n",
    "        label2 : string\n",
    "            label of other\n",
    "        \n",
    "        filename : string\n",
    "            default = \"\" : does not save figure, else filename\n",
    "            specifies the name of the file to which the plot will be saved.\n",
    "        \n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        plt.title(r\"\\textbf{Cost as a function of iteration}\")\n",
    "        \n",
    "        plt.plot(\n",
    "            np.arange(self.iterations-1),\n",
    "            self.cost_per_iter,\n",
    "            label=r\"$\\mathcal{J}(\\mathbf{U}^{(j)})_{\\textup{%s}}$\" %label1\n",
    "        )\n",
    "        plt.plot(\n",
    "            np.arange(other.iterations-1),\n",
    "            other.cost_per_iter,\n",
    "            label=r\"$\\mathcal{J}(\\mathbf{U}^{(j)})_{\\textup{%s}}$\" %label2\n",
    "        )\n",
    "        \n",
    "        plt.legend()\n",
    "        \n",
    "        plt.xlabel(r\"$j$\")\n",
    "        plt.ylabel(r\"$\\mathcal{J}(\\mathbf{U}^{(j)})$\")\n",
    "        \n",
    "        plt.grid(ls =\"--\")\n",
    "        plt.yscale(\"log\")  # Logarithmic scale of y-axis to see how it evolves with j better.\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        if filename != \"\":\n",
    "            fig.savefig(filename)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"Use a validation set {X,y} to check the accuracy of the network. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Validation set input\n",
    "        y : np.array\n",
    "            Validation set true value for output\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        accuracy : float\n",
    "            The accuracy is the percentage of correct predictions\n",
    "        \"\"\"\n",
    "        Y_test = self.predict(X)\n",
    "        accuracy = np.sum(y == Y_test)/len(Y_test)\n",
    "        return accuracy\n",
    "    \n",
    "    def variance(self, X, y):\n",
    "        \"\"\"Use a validation set {X,y} to check the variance of the network. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Validation set input\n",
    "        y : np.array\n",
    "            Validation set true value for output\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        variance : float\n",
    "            The variance is 1/(n-1) sum((prediction - true value)^2)\n",
    "        \"\"\"\n",
    "        Y_test = self.predict(X, integers=False)\n",
    "        variance = 1/(len(y)-1)*np.sum(np.square(Y_test-y))\n",
    "        return variance\n",
    "    \n",
    "    def confusion_matrix(self, X, y, label=\"\"):\n",
    "        \"\"\"Use a validation set {X,y} to test if the model is biased. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Validation set input\n",
    "        y : np.array\n",
    "            Validation set true value for output\n",
    "        label : string\n",
    "            Label to append to figure title\n",
    "        \"\"\"\n",
    "        Y_test = self.predict(X)\n",
    "        \n",
    "        Y_test = Y_test[:,0]\n",
    "        y      = y[:,0]  \n",
    "        Y_test = np.array([int(y_i) for y_i in Y_test])\n",
    "        \n",
    "        TP = np.sum(Y_test&y)         # True positives\n",
    "        TN = np.sum((1-Y_test)&(1-y)) # True negatives\n",
    "        FP = np.sum(Y_test&(1-y))     # False positives\n",
    "        FN = np.sum((1-Y_test)&y)     # False negatives\n",
    "        \n",
    "        # Normalising data\n",
    "        \n",
    "        tn = TN/(TN + FN)\n",
    "        fn = FN/(TN + FN)\n",
    "        fp = FP/(FP + TP)\n",
    "        tp = TP/(FP + TP)\n",
    "        \n",
    "        M = np.array([[tn,fn],\n",
    "                      [fp,tp]])\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        plt.title(f\"Confusion matrix{' - ' + label if label else ''}\")\n",
    "        \n",
    "        # Using the seaborn heatmap-function\n",
    "        sns.heatmap(M, annot=True, \n",
    "                    square = True, \n",
    "                    xticklabels=[0,1], \n",
    "                    yticklabels=[0,1],\n",
    "                    vmax = 1,\n",
    "                    vmin = 0\n",
    "                   )\n",
    "        \n",
    "        ax.set_xlabel(\"Predicted value\")\n",
    "        ax.set_ylabel(\"Actual value\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "    \n",
    "    def visualize_layers(self):\n",
    "        \"\"\"Visualizes how the input data is transformed through the layers of \n",
    "        the network. This function is only sensible to use when the data\n",
    "        is two-dimensional, and the number of nodes in each layer is the same\n",
    "        as the input dimension.\n",
    "        \"\"\"\n",
    "        height = int(np.ceil((self.num_layers + 1)/4))  # Number of columns of plot\n",
    "        \n",
    "        fig, ax = plt.subplots(ncols=4, nrows=height, figsize=(14, 3 * height))\n",
    "        fig.suptitle(r\"\\textbf{Grid transformations progression}\", fontsize=26)\n",
    "        \n",
    "        for i in range(self.num_layers + 1):\n",
    "            k = i // 4  # Row-index\n",
    "            j = i - k * 4   # Column-index\n",
    "            \n",
    "            ax[k,j].scatter(x=(self.Y[i,:,:])[0,:], \n",
    "                            y=(self.Y[i,:,:])[1,:], \n",
    "                            s=1, \n",
    "                            c=self.c.flatten(), \n",
    "                            cmap='bwr')\n",
    "            ax[k,j].axis([-1.2, 1.2, -1.2, 1.2])\n",
    "            ax[k,j].axis('square')\n",
    "            ax[k,j].axis(\"off\") #  Removing frame of axis\n",
    "        \n",
    "        for i in range(height * 4 - self.num_layers + 1):\n",
    "            # Deleting unused subplots    \n",
    "            ax[height-1,i].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def training_vs_validation_error(self, filename=\"\"):\n",
    "        \"\"\"Compares training error with validation error, using a validation set {X, y}\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Validation set input\n",
    "        y : np.array\n",
    "            Validation set true value for output\n",
    "        filename : string\n",
    "            default = \"\" : does not save figure, else filename\n",
    "            specifies the name of the file to which the plot will be saved.\n",
    "        \"\"\"\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.title(r\"\\textbf{Cost as a function of iteration. Validation vs training}\")\n",
    "        \n",
    "        plt.plot(\n",
    "            np.arange(self.iterations-1),self.cost_per_iter,\n",
    "            label=\"Training cost\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            np.arange(self.iterations-1),self.validation_cost_per_iter,\n",
    "            label=\"Validation cost\"\n",
    "        )\n",
    "        \n",
    "        plt.xlabel(r\"$j$\")\n",
    "        plt.ylabel(r\"$\\mathcal{J}(\\mathbf{U}^{(j)})$\")\n",
    "        plt.grid(ls =\"--\")\n",
    "        \n",
    "        plt.yscale(\"log\")  # Logarithmic scale of y-axis to see how it evolves with j better.\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        \n",
    "        if filename != \"\":\n",
    "            fig.savefig(filename)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        \"\"\"Saves a trained model. Saves all values neccesary to make predictions with the model. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            Name of binary-file to ave model to.\n",
    "        \"\"\"\n",
    "        # Create sub dictionaries to structre the data.\n",
    "        parameters = {}\n",
    "        parameters['weight'] = self.U.weight\n",
    "        parameters['bias_vec'] = self.U.bias_vec\n",
    "        parameters['mu'] = self.U.mu\n",
    "        parameters['omega'] = self.U.omega\n",
    "\n",
    "        dimensions = {}\n",
    "        dimensions['K'] = self.num_layers\n",
    "        dimensions['d'] = self.dimension\n",
    "        dimensions['I'] = self.num_images\n",
    "        dimensions['iterations'] = self.iterations \n",
    "\n",
    "        functions = {}\n",
    "        functions['sigma'] = self.sigma\n",
    "        functions['sigma_derivative'] = self.sigma_derivative\n",
    "        functions['eta'] = self.eta\n",
    "        functions['eta_derivative'] = self.eta_derivative\n",
    "\n",
    "        # Collect all dictionaries in one.\n",
    "        network_dict = {}\n",
    "        network_dict['parameters'] = parameters\n",
    "        network_dict['dimensions'] = dimensions\n",
    "        network_dict['functions'] = functions\n",
    "\n",
    "        # Save dictionary as binay file.\n",
    "        # 'w' for write, 'b' to open as binary file (text file is default).\n",
    "        with open(filename, 'wb') as outfile: \n",
    "            pickle.dump(network_dict, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        \"\"\"Loads up a trained model. Sets all valules neccesary to make predictions with the model. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        filename : string\n",
    "            Name of binary-file to load model form. The file must contain a dictionary.\n",
    "        \"\"\"\n",
    "        # Open file as binary file.\n",
    "        # 'r' for read, add 'b' to open the file as a binary file (default is text file)\n",
    "        file_to_read = open(filename, \"rb\")\n",
    "        print('file', file_to_read)\n",
    "\n",
    "        # Converts binary file to.\n",
    "        network_dict = pickle.load(file_to_read)\n",
    "        print('dict', network_dict)\n",
    "\n",
    "        self.num_layers = network_dict['dimensions']['K']\n",
    "        self.dimension = network_dict['dimensions']['d']\n",
    "        self.num_images = network_dict['dimensions']['I']\n",
    "        self.iterations = network_dict['dimensions']['iterations']\n",
    "\n",
    "        # Initalize U with random values.\n",
    "        self.U = Param(self.num_layers,self.dimension,self.num_images)\n",
    "\n",
    "        # Set the right values for U.\n",
    "        self.U.weight = network_dict['parameters']['weight']\n",
    "        self.U.bias_vec = network_dict['parameters']['bias_vec']\n",
    "        self.U.mu = network_dict['parameters']['mu']\n",
    "        self.U.omega = network_dict['parameters']['omega']\n",
    "\n",
    "        self.sigma = network_dict['functions']['sigma']\n",
    "        self.sigma_derivative = network_dict['functions']['sigma_derivative']\n",
    "        self.eta = network_dict['functions']['eta']\n",
    "        self.eta_derivative = network_dict['functions']['eta_derivative']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор данных\n",
    "\n",
    "В этом блокноте мы протестировали сеть на простой и легкодоступной форме набора данных `sklearn`. Набор данных загружается с помощью вызова `sklearn.datsets.make_moons(n)`, где $n$ - количество точек данных. Набор данных состоит из 2-мерных входных данных, которые представляют точки в сетке с соответствующими метками. Вызов функции возвращает две переменные, $X$ и $y$, где $X$ содержит точки данных, а $y$ содержит связанные метки. Ниже мы построили набор данных для $n=400$ и раскрасили точки в соответствии с метками.\n",
    "\n",
    "Функция вернет точки в двух полукругах в $\\mathbb{R}^2$, помеченные $1$ или $0$ в зависимости от их координат. Мы решили присвоить цвет _blue_ экземплярам с меткой $0$ и _red_ экземплярам с меткой $1$. Чтобы сделать проблему менее тривиальной, мы добавляем к данным шум, из-за которого точки лежат немного в стороне от полукруга, к которому они принадлежат. Данные с шумом и без шума показаны ниже. Функция по умолчанию возвращает точки в случайном порядке. Значение `random_state` устанавливается для того, чтобы функция каждый раз возвращала точки в одном и том же порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Vizualization of dataset\n",
    "X, y = datasets.make_moons(400,random_state = 42, noise = 0)\n",
    "\n",
    "blue = X[y==0]\n",
    "red  = X[y==1]\n",
    "\n",
    "plt.title(r\"\\textbf{Data without noise}\")\n",
    "plt.plot(blue[:,0],blue[:,1],\"bo\")\n",
    "plt.plot(red[:,0],red[:,1],\"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualization of dataset\n",
    "X, y = datasets.make_moons(400,random_state = 42, noise = 0.15)\n",
    "\n",
    "blue = X[y==0]\n",
    "red  = X[y==1]\n",
    "\n",
    "plt.title(r\"\\textbf{Data with noise}\")\n",
    "plt.plot(blue[:,0],blue[:,1],\"bo\")\n",
    "plt.plot(red[:,0],red[:,1],\"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Протестируем сеть\n",
    "\n",
    "Пришло время протестировать сеть. Цель будет состоять в том, чтобы классифицировать, принадлежит ли точка синему или красному полукругу в наборе данных. Мы протестируем как градиентный спуск Адама, так и ванильный градиентный спуск, и поэтому мы создадим две отдельные сети.\n",
    "\n",
    "Во время обучения сети мы также проверяем, как она работает с другим набором данных. Поэтому мы делаем два набора данных _separate_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 1000  # Количество точек данных\n",
    "\n",
    "X_train, y_train = datasets.make_moons(I, random_state=100, noise=0.1)      \n",
    "X_validate, y_validate = datasets.make_moons(I, random_state=30, noise=0.1)  \n",
    "\n",
    "y_train = np.reshape(y_train, (I,1))  # Change the shape to adapt it to the network.\n",
    "y_validate = np.reshape(y_validate, (I,1))\n",
    "\n",
    "netAdam = Network(\n",
    "    K=15,        # number of layers\n",
    "    d=2,         # dimension of input\n",
    "    I=I,         # number of datapoints\n",
    "    num_iterations=5000,\n",
    "    activation_functions_list=[tanh, tanh_derivative, sigmoid, sigmoid_derivative],\n",
    "    gradient_descent_method=Adam,\n",
    "    gradient_descent_input=[], # using default values of the parameters\n",
    "    data=[X_validate.T, y_validate, X_train.T, y_train],\n",
    ")\n",
    "\n",
    "\n",
    "netVanilla = Network(\n",
    "    K=15,        # number of layers\n",
    "    d=2,         # dimension of input\n",
    "    I=I,         # number of datapoints\n",
    "    num_iterations=5000,\n",
    "    activation_functions_list=[tanh, tanh_derivative, sigmoid, sigmoid_derivative],\n",
    "    gradient_descent_method=Plain_vanilla,\n",
    "    gradient_descent_input=[], # using default values of the parameters\n",
    "    data=[X_validate.T, y_validate, X_train.T, y_train],\n",
    ")\n",
    "\n",
    "# If you wish to save a model, or load a model, this is how its done:\n",
    "# netAdam.save_model('test')\n",
    "# AdamCopy = Network(filename = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netVanilla.train()\n",
    "netAdam.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы визуализировать, как стоимость развивается в зависимости от индекса итерации, мы используем функцию `Network.training_vs_validation_error()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netVanilla.training_vs_validation_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netAdam.training_vs_validation_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как показано выше, стоимость валидации в большинстве случаев достигнет точки, за которой она существенно не улучшит классификацию. Стоимость валидации может даже увеличиться, если мы пойдем дальше, хотя стоимость обучения продолжает снижаться. В идеале следует прекратить обучение с минимальными затратами на проверку, так как дальнейшее обучение сети приведет к ее переобучению(_overfitting_). То есть вместо того, чтобы улавливать суть структуры данных, она специализируется на конкретных данных, которые ей были даны. Эвристически сеть обманывает себя, рассматривая случайный шум в данных как часть структуры, которую она должна предсказать. Это приводит к тому, что сеть работает очень хорошо с обучающими данными, но хуже с тестирующими данными. \n",
    "\n",
    "В качестве иллюстрации этого рассмотрим задачу аппроксимации многочлена множеством точек. Если у нас есть N точек, которые мы хотим аппроксимировать нашим полиномом, мы знаем, что нам гарантировано, что существует полином степени не более N−1, который проходит через все точки. Однако это не обязательно тот полином, который наиболее близко напоминает истинную модель. Другой крайний случай-когда модель слишком проста, и мы называем ее недоученной (_underfitting_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overfitting](images/overfitting_fig.png \"overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация обучения\n",
    "\n",
    "Основная цель обучения - найти значения параметров $\\mathbf{U}$, которые минимизируют $\\mathcal{J}$. Чтобы увидеть, работает ли обучение так, как ожидалось, мы можем построить график $\\mathcal{J}(\\mathbf{U}^{(j)})$, чтобы увидеть, как изменяется стоимость в зависимости от итераций $j$. Мы используем функцию `Network.compare_evolution`, реализованную в классе `Network`, для визуализации обучения для обеих сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netVanilla.compare_evolution(netAdam, \"Vanilla\", \"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из приведенного выше графика, сеть, обученная с помощью алгоритма Adam, обучается намного быстрее, чем сеть, обученная с помощью алгоритма Plain-Vanilla. Тем не менее, поскольку задача настолько проста, погрешность обеих сетей через некоторое время стагнирует. Поэтому обучение Adam-сети за $5000$ итераций в данном случае является довольно чрезмерным, так как это не повышает производительность. Это также видно ниже, где мы сравниваем, как работают две сети в *матрице ошибок*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике ниже показано положение красных и синих точек данных после начала преобразования через каждый из слоев сети. Из приведенных ниже визуализаций мы видим, что сеть учится скручивать и распутывать две спирали, чтобы было легко сделать классификацию, что она просто делает, рисуя прямую линию в $\\mathbb{R}^2$, которая отделяет синий кусок от красного. Понимание, полученное в результате этой искусственно простой проблемы, действительно может быть перенесено на более сложные данные более высокого измерения. Проблема в том, что в задачах с более высокими измерениями невозможно визуализировать этот процесс с такой же легкостью. Если бы, например, мы должны были двоично классифицировать точки в $N$-мерном пространстве, обученная сеть отображала бы точки в $N$-мерном пространстве через слои, и в конечном итоге она нарисовала бы гиперплоскость $N-1$, разделяющую два класса на две области пространства. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netAdam.visualize_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения сети, нет ничего особенного в классификации точек в спиралях по сравнению с любой другой точкой на плоскости. Если бы мы классифицировали область вокруг спиралей, мы ожидаем, что классификация будет хорошей вблизи каждой спирали и в меньшей степени между ними. Это именно то, что мы наблюдаем ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "y = np.linspace(-1,1,N)\n",
    "x = np.linspace(-1,2,N)\n",
    "\n",
    "xx, yy = np.meshgrid(x,y)\n",
    "\n",
    "plane = np.reshape((xx,yy), (2, N**2))\n",
    "\n",
    "Z = netAdam.predict(plane, integers = False)\n",
    "\n",
    "plt.contourf(x, y, Z.reshape((N,N)), cmap='seismic', levels = 100)\n",
    "plt.contour(x, y, Z.reshape((N,N)), levels=1, colors='k')\n",
    "plt.xlim([-1,2])\n",
    "plt.ylim([-1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точность сети\n",
    "\n",
    "Несмотря на то, что важно, чтобы сеть хорошо работала во время обучения, именно тесты, выполненные с проверочным набором, действительно говорят вам, насколько хороша сеть. Здесь вы тестируете сеть на новых данных и видите, насколько хорошо она преформируется в целом. Существует множество способов тестирования сети, но мы выбрали три простых метода, которые могут быть реализованы для большинства проблем. Сначала мы проверяем точность сети, т.е. Какой процент догадок верен. Если точность близка к $50 \\%$ для двоичной классификации, это означает, что сеть не смогла узнать связь между входными и выходными данными, и с тем же успехом можно использовать случайные предположения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method beloning to network\n",
    "#self = Network\n",
    "\n",
    "def accuracy(self, X, y):\n",
    "    \"\"\"Use a validation set {X,y} to check the accuracy of the network. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        Validation set input\n",
    "    y : np.array\n",
    "        Validation set true value for output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : float\n",
    "        The accuracy is the percentage of correct predictions\n",
    "    \"\"\"\n",
    "    Y_test = self.predict(X)\n",
    "    accuracy = np.sum(y == Y_test)/len(Y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 \n",
    "X_validate, c_validate = datasets.make_moons(n,noise = 0.15)\n",
    "\n",
    "print(\"Accuracy Adam:    %.3f\" %netAdam.accuracy(X_validate.T, np.array([c_validate]).T))\n",
    "print(\"Accuracy Vanilla: %.3f\" %netVanilla.accuracy(X_validate.T, np.array([c_validate]).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-вторых, мы проверяем дисперсию сети. Здесь мы видим, насколько сеть уверена в своих догадках. В идеале сеть будет выводить либо $1$, либо $0$ для двух категорий, но на самом деле она возвращает десятичное число между $1$ и $0$. Дисперсия - это мера того, насколько близки или далеки от истинного значения предположения. Чем меньше дисперсия, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function beloning to network\n",
    "#self = Network\n",
    "\n",
    "def variance(self, X, y):\n",
    "    \"\"\"\n",
    "    Use a validation set {X,y} to check the variance of the network. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        Validation set input\n",
    "    y : np.array\n",
    "        Validation set true value for output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    variance : float\n",
    "        The variance is 1/(n-1) sum((prediction - true value)^2)\n",
    "    \"\"\"\n",
    "    Y_test = self.predict(X, integers=False)\n",
    "    variance = 1/(len(y)-1)*np.sum(np.square(Y_test-y))\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance Adam:    %.3e\" %netAdam.variance(X_validate.T, np.array([c_validate]).T))\n",
    "print(\"Variance Vanilla: %.3e \" %netVanilla.variance(X_validate.T, np.array([c_validate]).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третий тест - это матрица ошибок. Это квадратная матрица $n\\times n$ , где $n$ - количество классов, которые она предсказывает. Строки представляют истинное значение класса, а столбцы-предполагаемое значение. Элемент $(i,j)$ матрицы - (нормализованное) число предполагаемых экземпляров категории $j$, которые имеют истинное значение $i$. Идеальной классификацией тогда была бы единичная матрица. Ниже мы построим матрицы ошибок  для проверки в двух сетях. В случае двоичной классификации мы можем записать элементы как истинные отрицательные (TN), истинные положительные (TP), ложные отрицательные (FN) и ложные положительные (FP) следующим образом\n",
    "\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "        \\frac{\\text{TN}}{\\text{N}} & \\frac{\\text{FN}}{N} \\\\\n",
    "        \\frac{\\text{FP}}{\\text{P}} & \\frac{\\text{TP}}{P}\n",
    "    \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "где P-количество положительных экземпляров (категория 1), а N-количество отрицательных экземпляров (категория 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_test_vanilla = netVanilla.confusion_matrix(X_validate.T, np.array([c_validate]).T)\n",
    "bias_test_adam = netAdam.confusion_matrix(X_validate.T, np.array([c_validate]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комментарии\n",
    "\n",
    "### Несбалансированный набор данных\n",
    "\n",
    "В этом блокноте мы использовали очень идеализированный набор данных, который всегда имеет равное количество точек данных для каждого класса. При использовании реальных данных это происходит редко. Если набор данных имеет большой избыточный вес одного из классов, есть большая вероятность, что сеть будет предвзято относить большинство объектов к этому классу, поскольку это, как правило, является хорошим решением во время обучения. Это одна из многих проблем, с которыми вы можете столкнуться при работе с реальными наборами данных. Ниже приводится иллюстрация того, что может произойти в случае несбалансированного набора данных. В этом примере мы включаем только $10$ синих точек данных и $250$ красных, чтобы создать искусственно несбалансированный набор данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 500  # Number of datapoints\n",
    "\n",
    "X_train, y_train = datasets.make_moons(I, random_state=100, noise=0.1)      \n",
    "X_validate, y_validate = datasets.make_moons(I, random_state=30, noise=0.1)  \n",
    "\n",
    "# Removing some of the blue datapoints \n",
    "\n",
    "blue = y_train == 0\n",
    "red  = y_train == 1\n",
    "y_blue = y_train[blue]\n",
    "X_blue = X_train[blue]\n",
    "y_red  = y_train[red]\n",
    "X_red  = X_train[red]\n",
    "\n",
    "y = y_blue[:10]\n",
    "X = X_blue[:10]\n",
    "\n",
    "X_train_new = np.concatenate((X,X_red), axis = 0 )\n",
    "y_train_new = np.concatenate((y,y_red), axis = 0 )\n",
    "\n",
    "y_train_new = np.reshape(y_train_new, (260,1))  # Change the shape to adapt it to the network.\n",
    "y_validate = np.reshape(y_validate, (I,1))\n",
    "\n",
    "imbalancedNet = Network(\n",
    "    K=15,          # number of layers\n",
    "    d=2,           # dimension of input\n",
    "    I=260,         # number of datapoints\n",
    "    num_iterations=1000,\n",
    "    activation_functions_list=[tanh, tanh_derivative, sigmoid, sigmoid_derivative],\n",
    "    gradient_descent_method=Plain_vanilla,\n",
    "    gradient_descent_input=[], # using default values of the parameters\n",
    "    data=[X_validate.T, y_validate, X_train_new.T, y_train_new],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalancedNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 \n",
    "X_validate, c_validate = datasets.make_moons(n,noise = 0.15)\n",
    "\n",
    "bias_test_imbalanced = imbalancedNet.confusion_matrix(X_validate.T, np.array([c_validate]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение, валидация и набор тестов\n",
    "\n",
    "В этом блокноте мы использовали только обучающие и проверочные наборы. Обычно также используется тестовый набор. Очевидно, что обучающий набор используется во время обучения сети. Набор проверки используется для проверки производительности модели *при разработке* сети. Это может быть, например, для поиска наилучших значений количества слоев, итераций и нейронов в сети. Когда вы довольны всей сетью и всеми ее параметрами, вы проводите заключительный тест с набором тестов. Это делается для того, чтобы изменения, внесенные в ходе разработки, также подходили для тестовых данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Следующий шаг \n",
    "\n",
    "Несмотря на то, что набор данных в этом блокноте является идеализированным, теория может быть применена к широкому кругу проблем. Создание модели машинного обучения с нуля может быть интересным и увлекательным, но для более эффективных и сложных моделей мы рекомендуем попробовать некоторые пакеты, доступные для Python:\n",
    "\n",
    "\n",
    "- <a href=\"https://www.tensorflow.org/overview\">Getting started with Tensorflow</a>.\n",
    "- <a href=\"https://pytorch.org/tutorials/\">Getting started with PyTorch</a>.\n",
    "- <a href=\"https://scikit-learn.org/stable/getting_started.html\">Getting started with Scikit-learn</a>.\n",
    "\n",
    "<a href = \"https://pandas.pydata.org/docs/getting_started/index.html\"> Пакет Pandas </a> также очень полезен при работе с большими объемами данных, и большинство пакетов машинного обучения в Python совместимы с фреймами данных Pandas.\n",
    "\n",
    "\n",
    "Полносвязные нейронные сети - очень популярный тип машинного обучения, но существует множество различных моделей, как в категории нейронных сетей, так и моделей, использующих совершенно разные структуры.\n",
    "\n",
    "- <a href = \"https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/\"> Long short term memory (LSTM) networks </a> может использоваться, например, для распознавания речи и специализируется на поиске паттернов во времени.\n",
    "- <a href =  \"https://www.geeksforgeeks.org/what-is-reinforcement-learning/\"> Reinforcement learning </a> это тип неконтролируемого метода машинного обучения, который использует вознаграждения во время обучения вместо истинных значений для каждой точки данных.\n",
    "- <a href =  \"https://towardsdatascience.com/understanding-random-forest-58381e0602d2\"> Random forest </a> это метод машинного обучения, который облегчает определение того, какие переменные являются наиболее важными для классификации или регрессии.\n",
    "- <a href =  \"https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148\"> Logistic regression </a> это двоичный классификатор, который, как известно, прост в реализации и взаимопроникновении, и может быть хорошим для начала, если вы заинтересованы в статистических данных, лежащих в основе машинного обучения.\n",
    "- <a href =  \"https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\"> Support vector machine </a> может обеспечить хорошую точность как для задач классификации, так и для задач регрессии с меньшей вычислительной мощностью, чем, например, нейронные сети.\n",
    "- <a href =  \"https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\"> K-means </a> это неконтролируемый метод поиска шаблонов в (немаркированном) наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сноски <br>\n",
    "$^1$ ANN также может иметь менее трех слоев; Однослойный прецептрон состоит только из выходного слоя. <br>\n",
    "$^2$ Не во всех сетях есть нейроны, которые выводят значения от 0 до 1. Именно диапазон функции активации определяет масштабирование выходных данных нейронов. <br>\n",
    "$^3$ Или любая другая функция активации. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    " <a name=\"biological_net\">[1]</a> _Neural network_ https://en.wikipedia.org/wiki/Neural_network <br>\n",
    " <a name=\"activation_functions\">[2]</a> _Understanding Activation Functions in Neural Networks_ https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0 <br>\n",
    " <a name=\"ann_training\">[3]</a> _Activation functions in neural networks_ https://www.geeksforgeeks.org/activation-functions-neural-networks/ <br>\n",
    " <a name=\"ReLU\">[4]</a> _A Practical Guide to ReLU_ https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7 <br>\n",
    " <a name=\"initialization_of_parameters\">[5]</a> _Weight Initialization Techniques in Neural Networks_ https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78 \n",
    " \n",
    " The original report about the ResNet: <br>\n",
    " _Deep Residual Learning for Image Recognition_ https://arxiv.org/abs/1512.03385\n",
    " \n",
    " https://habr.com/ru/post/474084/ \n",
    " https://habr.com/ru/post/478790/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение\n",
    "\n",
    "## Вывод градиентных формул\n",
    "\n",
    "В тексте мы вывели градиенты $\\mathcal{J}$ по отношению к $\\mu$ и $\\omega$. Здесь мы выведем два других градиента, и с этой целью мы представим немного новой нотации, чтобы более элегантно обрабатывать выражения.\n",
    "\n",
    "Пусть $H : \\mathbb{R}^m \\to \\mathbb{R}^n$ - функция переменных $m$, а $\\mathbf{x},\\boldsymbol{\\delta}$ - векторы в $\\mathbb{R}^m$. Направленная производная $H$ в $\\mathbf{x}$ в направлении $\\boldsymbol{\\delta}$ как \n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d} \\epsilon} \\biggr\\lvert_{\\epsilon = 0} H(\\mathbf{x} + \\epsilon \\boldsymbol{\\delta}) = \\nabla H (\\mathbf{x}) \\cdot \\boldsymbol{\\delta} = \\left\\langle \\frac{\\partial H}{\\partial \\mathbf{x}} (\\mathbf{x}), \\boldsymbol{\\delta} \\right\\rangle.\n",
    "$$\n",
    "\n",
    "Рассмотрим изменение $\\mathcal{J}$ в направлении $\\delta W_k$. Поскольку $\\mathcal{J}$ зависит только косвенно от $W_k$, через $\\mathbf{Y}_K$, мы сначала рассмотрим изменение вдоль направления $\\delta \\mathbf{Y}_K$ \n",
    "\n",
    "\\begin{equation}\\label{eq:del_J}\n",
    "    \\delta \\mathcal{J} = \\frac{\\text{d}}{\\text{d} \\epsilon} \\biggr\\lvert_{\\epsilon = 0} \\mathcal{J}(\\mathbf{Y}_K + \\epsilon \\delta \\mathbf{Y}_K) = \\left\\langle \\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_K}, \\delta \\mathbf{Y}_K \\right\\rangle. \\quad (1)\n",
    "\\end{equation}\n",
    "\n",
    "Теперь введем $\\mathbf{P}_K := \\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_K}$. Так как у нас есть \n",
    "\n",
    "\\begin{equation}\\label{eq:transf}\n",
    "    \\mathbf{Y}_K = \\mathbf{Y}_{K-1} + h \\sigma{\\left( W_{K-1} \\mathbf{Y}_{K-1} + b_{K-1} \\right)},\\quad (2)\n",
    "\\end{equation}\n",
    "\n",
    "изменение $\\delta \\mathbf{Y}_K$ равно \n",
    "\n",
    "$$\n",
    "    \\delta \\mathbf{Y}_K = \\left( I +  h \\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (W_{K-1} \\mathbf{Y}_{K-1} + b_{K-1}) \\right) \\delta \\mathbf{Y}_{K-1}.\n",
    "$$\n",
    "\n",
    "Мы можем вставить это в уравнение (1) и использовать тот факт, что $\\langle v, Aw \\rangle = \\langle A^T v, w \\rangle$ для произвольных векторов $v\\in \\mathbb{R}^n, w \\in \\mathbb{R}^m$ и матрицы $A \\in \\mathbb{R}^{n\\times m}$. Следовательно, \n",
    "\n",
    "\\begin{align*}\n",
    "    \\delta \\mathcal{J} &= \\left\\langle \\mathbf{P}_K, \\left( I +  h\\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (W_{K-1} \\mathbf{Y}_{K-1} + b_{K-1}) \\right) \\delta \\mathbf{Y}_{K-1} \\right\\rangle \\\\\n",
    "    &= \\left\\langle \\mathbf{P}_K +  h\\left[\\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (W_{K-1} \\mathbf{Y}_{K-1} + b_{K-1})\\right]^T \\mathbf{P}_K, \\delta \\mathbf{Y}_{K-1} \\right\\rangle.\\quad (3)\n",
    "\\end{align*}\n",
    "\n",
    "Поэтому мы определяем в целом \n",
    "\n",
    "\\begin{equation}\\label{eq:P_k-1_simple}\n",
    "    \\mathbf{P}_{k-1} = \\mathbf{P}_k + h \\left[ \\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1})\\right]^T \\mathbf{P}_k.\\quad (4)\n",
    "\\end{equation}\n",
    "\n",
    " то есть \n",
    "\n",
    "$$\n",
    "\\mathbf{P}_{k-1} = \\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_{k-1}} = \\mathbf{P}_k +  h W_{k-1}^{T} \\cdot \\left[ \\sigma' \\left(W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1} \\right) \\odot \\mathbf{P}_{k}\\right].\n",
    "$$\n",
    "\n",
    "Таким образом, мы пришли к $\\delta \\mathcal{J} = \\langle \\mathbf{P}_{K-1},\\delta \\mathbf{Y}_{K-1} \\rangle$. Продолжая аргументацию индуктивно, мы в конечном итоге найдем \n",
    "\n",
    "\\begin{equation}\\label{eq:del_J_compact}\n",
    "    \\delta \\mathcal{J} = \\langle \\mathbf{P}_{k+1},\\delta \\mathbf{Y}_{k+1} \\rangle.\\quad (5)\n",
    "\\end{equation}\n",
    "\n",
    "Поскольку $\\mathbf{Y}_{k+1} = \\mathbf{Y}_{k} + h \\sigma{\\left( W_{k} \\mathbf{Y}_{k} + b_{k} \\right)},$ мы можем написать \n",
    "\n",
    "\\begin{equation}\n",
    "    \\delta \\mathbf{Y}_{k+1} = h \\frac{\\partial \\sigma}{\\partial W} (W_{k} \\mathbf{Y}_{k} + b_{k}) \\delta W_k,\n",
    "\\end{equation}\n",
    "\n",
    "что можем подставить в уравнение (5), чтобы получить \n",
    "\n",
    "$$\n",
    "    \\delta \\mathcal{J} = \\left\\langle h \\left[ \\frac{\\partial \\sigma}{\\partial W} (W_{k} \\mathbf{Y}_{k} + b_{k})\\right]^T \\mathbf{P}_{k+1}, \\delta W_k \\right\\rangle.\n",
    "$$\n",
    "\n",
    "Теперь мы можем заключить, что градиент $\\mathcal{J}$ относительно $W_k$ задается как \n",
    "\n",
    "\\begin{equation}\\label{eq:delW}\n",
    "    \\frac{\\partial \\mathcal{J}}{\\partial W_k} = h \\left[ \\frac{\\partial \\sigma}{\\partial W} (W_{k} \\mathbf{Y}_{k} + b_{k})\\right]^T \\mathbf{P}_{k+1}. \n",
    "\\end{equation}\n",
    "\n",
    "Заметим, что $\\mathbf{P}_k$ необходим для вычисления $\\mathbf{P}_{k-1}$, поэтому мы сначала вычисляем $\\mathbf{P}$ для $k = K$, а затем переходим назад для всех $k < K$. Совершенно аналогичным образом мы получаем \n",
    "\n",
    "\\begin{equation}\\label{eq:delb}\n",
    "     \\frac{\\partial \\mathcal{J}}{\\partial b_k} = h \\left[ \\frac{\\partial \\sigma}{\\partial b} (W_{k} \\mathbf{Y}_{k} + b_{k})\\right]^T \\mathbf{P}_{k+1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Явная формула для $\\mathbf{P}_K$\n",
    "\n",
    "Чтобы получить $\\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_K}$, мы рассмотрим следующее (и заметим, что мы подавляем индекс $K$)\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d} \\epsilon} \\biggr\\lvert_{\\epsilon = 0} \\mathcal{J}(\\mathbf{Y} + \\epsilon \\delta \\mathbf{Y}) = \\frac{1}{2} \\frac{\\text{d}}{\\text{d} \\epsilon} \\biggr\\lvert_{\\epsilon = 0} \\left\\langle\n",
    "    \\mathbf{Z}(\\epsilon) - \\mathbf{c}, \\mathbf{Z}(\\epsilon) - \\mathbf{c}\n",
    "    \\right\\rangle\n",
    "    = \\left\\langle \\mathbf{Z}(0) - \\mathbf{c}, \\mathbf{Z}^\\prime(0) \\right\\rangle,\n",
    "$$\n",
    "\n",
    "где \n",
    "\n",
    "$$\n",
    "\\mathbf{Z}(\\epsilon) = \\eta\\left( \\left[\\mathbf{Y} + \\epsilon \\delta \\mathbf{Y})\\right]^T \\omega + \\mu \\mathbf{1}\\right).\n",
    "$$\n",
    "\n",
    "По правилу цепочки мы находим \n",
    "\n",
    "$$\n",
    "\\mathbf{Z}^\\prime(0) = \\eta^\\prime \\left( \\mathbf{Y}^T \\omega + \\mu \\mathbf{1}\\right) \\delta \\mathbf{Y}^T \\omega.\n",
    "$$\n",
    "\n",
    "Из этого следует, что \n",
    "\n",
    "$$\n",
    "    \\left\\langle \\mathbf{Z}(0) - \\mathbf{c}, \\mathbf{Z}^\\prime(0) \\right\\rangle = \\left\\langle \\omega \\left[ (\\mathbf{Z} - \\mathbf{c}) \\odot \\eta^\\prime \\left( \\mathbf{Y}^T \\omega + \\mu \\mathbf{1}\\right) \\right]^T, \\delta \\mathbf{Y}  \\right\\rangle,\n",
    "$$\n",
    "\n",
    "и выражение для $\\frac{\\partial \\mathcal{J}}{\\partial \\mathbf{Y}_K}$ следует. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод $\\mathbf{P}_{k-1}$\n",
    "\n",
    "Чтобы обосновать утверждение, что \\eqref{eq:P_k-1} следует из \\eqref{eq:P_k-1_simple}, достаточно показать, что \n",
    "\n",
    "$$\n",
    "    \\left[ \\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1})\\right]^T \\mathbf{P}_k = W_{k-1}^{T} \\cdot \\left[ \\sigma' \\left(W_{k-1} \\mathbf{Y}_{k-1} + b_{k-1} \\right) \\odot \\mathbf{P}_{k}\\right].\n",
    "$$\n",
    "\n",
    "Далее мы будем подавлять индекс слоев и резервировать индекс для \"компонентов\". \n",
    "\n",
    "\\begin{align*}\n",
    "    \\left\\langle \\left[ \\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (\\cdot) \\right]^T \\mathbf{P}, \\delta \\mathbf{Y} \\right\\rangle &= \\left\\langle \\mathbf{P}, \\frac{\\partial \\sigma}{\\partial \\mathbf{Y}} (\\cdot) \\delta \\mathbf{Y} \\right\\rangle = \\left\\langle \\mathbf{P}, \\frac{\\text{d}}{\\text{d}\\epsilon} \\biggr\\lvert_{\\epsilon = 0} \\sigma (W \\left( \\mathbf{Y} + \\epsilon \\delta\\mathbf{Y} \\right) + b ) \\right\\rangle \\\\\n",
    "    &= \\sum_{i,j,k} \\mathbf{P}_{ij} \\sigma^\\prime \\left( (W \\mathbf{Y} + b)_{ij}\\right) W_{ik} \\delta \\mathbf{Y}_{kj}  = \\sum_{k,j} \\delta \\mathbf{Y}_{kj} \\sum_{i} W_{ki}^{T} \\left[ \\mathbf{P} \\odot \\sigma^\\prime(W\\mathbf{Y} + b) \\right]_{ij} \\\\\n",
    "    &= \\left\\langle W^T \\left[ \\sigma^\\prime (W\\mathbf{Y} + b) \\odot \\mathbf{P} \\right], \\delta \\mathbf{Y} \\right\\rangle.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиенты относительно $W_k$ и $b_k$\n",
    "\n",
    "Чтобы получить окончательные уравнения для $\\frac{\\partial \\mathcal{J}}{\\partial W_k}$, мы начинаем с \\eqref{eq:delW} и снова подавляем индекс слоя. Затем мы находим \n",
    "\n",
    "\\begin{align*}\n",
    "    \\left\\langle \\frac{\\partial \\mathcal{J}}{\\partial W}, \\delta W \\right\\rangle &= \\left\\langle h \\left[ \\frac{\\partial \\sigma}{\\partial W} (W \\mathbf{Y} + b)\\right]^T \\mathbf{P}, \\delta W \\right\\rangle = h \\left\\langle \\mathbf{P}, \\frac{\\partial \\sigma}{\\partial W} (W \\mathbf{Y} + b) \\delta W \\right\\rangle\\\\\n",
    "    &= h \\left\\langle \\mathbf{P}, \\frac{\\text{d}}{\\text{d}\\epsilon} \\biggr\\lvert_{\\epsilon = 0} \\sigma ((W + \\epsilon \\delta W) \\mathbf{Y} + b ) \\right\\rangle \\\\\n",
    "    &= h \\sum_{i,j,k} \\mathbf{P}_{ij} \\sigma^\\prime ((W\\mathbf{Y} + b)_{ij}) \\delta W_{ik} \\mathbf{Y}_{kj} = h \\sum_{i,k} \\delta W_{ik} \\sum_{j} \\left[ \\mathbf{P} \\odot \\sigma^\\prime (W\\mathbf{Y} + b)\\right]_{ij} \\mathbf{Y}_{jk}^T \\\\\n",
    "    &= h \\left\\langle \\left[ \\mathbf{P} \\odot \\sigma^\\prime (W\\mathbf{Y} + b) \\right] \\mathbf{Y}^T, \\delta W \\right\\rangle.\n",
    "\\end{align*}\n",
    "\n",
    "Это показывает окончательную формулу для $\\frac{\\partial \\mathcal{J}}{\\partial W_k}$. Мы опускаем доказательство формулы для $\\frac{\\partial \\mathcal{J}}{\\partial b_k}$, так как она получена очень похожим образом."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
