{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>\n",
    "\n",
    "# Метод Гаусса-Зейделя\n",
    "\n",
    "### Modules - Partial Differential Equations\n",
    "<section class=\"post-meta\">\n",
    "By Henning G. Hugdal, Håkon W. Ånes and Jon Andreas Støvneng\n",
    "</section>\n",
    "Last edited: February 7th 2018 \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы рассмотрим метод решения линейной системы уравнений с использованием итерационного метода, называемого методом Гаусса-Зейделя [1]. Тот факт, что это итерационный метод, означает, что нужно много раз повторять алгоритм решения, чтобы получить ответ с точностью ниже заданного допуска. Это противоположно прямым методам, где одна итерация алгоритма дает решение напрямую. Однако алгоритм прямого метода может иметь определенные ограничения в отношении того, где они могут быть применены, что делает итерационные методы полезными во многих ситуациях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть линейная система уравнений\n",
    "$$ A {\\bf{x}} = {\\bf{b}}$$\n",
    "метод Гаусса-Зейделя основан на разложении $A$ на нижнюю диагональную матрицу $L$ и верхнюю диагональную матрицу $U$:\n",
    "$$\\begin{align}\n",
    " A = \\left(\\matrix{\n",
    " a_{11} & a_{12} & a_{13} & ...\\\\\n",
    " a_{21} & a_{22} & a_{23} & ...\\\\\n",
    " a_{31} & a_{32} & a_{33} & \\ddots \\\\\n",
    " \\vdots & \\vdots & \\vdots & \\ddots\n",
    " }\\right) = \\left(\\matrix{\n",
    " a_{11} & 0 & 0 & ...\\\\\n",
    " a_{21} & a_{22} & 0 & ...\\\\\n",
    " a_{31} & a_{32} & a_{33} & \\ddots \\\\\n",
    " \\vdots & \\vdots & \\vdots & \\ddots\n",
    " }\\right) + \\left(\\matrix{\n",
    " 0 & a_{12} & a_{13} & ...\\\\\n",
    " 0 & 0 & a_{23} & ...\\\\\n",
    " 0 & 0 & 0 & \\ddots \\\\\n",
    " \\vdots & \\vdots & \\vdots & \\ddots\n",
    " }\\right) \\equiv L + U\\\\\n",
    " \\phantom{+}\n",
    "\\end{align}$$\n",
    "Это можно использовать для получения $\\bf{x}$ на итерации $k+1$, используя решение из предыдущей итерации:\n",
    "$$ L{\\bf{x}}^{k+1} = {\\bf{b}} - U{\\bf{x}}^{k}.$$\n",
    "Если мы теперь посмотрим на уравнение для каждого элемента в ${\\bf{x}}$, мы получим\n",
    "$$\\begin{align}\n",
    "a_{11}x^{k+1}_1 &= b_1 - \\sum_{i=2} a_{1i}x^{k}_i \\quad \\Rightarrow \\quad x^{k+1}_1 = \\frac{b_1}{a_{11}} - \\frac{1}{a_{11}}\\sum_{i=2} a_{1i}x^{k}_i,\\\\\n",
    "a_{21}x^{k+1}_1 + a_{22}x^{k+1}_2 &= b_2 - \\sum_{i=3} a_{2i}x^{k}_i \\quad \\Rightarrow \\quad x^{k+1}_2 = \\frac{b_2}{a_{22}} - \\frac{1}{a_{22}}\\sum_{i=3} a_{2i}x^{k}_i - \\frac{a_{21}}{a_{22}}x_1^{k+1},\n",
    "\\end{align}$$\n",
    "и т.д. Здесь мы видим, что во второй строке используется значение $x_1^{k+1}$, найденное в строке выше. Из вышеизложенного мы можем вывести общий алгоритм, а именно, что значение $x_i^{k+1}$ находится с помощью\n",
    "$$x_i^{k+1} = \\frac{b_i}{a_{ii}} - \\frac{1}{a_{ii}}\\sum_{j>i} a_{ij} x_j^{k} - \\frac{1}{a_{ii}}\\sum_{j<i} a_{ij}x_j^{k+1}.$$\n",
    "Примечание: Если бы в последнем слагаемом у нас было $k$ вместо $k+1$, это соответствовало бы методу Якоби. Однако, поскольку мы здесь используем уже вычисленные новые значения везде, где это возможно, метод Гаусса-Зейделя сходится быстрее, чем метод Якоби.\n",
    "\n",
    "#### Первоначальное предположение\n",
    "Чтобы получить решение на итерации $k+1$, мы используем решение на итерации $k$. Но каково решение на итерации $k=0$? Это должно быть задано явно в качестве первоначального предположения! Хорошая догадка означает, что для получения точного решения требуется меньше итераций.\n",
    "\n",
    "\n",
    "#### Критерий остановки\n",
    "Но как мы узнаем, когда остановить итерацию? Один из вариантов - повторить заданное количество раз, несмотря ни на что, и сохранить полученное решение. Этот вариант имеет очевидные недостатки: во-первых, нет возможности узнать, насколько хорошо полученное решение. Во-вторых, может выйти огромная трата времени на 1000 итераций, в то время как решение было достаточно хорошим, например, после 300 итераций.\n",
    " \n",
    "Второй вариант - посмотреть, насколько сильно меняется решение от итерации к итерации, и прекратить итерацию, когда разница меньше заданного значения. Один из способов сделать это - установить критерий остановки в виде допустимой погрешности, умноженной на 2-норму разницы между первоначальным предположением и первой итерацией. 2-норма вектора ${\\bf{x}}$ задается\n",
    "$$||{\\bf x}||_2 = \\left(\\sum_{i=1}^n \\left|x_i\\right|^2\\right)^{1/2}.$$\n",
    "Хотя это может быть лучшим вариантом, чем выбор фиксированного числа итераций, это все равно будет не идеальным решением. Если, например, первоначальное предположение очень плохое, 2-норма разницы после первой итерации может быть очень большой, поэтому допустимая погрешность должна быть установлена очень низкой, чтобы получить хорошую точность. Это также означает, что метод должен сходиться, иначе мы получим бесконечное число итераций.\n",
    "\n",
    "\n",
    "#### Сходимость\n",
    "Метод Гаусса-Зейделя будет сходиться, когда матрица $A$ является диагонально доминирующей, т.е. если выполняются следующие условия:\n",
    "$$\\begin{align} a_{ii} &\\ge \\sum_{j\\ne i} |a_{ij}| \\qquad \\forall~i,\\\\\n",
    "\\exists~i:\\qquad a_{ii} &> \\sum_{j\\ne i} |a_{ij}|.\\end{align}$$\n",
    "Если это не выполняется, метод не гарантирует сходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Уравнение Лапласа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера использования метода Гаусса-Зейделя мы решим уравнение Лапласа в одном измерении с граничными условиями Дирихле с обеих сторон, т.е.\n",
    "$$ \\frac{d^2}{dx^2} f = 0$$\n",
    "с $f(0) = f_0 = 10$ и $f(1) = f_1 = 2$. Мы дискретизируем ось $x$, используя N+1 точек сетки: $x_i = i\\Delta_x$, где $\\Delta x = 1/(N+1)$ и $i\\in [0, N+1]$. Следовательно, мы хотим найти решение $f(x_i) = f_i$ для $i\\in[1, N]$. Мы используем центральные разности второго порядка для дискретизации второй производной,\n",
    "$$ \\frac{d^2}{dx^2} f(x_i)\\quad\\rightarrow\\quad \\frac{f_{i+1} - 2f_i + f_{i-1}}{\\Delta x^2}.$$\n",
    "\n",
    "Используя эту дискретизацию, мы можем записать уравнение Лапласа в виде линейной системы уравнений $A{\\bf{f}} = {\\bf b}$, где\n",
    "$$\\begin{align}\n",
    "A = \\left(\\matrix{\n",
    "2 & -1 & 0 & 0 & ...\\\\\n",
    "-1 & 2 & -1 & 0 & ...\\\\\n",
    "0 & -1& 2& -1 & ...\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n",
    "}\\right),\\\\\n",
    "\\phantom{+}\n",
    "\\end{align}$$\n",
    "а источник ${ \\bf b}$ будет обсуждаться ниже.\n",
    "Здесь мы умножили обе стороны уравнения Лапласа на $-\\Delta x^2$. Сначала мы проверяем, является ли $A$ матрицей с доминирующими диагоналями. \n",
    "\n",
    "Прежде всего,мы видим, что для всех строк, кроме первой и последней, у нас $|a_{ii}| = |a_{i, i+1}| + |a_{i, i-1}| = 2$. Следовательно, выполняется первое условие. Мы также видим, что для первой строки $|a_{11}| = 2 > |a_{12}| = 1$. Следовательно, справедливо и второе условие. Следовательно, $A$ является диагонально доминирующей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, особое внимание должно быть уделено случаям $i=1$ и $i=N$, так как тогда мы должны использовать граничные условия. Для $i=1$ в этом случае мы получаем константу $f_0$ с правой стороны. Аналогично, для $i=N$, мы получаем константу $f_1$ с правой стороны. Следовательно, вектор ${\\bf b}$ состоит только из $f_0$ в качестве первого элемента и $f_1$ в качестве последнего, $N$-элемента. Все остальные элементы равны нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Точное решение\n",
    "Точное решение уравнения Лапласа с заданными граничными условиями легко получить. Интегрируя дважды относительно $x$, мы получаем\n",
    "$$f(x) = Ax + B.$$\n",
    "Используя первое граничное условие, мы получаем $B = f_0 = 10$. На второй границе мы получаем $A+10 = 2$, т.е. $A = -8$. Следовательно, точное решение $f(x) = -8x+10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже мы импортируем необходимые библиотеки и определяем ${\\bf f}$ с помощью метода Гаусса-Зейделя. Чтобы увидеть, как решение сходится к точному решению, мы построим 2-норму разницы между точным решением и решением на итерации $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as datetime\n",
    "newparams = {\n",
    "    'figure.figsize': (16, 6), 'axes.grid': True,\n",
    "    'lines.linewidth': 1.5,\n",
    "    'font.size': 20\n",
    "    }\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество точек сетки\n",
    "N = 100\n",
    "dx = 1/(N+1)\n",
    "x = np.linspace(dx, 1-dx, N)\n",
    "\n",
    "# Точное решение\n",
    "f_e = -8*x+10\n",
    "\n",
    "# допустимая погрешность\n",
    "tol = 1e-6\n",
    "diff = 1\n",
    "it_error = []\n",
    "\n",
    "# Разница на первом проходе\n",
    "diff0 = 0\n",
    "\n",
    "# Граничные условия\n",
    "f0 = 10\n",
    "f1 = 2\n",
    "\n",
    "# Диагональные элементы\n",
    "d = 2\n",
    "\n",
    "# Off-diagonal elements\n",
    "e = -1\n",
    "\n",
    "# Инициализация матрицы\n",
    "A = np.zeros([N, N])\n",
    "for i in range(N):\n",
    "    A[i, i] = d\n",
    "    if i < N-1:\n",
    "        A[i, i+1] = e\n",
    "    if i > 0:\n",
    "        A[i, i-1] = e\n",
    "        \n",
    "\n",
    "# Инициализация вектор b\n",
    "b = np.zeros(N)\n",
    "b[0] = f0\n",
    "b[N-1] = f1\n",
    "        \n",
    "# Инициализация массива решений, используя нули в качестве начального предположения\n",
    "f = np.zeros(N)\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "while diff > tol*diff0:\n",
    "    f_new = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            f_new[i] = (b[i] - A[i, i+1]*f[i+1])/A[i, i]\n",
    "        elif i == N-1:\n",
    "            f_new[i] = (b[i] - A[i, i-1]*f_new[i-1])/A[i, i]\n",
    "        else:\n",
    "            f_new[i] = (b[i] - A[i, i+1]*f[i+1] - A[i, i-1]*f_new[i-1])/A[i, i]\n",
    "\n",
    "\n",
    "    # Определит 2-норму различий между итерациями\n",
    "    diff = np.sqrt(sum((f_new-f)**2))\n",
    "    \n",
    "    # 2-норма разности на первой итерации\n",
    "    if diff0 == 0:\n",
    "        diff0 = diff\n",
    "        \n",
    "    it_error.append(np.sqrt(sum((f_new-f_e)**2)))\n",
    "        \n",
    "    # Обновление f\n",
    "    f = f_new\n",
    "\n",
    "    n_iter += 1\n",
    "    \n",
    "print(\"Общее время, затраченное на итерации: \", datetime.now() - start)\n",
    "    \n",
    "print(\"Общее количество итераций: \", n_iter)\n",
    "\n",
    "print(\"2-норма разности между решением и точным решением: \", it_error[-1])\n",
    "\n",
    "x = np.linspace(0, 1, N+2)\n",
    "ftot = np.concatenate(([f0], f, [f1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, ftot)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f$')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(it_error)\n",
    "plt.xlabel('Iteration no.')\n",
    "plt.ylabel('Iteration error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из последнего графика мы видим, как отклонение от точного решения уменьшается с каждой итерацией.\n",
    "\n",
    "Мы можем сравнить результат с использованием функций в `numpy.linalg`, посмотрев на время, используемое для определения ${\\bf f}$, и на две нормы разницы между полученными решениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as linalg\n",
    "start = datetime.now()\n",
    "\n",
    "f_linalg = linalg.solve(A, b)\n",
    "\n",
    "print(\"Time elapsed: \", datetime.now() - start)\n",
    "\n",
    "# Определит 2-норму разности между решениями\n",
    "dev = np.sqrt(sum((f-f_linalg)**2))\n",
    "\n",
    "# Определит 2-норму между решением с использованием linalg и точным решением\n",
    "error = np.sqrt(sum((f_linalg-f_e)**2))\n",
    "\n",
    "print(\"2-норма разности между решениями: \", dev)\n",
    "print(\"2-норма разности между решением linalg и точным решением: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что при выбранной погрешности разница между решениями невелика, и что решение, полученное с помощью `solve`, очень близко к точному решению. Обратите также внимание, что время, прошедшее при использовании `linalg`, на 3-4 порядка меньше, чем при использовании итерационного метода!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References\n",
    "[1] R.H. Pletcher, J. C. Tannehill, D. Anderson. *Computational Fluid Mechanics and Heat Transfer*, CRC Press (2011)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
