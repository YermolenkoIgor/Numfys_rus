{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"pull-right\">\n",
    "<a href=\"http://numfys.net/examples\"><img src=\"https://www.numfys.net/static/img/favicon.ico\" style=\"height:60px; margin-top: 25px;\"></a>\n",
    "</div>\n",
    "\n",
    "# Простая фильтрация звука с использованием дискретного преобразования Фурье\n",
    "\n",
    "### Example – Waves and Acoustics \n",
    "By Jonas Tjemsland, Andreas Krogen, Håkon Ånes og Jon Andreas Støvneng.\n",
    "\n",
    "Last edited: May 20th 2016\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта тетрадь дает представление о работе со звуками на Python. Мы используем класс Python [wave](https://docs.python.org/2/library/wave.html). Изучите материал по ссылке, чтобы понять, как работают различные функции! Ближе к концу несколько звуковых дорожек фильтруются с использованием дискретных преобразований Фурье (DFT) и тригонометрического приближения наименьших квадратов.\n",
    "\n",
    "**ПРИМЕЧАНИЕ: Некоторые звуковые файлы могут быть немного громкими, и перед их воспроизведением рекомендуется уменьшить громкость.**\n",
    "\n",
    "Как всегда, мы начинаем с импорта необходимых библиотек и задаем общие параметры рисунка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import wave\n",
    "import IPython\n",
    "from scipy import fftpack as fft\n",
    "%matplotlib inline\n",
    "\n",
    "# Casting unitary numbers to real numbers will give errors\n",
    "# because of numerical rounding errors. We therefore disable \n",
    "# warning messages.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set common figure parameters\n",
    "newparams = {'axes.labelsize': 8, 'axes.linewidth': 1, 'savefig.dpi': 200,\n",
    "             'lines.linewidth': 1, 'figure.figsize': (8, 3),\n",
    "             'ytick.labelsize': 7, 'xtick.labelsize': 7,\n",
    "             'ytick.major.pad': 5, 'xtick.major.pad': 5,\n",
    "             'legend.fontsize': 7, 'legend.frameon': True, \n",
    "             'legend.handlelength': 1.5, 'axes.titlesize': 7,}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа со звуком\n",
    "\n",
    "Звук - это продольная волна в среде, такой как воздух или вода. Это вибрация, которая распространяется через среду в виде колебаний давления и перемещений частиц. Например, тон А - это звуковая волна частотой 440 Гц, создаваемая камертоном, динамиком, струной или другим устройством, которое заставляет воздух колебаться с заданной частотой. На компьютере звуки - это не что иное, как последовательность цифр. Данный тон может быть математически описан с помощью\n",
    "\n",
    "$$\n",
    "s(t)=A\\sin(2\\pi f t),\n",
    "$$\n",
    "\n",
    "где $A$ - амплитуда, $f$ - частота, а $t$ - время. В компьютере $s(t)$ оценивается в дискретные моменты времени, определяемые частотой дискретизации. Обычный аудиокод имеет частоту дискретизации 44100 Гц.\n",
    "\n",
    "Следующая функция создает мелодию с определенной частотой, длиной, амплитудой и частотой дискретизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone(frequency=440., length=1., amplitude=1., sampleRate=44100., soundType='int8'):\n",
    "    \"\"\" Returns a sine function representing a tune with a given frequency.\n",
    "    \n",
    "    :frequency: float/int. Frequency of the tone.\n",
    "    :length: float/int. Length of the tone in seconds.\n",
    "    :amplitude: float/int. Amplitude of the tone.\n",
    "    :sampleRate: float/int. Sampling frequency.\n",
    "    :soundType: string. Type of the elements in the returned array.\n",
    "    :returns: float numpy array. Sine function representing the tone.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0,length,int(length*sampleRate))\n",
    "    data = amplitude*np.sin(2*np.pi*frequency*t)\n",
    "    return data.astype(soundType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты давайте создадим ностальгический 8-битный звуковой файл mono wav. Обратите внимание, что 8-разрядные образцы хранятся как uint8 в диапазоне от 0 до 255, в то время как 16-разрядные образцы хранятся как int16 в диапазоне от -32768 до 32767. Другими словами, поскольку мы создаем аудиофайл с шириной выборки 8 бит, нам нужно добавить 128 к образцам, прежде чем мы запишем их в файл. Модуль wave автоматически изменится на uint8, если это не будет сделано, так что -128 станет 128, -127 станет 129 и так далее, и звуковой файл может быть несколько искажен. Спасибо Эйстейну Хиосену за то, что он указал на это! Если мы хотим использовать 16-битные образцы, нам не нужно беспокоиться об этом. Этот ноутбук поддерживает 8, 16 и 32-разрядные образцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that are being used in the start of this notebook\n",
    "sampleRate = 44100\n",
    "sampwidth = 1          # In bytes. 1 for 8 bit, 2 for 16 bit and 4 for 32 bit\n",
    "volumePercent = 50     # Volume percentage\n",
    "nchannels = 1          # Mono. Only mono works for this notebook\n",
    "\n",
    "# Some dependent variables\n",
    "shift = 128 if sampwidth == 1 else 0 # The shift of the 8 bit samples, as explained in the section above.\n",
    "soundType = 'i' + str(sampwidth)\n",
    "amplitude = np.iinfo(soundType).min*volumePercent/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for a A tone lasting 1 second at a sample\n",
    "frequency = 440\n",
    "length = 1\n",
    "\n",
    "# Calculate the sine function for the given parameters\n",
    "data = tone(frequency, length, amplitude, sampleRate, soundType)\n",
    "\n",
    "# Plot the function\n",
    "plt.plot(data)\n",
    "plt.xlim([0,2000])\n",
    "plt.title('Visualization of the A tone')\n",
    "plt.xlabel('Sample number')\n",
    "\n",
    "# Open a new .wav-file in \"write\" mode, set file parameters\n",
    "# and write to file\n",
    "data += shift # Shift the samplings if we use 8 bit\n",
    "with wave.open('Atone.wav', 'w') as file:\n",
    "    file.setparams((nchannels, sampwidth, sampleRate, 0, 'NONE', ''))\n",
    "    file.writeframes(data)\n",
    "\n",
    "# Display the sound file\n",
    "IPython.display.Audio('Atone.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем создать \"ритм\", позволив двум волнам разной частоты интерферировать. Тогда биение будет иметь частоту, равную абсолютному значению разницы в частоте двух волн, $f = \\left|f_2 - f_1\\right|$. Вы можете прочитать больше о частотах биений на великой [Гиперфизике](http://hyperphysics.phy-astr.gsu.edu/hbase/sound/beat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 400\n",
    "frequency2 = 408\n",
    "length = 5\n",
    "\n",
    "# Calculate the sine function for the given parameters\n",
    "data = ( tone(frequency, length, amplitude, sampleRate,soundType) +\n",
    "         tone(frequency2, length, amplitude, sampleRate,soundType) )\n",
    "\n",
    "# Plot the function\n",
    "plt.plot(data)\n",
    "plt.xlim([0,20000])\n",
    "plt.title('Visualization of beat')\n",
    "plt.xlabel('Sample number')\n",
    "\n",
    "# Create sound file\n",
    "data += shift\n",
    "with wave.open('beat.wav','w') as file:\n",
    "    file.setparams((nchannels, sampwidth, sampleRate, 0, 'NONE', ''))\n",
    "    file.writeframes(data)\n",
    "\n",
    "IPython.display.Audio('beat.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя эти концепции, мы действительно можем создать простую мелодию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"function\" to translate from a given tone to its frequency\n",
    "baseTone = 130.813  # The frequecy of the tone C3, bass C\n",
    "tones = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'Bb', 'B',\n",
    "         'Ch','C#h','Dh','D#h','Eh','Fh','F#h','Gh','G#h','Ah','Bbh','Bh']\n",
    "# And use dictionary comprehension to fill in the frequencies\n",
    "notes2freq = {tones[i]: baseTone*2**(i/12) for i in range(0,len(tones))}\n",
    "\n",
    "# The meldody data saved as a list of tuples (note, duration)\n",
    "l = 2.\n",
    "notes = [('D',0.083*l),('D',0.083*l),('D',0.083*l),('G',0.5*l),('Dh',0.5*l),('Ch',0.083*l),\n",
    "         ('B',0.083*l),('A',0.083*l),('Gh',0.5*l),('Dh',0.25*l),('Ch',0.083*l),('B',0.083*l),\n",
    "         ('A',0.083*l),('Gh',0.5*l),('Dh',0.25*l),('Ch',0.083*l),('B',0.083*l),('Ch',0.083*l),\n",
    "         ('A',0.5*l),('D',0.167*l),('D',0.083*l),('G',0.5*l),('Dh',0.5*l),('Ch',0.083*l),\n",
    "         ('B',0.083*l),('A',0.083*l),('Gh',0.5*l),('Dh',0.25*l),('Ch',0.083*l),('B',0.083*l),\n",
    "         ('A',0.083*l),('Gh',0.5*l),('Dh',0.25*l),('Ch',0.083*l),('B',0.083*l),('Ch',0.083*l),\n",
    "         ('A',0.5*l),('D',0.167*l),('D',0.083*l),('E',0.375*l),('E',0.125*l),('Ch',0.125*l),\n",
    "         ('B',0.125*l),('A',0.125*l),('G',0.125*l),('G',0.083*l),('A',0.083*l),('B',0.083*l),\n",
    "         ('A',0.167*l),('E',0.083*l),('F#',0.25*l),('D',0.167*l),('D',0.083*l),('E',0.375*l),\n",
    "         ('E',0.125*l),('Ch',0.125*l),('B',0.125*l),('A',0.125*l),('G',0.125*l),\n",
    "         ('Dh',0.1875*l),('A',0.0625*l),('A',0.5*l),('D',0.167*l),('D',0.083*l),('E',0.375*l),\n",
    "         ('E',0.125*l),('Ch',0.125*l),('B',0.125*l),('A',0.125*l),('G',0.125*l),('G',0.083*l),\n",
    "         ('A',0.083*l),('B',0.083*l),('A',0.167*l),('E',0.083*l),('F#',0.25*l),('Dh',0.167*l),\n",
    "         ('Dh',0.083*l),('Gh',0.125*l),('Fh',0.125*l),('D#h',0.125*l),('Ch',0.125*l),\n",
    "         ('Bb',0.125*l),('A',0.125*l),('G',0.125*l),('Dh',0.75*l)]\n",
    "\n",
    "# Create the file data\n",
    "data = np.array([],dtype=soundType)\n",
    "for note, duration in notes:\n",
    "    currentFrequency = notes2freq[note]\n",
    "    currentTone = tone(currentFrequency, duration, amplitude, sampleRate, soundType)\n",
    "    data = np.append(data, currentTone)\n",
    "data += shift\n",
    "with wave.open('melody.wav','w') as file:\n",
    "    file.setparams((nchannels, sampwidth, sampleRate, 0, 'NONE', ''))\n",
    "    file.writeframes(data)\n",
    "\n",
    "IPython.display.Audio('melody.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Красивое.\n",
    "\n",
    "### Теорема о выборке Найквиста-Шеннона и сглаживание\n",
    "\n",
    "Прежде чем двигаться дальше, мы должны кратко обсудить теорему о выборке Найквиста-Шеннона. Как упоминалось ранее, когда мы имеем дело с цифровым звуком, нам необходимо сделать плавный звуковой сигнал дискретным. Это достигается путем дискретизации сигнала в дискретные моменты времени. Количество выборок в единицу времени описывается частотой дискретизации, и интуитивно понятно, что частота дискретизации должна сильно зависеть от частот сигнала.\n",
    "\n",
    "Теорема выборки Найквиста-Шеннона гласит, что для восстановления сигнала частота дискретизации должна быть более чем в два раза больше максимальной частоты сигнала (часто называемой критерием однозначного представления) [3]. C. E. Шеннон сформулировал ее как [4]:\n",
    "\n",
    "> Если функция $f(t)$ не содержит частот выше $W$ Гц, она полностью определяется путем указания ее координат в ряде точек, расположенных на расстоянии $1/(W/2)$ секунд друг от друга.  \n",
    "\n",
    "Поскольку диапазон человеческого слуха составляет от 20 до 20 000 Гц, частота дискретизации 44100 Гц обычных компакт-дисков вполне понятна.\n",
    "\n",
    "Сглаживание описывает эффект, который приводит к тому, что различные сигналы становятся неразличимыми. Например, если частота samling равна $W$, частоты $f$ и $W-f$ неразличимы. Это означает, что самая высокая частота, которую можно представить с помощью частоты дискретизации $W$, равна $W/2$, часто называемой частотой Найквиста. Более того, все частоты ниже $W/2$ будут отражаться примерно на $W/2$. Это наглядно показано ниже.\n",
    "\n",
    "Далее мы создадим аудиофайл, в котором частота постепенно увеличивается с 0 Гц до частоты дискретизации, выбранной на уровне 5000 Гц. Как мы быстро замечаем, то, что мы слышим, - это не постепенное увеличение частоты, которого мы интуитивно ожидаем, а постепенное увеличение частоты, за которым следует постепенное снижение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = 5000\n",
    "length = .5\n",
    "\n",
    "# Calculate the sine function for the given parameters\n",
    "data = np.array([],dtype=soundType)\n",
    "for frequency in np.linspace(0, sampleRate, 20):\n",
    "    currentTone = tone(frequency, length, amplitude, sampleRate, soundType)\n",
    "    data = np.append(data, currentTone)\n",
    "data += shift\n",
    "with wave.open('aliasing.wav','w') as file:\n",
    "    file.setparams((nchannels, sampwidth, sampleRate, 0, 'NONE', ''))\n",
    "    file.writeframes(data)\n",
    "\n",
    "IPython.display.Audio('aliasing.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют способы удалить некоторые псевдонимы (сглаживание), но это не рассматривается в этой записной книжке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Звуки в частотной области\n",
    "\n",
    "Если мы выполняем DFT звуковой дорожки в пространственной области [амплитуда $s(t)$], результат можно интерпретировать как функцию, описывающую $s(t)$ в соответствующей частотной области. (Это более подробно объясняется в нашей [записной книжке по DFTs](https://nbviewer.jupyter.org/url/www.numfys.net/media/notebook/mo_b2_discrete_fourier_transform.ipynb).) Таким образом, если DFT выполняется для тона A, мы получим пик при $f=440$ Гц. Кроме того, и пики будут отражаться примерно на половине частоты дискретизации (из-за теоремы о выборке Найквиста-Шеннона). Кроме того, из-за сглаживания мы получим некоторые пики при $f=(440 + 880 \\cdot n)$ Гц, $n=0,1,...$. Поскольку тоны конечны и из-за ошибок численного округления мы также получим некоторое добавление шума к некоторому увеличению амплитуды, близкой к пикам. Шум и сглаживание становятся меньше, если мы используем большую ширину самлинга.\n",
    "\n",
    "Давайте построим тон A в частотной области, взяв $\\log \\mathcal F [s(t)](f)$. Мы сдвигаем два квадранта и определяем начало координат с частотой, равной половине частоты дискретизации, что облегчает фильтрацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = 44100\n",
    "length = 1\n",
    "frequency = 440\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "subplot = 0\n",
    "for sampwidth in [1,2,4]:\n",
    "    # Calculate the data for the given sample width\n",
    "    soundType = 'i' + str(sampwidth)\n",
    "    amplitude = np.iinfo(soundType).min*volumePercent/100.\n",
    "    data = tone(frequency, length, amplitude, sampleRate, soundType)\n",
    "    # Use DFT to tranform the data into the frequency domain\n",
    "    dataFreq = np.log(fft.fftshift(fft.fft(data)))\n",
    "    # Plot the results\n",
    "    subplot += 1\n",
    "    plt.subplot(3,1,subplot)\n",
    "    plt.plot(np.linspace(-0.5*sampleRate, 0.5*sampleRate, len(dataFreq)), dataFreq)\n",
    "    plt.xlim([-0.5*sampleRate, 0.5*sampleRate])\n",
    "    plt.title('Frequency domain of the %d bit A tone' %(sampwidth*8))\n",
    "plt.xlabel('Frequency, [Hz]')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из концепции, представленной до сих пор, легко понять, как можно отфильтровать определенные частоты.\n",
    "\n",
    "### Пример: Фильтрация определенных частот\n",
    "\n",
    "Теперь мы собираемся отфильтровать 16-битный звуковой файл [`spock_bad.wav`](https://www.numfys.net/media/spock_bad.wav)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'spock_bad'\n",
    "IPython.display.Audio(filename + '.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wave.open(filename + '.wav', 'rb') as file:\n",
    "    data = file.readframes(-1)\n",
    "    sampleRate = file.getframerate()\n",
    "    sampwidth = file.getsampwidth()\n",
    "    \n",
    "soundType = 'i' + str(sampwidth)\n",
    "\n",
    "data = np.fromstring(data, soundType)\n",
    "n = len(data)\n",
    "\n",
    "# Perform the DFT\n",
    "dataFreq = fft.fftshift(fft.fft(data))\n",
    "\n",
    "# Plot the sound file in the spatial domain\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.linspace(0, n/sampleRate, n), data)\n",
    "plt.title('Spatial domain of %s' % filename)\n",
    "plt.xlabel('Time, [s]')\n",
    "plt.xlim([0, n/sampleRate])\n",
    "\n",
    "# Plot the sound file in the frequency domain\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.linspace(-0.5*sampleRate, 0.5*sampleRate, n), np.log(np.abs(dataFreq)))\n",
    "plt.title('Frequency domain of %s' % filename)\n",
    "plt.xlabel('Frequency, [Hz]')\n",
    "plt.xlim([-0.5*sampleRate, 0.5*sampleRate])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы наблюдаем пики на частотах около $f=\\{100, 200, 1000, 5000\\}$ Хз. Поэтому мы пытаемся отфильтровать их и прислушаться к результату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 100  # Width of the removing intervals\n",
    "# Filter out the frequencies in the frequency domain\n",
    "for f in [100, 200, 1000, 5000]:\n",
    "    dataFreq[int(n/2 + n*f/sampleRate - w) : int(n/2 + n*f/sampleRate + w)] = 0\n",
    "    dataFreq[int(n/2 - n*f/sampleRate - w) : int(n/2 - n*f/sampleRate + w)] = 0\n",
    "\n",
    "# Transform the filtered frequency domain back to the spatial domain\n",
    "data = fft.ifft(fft.fftshift(dataFreq))\n",
    "data = data.astype(soundType)\n",
    "\n",
    "# Save the filtered data to a new file\n",
    "with wave.open(filename + '_filtered.wav', 'w') as A, \\\n",
    "    wave.open(filename + '.wav', 'rb') as file:\n",
    "    A.setparams(file.getparams())\n",
    "    A.writeframes(data.real)\n",
    "\n",
    "# Plot the filtered sound in the spatial domain\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.linspace(0, n/sampleRate, n), data)\n",
    "plt.title('Spatial domain of %s' % (filename + '_filtered'))\n",
    "plt.xlabel('Time, [s]')\n",
    "plt.xlim([0, n/sampleRate])\n",
    "\n",
    "# Plot the filtered sound in the frequency domain\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.linspace(-0.5*sampleRate, 0.5*sampleRate, n), np.log(np.abs(dataFreq)))\n",
    "plt.title('Frequency domain of %s' % (filename + '_filtered'))\n",
    "plt.xlabel('Frequency, [Hz]')\n",
    "plt.xlim([-0.5*sampleRate, 0.5*sampleRate])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Play the filtered sound file\n",
    "IPython.display.Audio(filename + '_filtered.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Фильтрация низких и высоких частот\n",
    "\n",
    "В этом примере мы проверим, что делает идеальный фильтр нижних частот и идеальный фильтр высоких частот со звуковым файлом. Эти фильтры удаляют сигналы с частотами выше частоты среза и ниже частоты среза соответственно. Эти фильтры чаще всего неидеальны, но эти типы фильтров здесь не обсуждаются. Фильтры ослабляют частоты выше или ниже заданного значения среза. Мы используем звуковой файл [`vena.wav`](https://www.numfys.net/media/vena.wav)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vena.wav'\n",
    "IPython.display.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idealLowpass(data, cutoff, sampleRate=44100):\n",
    "    \"\"\" Removes all frequencies above a given cutoff value of\n",
    "    a mono sound file described by an array of data and a samle\n",
    "    frequency.\n",
    "    \n",
    "    :data: float numpy array. The data of a sound file.\n",
    "    :cutoff: float/int. Cutoff value.\n",
    "    :sampleRate: int. The sampling frequency of the sound file.\n",
    "    :returns: float numpy array. Filtered sound data.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    dataFreq = fft.fftshift(fft.fft(data))\n",
    "    dataFreq[0 : int(n/2 -n*cutoff/sampleRate)] = 0\n",
    "    dataFreq[int(n/2 + n*cutoff/sampleRate) : len(dataFreq)] = 0\n",
    "    data = fft.ifft(fft.fftshift(dataFreq))\n",
    "    return data.real\n",
    "\n",
    "def idealHighpass(data, cutoff, sampleRate):\n",
    "    \"\"\" Removes all frequencies below a given cutoff value of\n",
    "    a mono sound file described by an array of data and a samle\n",
    "    frequency.\n",
    "    \n",
    "    :data: float numpy array. The data of a sound file.\n",
    "    :cutoff: float/int. Cutoff value.\n",
    "    :sampleRate: int. The sampling frequency of the sound file.\n",
    "    :returns: float numpy array. Filtered sound data.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    dataFreq = fft.fftshift(fft.fft(data))\n",
    "    dataFreq[int(n/2 - n*cutoff/sampleRate) : int(n/2 + n*cutoff/sampleRate)] = 0\n",
    "    data = fft.ifft(fft.fftshift(dataFreq))\n",
    "    return data.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from sound file\n",
    "with wave.open(filename, 'rb') as file:\n",
    "    data = file.readframes(-1)\n",
    "    sampleRate = file.getframerate()\n",
    "    sampwidth = file.getsampwidth()\n",
    "soundType = 'i' + str(sampwidth)\n",
    "data = np.fromstring(data, soundType)\n",
    "n = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы начинаем с применения фильтра нижних частот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the lowpass filter\n",
    "cutoff = 500\n",
    "dataLowpass = idealLowpass(data, cutoff, sampleRate)\n",
    "\n",
    "# Save the filtered sound\n",
    "with wave.open('Vena_lowpass.wav', 'w') as A, \\\n",
    "    wave.open(filename, 'rb') as file:\n",
    "    A.setparams(file.getparams())\n",
    "    A.writeframes(dataLowpass.astype(soundType))\n",
    "\n",
    "# Play the filtered sound\n",
    "IPython.display.Audio('Vena_lowpass.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы можете слышать, все высокие частоты исчезли, и мы остались с басовыми тонами. Обратите внимание, например, что мы больше не слышим высоких шляп и бубна.\n",
    "\n",
    "Теперь мы применяем фильтр высоких частот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the highpass filter\n",
    "cutoff = 500\n",
    "dataHighpass = idealHighpass(data, cutoff, sampleRate)\n",
    "\n",
    "# Save the filtered sound\n",
    "with wave.open('Vena_highpass.wav', 'w') as A, \\\n",
    "    wave.open(filename, 'rb') as file:\n",
    "    A.setparams(file.getparams())\n",
    "    A.writeframes(dataHighpass.astype(soundType))\n",
    "\n",
    "# Play the filtered sound\n",
    "IPython.display.Audio('Vena_highpass.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь все наоборот; все низкие частоты исчезли, и мы больше не слышим басовых тонов.\n",
    "\n",
    "### Пример: Удаление белого шума (случайный шум)\n",
    "\n",
    "В этом примере мы собираемся отфильтровать белый шум, используя тригонометрическое приближение наименьших квадратов. Это приближение объясняется в нашей записной книжке [trigonometric interpolation](https://nbviewer.jupyter.org/url/www.numfys.net/media/notebooks/mo_curve2_trigonometric_interpolation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastSquaresTrig(x, m, N):\n",
    "    \"\"\" Calculates a trigonometric polynomial of degree n/2 (n even) or\n",
    "    (n-1)/2 (n odd) that interpolates a set of n real data points. The\n",
    "    data points can be written as (t_i,x_i), i=0,1,2,..., where t_i are \n",
    "    equally spaced in the interval [c,d].\n",
    "    \n",
    "    :x: complex or float numpy array. Data points.\n",
    "    :c: float. Interval start. t[0].\n",
    "    :d: float. Interval end. t[n-1].\n",
    "    :returns: float numpy array.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    if not 0<=m<=n<=N:\n",
    "        raise ValueError('Is 0 <= m <= n <= N?')\n",
    "    y = fft.fft(x)\n",
    "    yp = np.zeros(N, np.complex64)\n",
    "    m2 = int(m/2)\n",
    "    yp[0:m2] = y[0:m2]\n",
    "    yp[N - m2 + 1:N] = y[n - m2 + 1:n]\n",
    "    if (m % 2):\n",
    "        yp[m2] = y[m2]\n",
    "    else:\n",
    "        yp[m2] = np.real(y[m2])\n",
    "    if m<n and m>0:\n",
    "        yp[N-m2] = yp[m2]\n",
    "    return np.real(fft.ifft(yp))*N/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the sound file [`comet_noise.wav`](https://www.numfys.net/media/comet_noise.wav)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'comet_noise.wav'\n",
    "IPython.display.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wave.open(filename, 'rb') as file:\n",
    "    data = file.readframes(-1)\n",
    "    sampleRate = file.getframerate()\n",
    "    sampwidth = file.getsampwidth()\n",
    "soundType = 'i' + str(sampwidth)\n",
    "data = np.fromstring(data, soundType)\n",
    "data = leastSquaresTrig(data, len(data)/14, len(data))\n",
    "\n",
    "with wave.open('comet_filtered.wav', 'w') as A, \\\n",
    "    wave.open(filename, 'rb') as file:\n",
    "    A.setparams(file.getparams())\n",
    "    A.writeframes(data.astype(soundType))\n",
    "\n",
    "IPython.display.Audio('comet_filtered.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что белый шум больше не слышен, но это за счет качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "All the sound files are collected from http://tos.trekcore.com/.\n",
    "\n",
    "[1] H. P. Langtangen: \"A primer on scientific programming with Python\", 4th edition, p. 621-627, Springer 2014  \n",
    "[2] R Nave: \"Beats\", http://hyperphysics.phy-astr.gsu.edu/hbase/sound/beat.html  \n",
    "[3] C. E. Shannon: \"Communication in the presence of noise\", Proc. Institute of Radio Engineers, vol. 37, no.1, p. 10–21, 1949.  \n",
    "[4] Wikipedia: \"Audio bit depth\", https://en.wikipedia.org/wiki/Audio_bit_depth, 10th May 2016 [acquired: 11th May 2016]  \n",
    "[5] Wikipedia: \"Nyquist–Shannon sampling theorem\", https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem, 9th May 2016 [acquired: 11th May 2016]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
