{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>\n",
    "\n",
    "# Томография\n",
    "\n",
    "## Examples – Biophysics\n",
    "<section class=\"post-meta\">\n",
    "By Jonas Tjemsland, Håkon Ånes, Andreas Krogen og Jon Andreas Støvneng.\n",
    "</section>\n",
    "Last edited: January 20th 2019\n",
    "\n",
    "___\n",
    "This notebook is based on an assignment given in the course *TMA4320 Introduction to Scientific Computation* at NTNU in April 2016 [[1]](#rsc). The assignment was prepared by Pål Erik Goa, Jon Andreas Støvneng, Peder Galteland and Grunde Wesenberg. The code is based on the answers by Gjert Magne Knutsen, Daniel Halvorsen and Jonas Tjemsland.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступление\n",
    "\n",
    "Медицинская визуализация занимает центральное место в современной диагностике. [Рис. 1](#img1) ниже показано поперечное сечение головы, основанное на так называемой *компьютерной томографии* (КТ). В этом блокноте мы получаем представление о том, как компьютерная томография использует рентгеновские лучи для восстановления довольно четких изображений. Мы будем использовать изображения в оттенках серого размером $N\\times N$, которые представлены матрицей $N\\times N$. Значение каждого элемента матрицы будет представлять \"серость\" пикселя ($1$ для белого и $0$ для черного). В конце мы будем использовать инструменты, разработанные на уроке [Фильтрация изображений с использованием преобразования Фурье](https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/image_filtering_using_fourier_transform.ipynb) чтобы получить более четкое изображение.\n",
    "<a id=\"img1\"></a>\n",
    "<body>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/0/04/Brain_CT_scan.jpg\"  width=250px, alt=\"CT scan of the brain\"/>  \n",
    "\n",
    "**Рисунок 1:** *Аксиальная компьютерная томография головного мозга [[2]](#rsc).*\n",
    "\n",
    "Чтобы полностью понять и оценить результаты, мы начнем с теории. Нетерпеливому читателю рекомендуется перейти к разделу *Простой пример*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import numpy as np\n",
    "import scipy.fftpack as fft\n",
    "from skimage import io\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set some figure parameters\n",
    "newparams = {'axes.labelsize': 9, 'axes.linewidth': 1, 'savefig.dpi': 200,\n",
    "             'lines.linewidth': 1, 'figure.figsize': (8, 3),\n",
    "             'ytick.labelsize': 7, 'xtick.labelsize': 7,\n",
    "             'ytick.major.pad': 5, 'xtick.major.pad': 5,\n",
    "             'legend.fontsize': 9, 'legend.frameon': True, \n",
    "             'legend.handlelength': 1.5, 'axes.titlesize': 9, 'figure.dpi': 200,\n",
    "             'mathtext.fontset': 'stix', 'font.family': 'STIXGeneral'}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Рентген\n",
    "\n",
    "Рентгеновские лучи представляют собой электромагнитное излучение в диапазоне длин волн от $0.01$ до $10\\:\\mathrm{нм}$, соответствующее энергиям между $100\\:\\mathrm{эВ}$ и $100\\:\\mathrm{кэВ}$. Фотоны могут, например, генерироваться в вакуумных лампах. В вакуумной трубке электроны испускаются с нагретого катода и ускоряются к аноду электрическим полем, создаваемым ускоряющим высоким напряжением. Излучение может создаваться различными физическими механизмами. Например, ускоренный электрон может выбить электрон с одной из внутренних орбиталей атома анода. Электрону, находящемуся в состоянии с более высокой энергией, затем разрешается занять это пустое состояние и по пути туда испустить фотон. Этот фотон имеет характеристическую энергию, равную разности энергий между двумя электронными орбиталями, или состояниями, в атоме анода. Такой переход из второго низшего состояния в состояние с наименьшей энергией называется $K_\\alpha$, и его энергия приблизительно описывается *законом Мозли*,\n",
    "\n",
    "$$\n",
    "E(K_\\alpha)=10.2 \\:\\mathrm{eV}\\cdot (Z-1)^2,\n",
    "$$\n",
    "\n",
    "где $Z$ - атомный номер материала анода. Вольфрам ($W; Z=74$) дает энергию $E(K_\\alpha) = 54.4\\:\\mathrm{keV}$, немного ниже экспериментального значения $59.3\\:\\mathrm{keV}$.\n",
    "\n",
    "В дополнение к этому характерному рентгеновскому излучению наблюдается непрерывный спектр с четко определенной минимальной длиной волны. Это происходит из-за *разрушающего излучения* или *тормозного излучения* и происходит, по существу, во всех ситуациях, когда заряженные частицы ускоряются в электрических полях, создаваемых другими частицами. В рентгеновской трубке ускоренные электроны замедляются, когда они сталкиваются с атомами в материале анода. Данный электрон может максимально передать всю свою кинетическую энергию $E_k$ одному фотону. Это означает, что возбужденный фотон имеет длину волны, большую или равную\n",
    "\n",
    "$$\n",
    "\\lambda_{min}=\\frac{hc}{E_k},\n",
    "$$\n",
    "\n",
    "где $E_k = \\mathrm{eV}$ определяется напряжением $V$ между катодом и анодом. Здесь $h$ - постоянная Планка, $\\mathrm{e}$ - элементарный заряд, а $c$ - скорость света.\n",
    "\n",
    "В действительности КТ использует фотоны как от характерного излучения, так и от тормозного излучения. Для простоты мы предположим, что фотон имеет определенную энергию, скажем, 60 кэВ, что примерно совпадает с излучением $K_\\alpha$ от вольфрама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Затухание\n",
    "\n",
    "Пусть объект (например, человеческая голова) облучается рентгеновскими лучами (или любым другим типом электромагнитного излучения) с заданной интенсивностью $I$. Часть рентгеновских фотонов пройдет через объект без изменений. Остальные фотоны будут либо поглощены, либо рассеяны атомами. Вероятность поглощения или рассеяния будет сильно зависеть как от энергии фотона, так и от характеристик материала объекта. Для заданной энергии фотона относительное уменьшение интенсивности $\\mathrm{d}I/I$ на единицу длины $\\mathrm{d}t$ , имеет вид\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}I/I}{\\mathrm{d}t}=-\\mu,\n",
    "$$\n",
    "\n",
    "где $\\mu$ - *коэффициент линейного затухания*. $\\mu$ является высоким для твердых и плотных тканей, низким для мягких тканей (обычно с высоким содержанием воды) и приблизительно нулевым для воздуха. Для фотонов с энергией $60\\:\\mathrm{keV}$ у нас будет $\\mu\\approx 600\\: \\mathrm{m}^{-1}$ для костей и $\\mu\\approx 20\\:\\mathrm{m}^{-1}$ для мягких тканей.\n",
    "\n",
    "Интенсивность $I$, прохождения через детектор, получается из приведенного выше уравнения,\n",
    "\n",
    "$$\n",
    "I=I_0\\exp\\left\\{-\\int_{t_1}^{t_2}\\mu(t)\\;\\mathrm{d}t\\right\\}.\n",
    "$$\n",
    "\n",
    "Этот интеграл называется *проекцией*. Его значение будет зависеть от того, где рентгеновский луч попадает на объект, обозначенный $s$, и как объект ориентирован относительно направления луча, обозначенного $\\theta$.\n",
    "\n",
    "$$\n",
    "p(s,\\theta)=\\ln(I_0/I)=\\int_{t_1}^{t_2}\\mu(t)\\mathrm{d}t.\n",
    "$$\n",
    "\n",
    "Обратите внимание, что $\\mu$, $t_1$ и $t_2$ зависят от $s$ и $\\theta$, как показано на [рис. 2](#fig2) ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка\n",
    "\n",
    "Рентгеновские лучи посылаются тонкими (по существу одномерными) лучами в направлении объекта, подлежащего отображению. Используя несколько лучей, расположенных рядом, мы можем, по существу, изучать горизонтальное поперечное сечение объекта. Мы собираемся проанализировать, как информация об объекте может быть извлечена из таких экспериментов. Другими словами, как мы можем реконструировать поперечное сечение?\n",
    "\n",
    "<a id=\"fig2\"></a>\n",
    "<img src=\"images/tomography_setup.png\" width=500px, alt=\"Source and detector schematic diagram.\">\n",
    "\n",
    "**Рисунок 2:** *Источник и детектор повернуты на угол $\\theta$ относительно объекта. Координата $s$ указывает, где рентгеновский луч (пунктирные линии) попадает на объект. Координата $t$ определяет направление луча. Для $\\theta=0$, $t$ совпадает с осью $y$. Луч входит в объект при $t=t_1$ и покидает объект при $t=t_2$. Функция $f(x,y)$ представляет распределение различных видов тканей внутри объекта. В общем, мы можем думать о $f(x,y)$ как о цвете в оттенках серого в позиции $(x,y)$.*\n",
    "\n",
    "Из [Рис. 2](#рис. 2) мы получаем соотношение\n",
    "\n",
    "$$\n",
    "s=x\\cos\\theta + y\\sin \\theta,\n",
    "$$\n",
    "\n",
    "таким образом, линия проекции для конкретных значений $s$ и $\\theta$ может быть записана как \n",
    "\n",
    "$$\n",
    "y(x;s,\\theta)=-x\\cot\\theta +\\frac{s}{\\sin\\theta}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнение измерения\n",
    "\n",
    "Измеряя проекции для $s$-значений, которые охватывают весь объект, и для $\\theta$-значений, которые охватывают все возможные ориентации объекта ($\\theta \\geq 180^\\circ$), мы получаем матрицу $\\{p(s,\\theta)\\}$ – так называемую *синограмму*. Синограмма содержит в принципе всю информацию, необходимую для реконструкции распределения тканей объекта $f(x,y)$. Но чтобы извлечь эту информацию, мы должны использовать форму томографической реконструкции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение обратной проекции\n",
    "\n",
    "Из синограммы мы можем построить *прямую обратную проекцию* $g(x,y)$. Заданная проекция $p(s,\\theta)$ дает нам значение интеграла $f(x,y)$ на прямой, которая попадает на объект в положении $s$ для заданной ориентации $\\theta$. Лучшее, что мы можем сделать (без дополнительной информации о $f(x, y)$), - это предположить, что значение интеграла равномерно распределено между $t_1$ и $t_2$, учитывая, что\n",
    "\n",
    "$$\n",
    "g(x,y;s,\\theta)=\\frac{p(s,\\theta)}{t_2-t_1}.\n",
    "$$\n",
    "\n",
    "Это, конечно, можно сделать для всех значений $\\theta$ и $s$. Если мы позволим $x$ и $y$ быть фиксированными и добавим все значения $g(x,y;s,\\theta)$, мы получим $g(x, y)$. Если это сделать для всех $(x,y)$, мы получим прямое обратное проецируемое изображение.\n",
    "\n",
    "Как вы, возможно, догадались, обратное проецируемое изображение будет размытой версией исходного изображения. Кроме того, сейчас, возможно, было бы неплохо сделать паузу и взглянуть на изображения, представленные ниже, прежде чем продолжить чтение, чтобы визуализировать то, что было сказано до сих пор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простой пример\n",
    "\n",
    "Мы начнем с простого примера на сетке $3\\times 3$, описываемой матрицей $3\\times 3$. Рассмотрим объект,состоящий из квадратной кости ( $f(x, y)=1$; белый), окруженной мягкой тканью ( $f(x,y)=0$; черный). Мы начинаем с генерации синограммы с использованием углов $\\theta=\\{0,\\pi/2\\}$. В разделе \"Получение обратной проекции\" выше, посмотрите, можете ли вы найти ответ (или, по крайней мере, визуализировать ответ) на эти вопросы:\n",
    "\n",
    "* Каковы три проекции при $\\theta = 0$? То есть $p(m,0)$ с $m=1$ для 1 столбца и т.д.\n",
    "* Каковы три проекции при $\\theta = \\pi/2$? То есть $p(m,\\pi/2)$ с $m=1$ для первой строки и т.д.\n",
    "* Каково изображение, которое вы получаете при прямой обратной проекции из этих шести проекций?\n",
    "\n",
    "Теперь мы выполняем вычисления и строим график результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [[0, 0, 0], [0, 1, 0], [0, 0, 0]]\n",
    "m, n = np.shape(f)\n",
    "\n",
    "# Calculate the six projections for theta={0,pi/2}\n",
    "pRow = np.sum(f, 1) # theta = pi/2\n",
    "pCol = np.sum(f, 0) # theta = 0\n",
    "\n",
    "# Calculate the direct back projection\n",
    "g = np.zeros((m, n))\n",
    "for row in range(0, m):\n",
    "    g[row, :] = pRow[row]/m + pCol[:]/n\n",
    "\n",
    "# Normalise (strictly not necessary)\n",
    "g = np.sum(f)*g/np.sum(g)\n",
    "\n",
    "# Visualise the result\n",
    "plt.subplot(121)\n",
    "plt.imshow(f, cmap='gray', interpolation='nearest')\n",
    "plt.title('Model object');\n",
    "plt.subplot(122)\n",
    "plt.imshow(g, cmap='gray', interpolation='nearest')\n",
    "plt.title('Back projection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание синограммы\n",
    "\n",
    "Для простоты мы будем считать, что исходное изображение имеет $N\\times N$ пикселей, где $N$ равно 2.\n",
    "\n",
    "Теперь мы создаем функцию, которая вычисляет синограмму для произвольного $N$ и количества углов $\\theta$. Пусть количество проекций равно $2N-1$ (количество диагоналей), так что каждый пиксель подсчитывается только один раз, когда $\\theta = \\pi/4$. Для произвольного $\\theta$ мы выбираем, чтобы каждый пиксель использовался только в одной проекции.\n",
    "\n",
    "Трудная часть состоит в том, чтобы выяснить, какой пиксель $(i, j)$ принадлежит данной проекции $(s,\\theta)$. Это делается путем проверки того, какая проекция ближе всего к данному пикселю. Конечно, есть несколько способов сделать это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinogram(img, Ntheta):\n",
    "    \"\"\"Create a sinogram of an image.\n",
    "    \n",
    "    Parameters:\n",
    "        img:    array-like, shape (N, N). Image.\n",
    "        Ntheta: int. Number of projection angles in radians between 0 and pi/2\n",
    "    Returns: \n",
    "        NumPy-array, shape (2*N-1, Ntheta). Sinogram.\n",
    "    \"\"\"\n",
    "    M, N = np.shape(img)\n",
    "    assert(M == N)\n",
    "    Ndiag = 2*N - 1;               # Number of projections (diagonals)\n",
    "    p = np.zeros((Ndiag, Ntheta)); # Allocate memory for the sinogram\n",
    "    # Create a meshgrid for the pixels (x - N/2, y - N/2)\n",
    "    A = (2*np.arange(1, N + 1) - N - 1)/2\n",
    "    [x, y] = np.meshgrid(A, A)\n",
    "    # Calculate the projection for Ntheta number of angles (theta) between 0 and pi/2,\n",
    "    # which is stored in the sinogram, p\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for k in bar(range(0, Ntheta)):\n",
    "        theta = k*np.pi/Ntheta # Current angle\n",
    "        # Find the projection number to each pixel for the given angle\n",
    "        m = np.round(N + np.sqrt(2)*(x*np.cos(theta) + y*np.sin(theta)))\n",
    "        # Iterate through each projection and put the pixels in the right place in\n",
    "        # the sinogram\n",
    "        for i in range(0, N):\n",
    "            for j in range(0, N):\n",
    "                p[int(m[i][j]) - 1][k] = p[int(m[i][j] - 1), k] + img[i][j]; # Add to sinogram\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание прямой обратной проекции\n",
    "\n",
    "Теперь мы создаем функцию,которая вычисляет прямую обратную проекцию $g(x, y)$. Вклад данной проекции $p(s_m,\\theta_n)$ в пиксель $(i,j)$ равен $p(s_m,\\theta_n)/M$, где $M$ - количество пикселей, принадлежащих этой проекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_projection(p):\n",
    "    \"\"\" Create a direct back projection of a sinogram created in a similar\n",
    "    fashion as in the sinogram() function above. The original image is assumed\n",
    "    to be an N x N matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        p: array-like, shape (2*N-1, Ntheta). Sinogram.\n",
    "    Returns: \n",
    "        NumPy-array, shape (N, N). Sinogram.\n",
    "    \"\"\"\n",
    "    Ndiag, Ntheta = np.shape(p) # Number of projections and projection angles\n",
    "    N = int((Ndiag + 1)/2)      # The size of the original image (assumed N x N)\n",
    "    g = np.zeros((N, N))        # Allocate memory for the back projection\n",
    "    # Create a meshgrid for the pixels (x - N/2, y - N/2)\n",
    "    A = (2*np.arange(1, N + 1) - N - 1)/2\n",
    "    [x, y] = np.meshgrid(A, A)\n",
    "    # Compute the back projection\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for k in bar(range(0, Ntheta)):\n",
    "        theta = k*np.pi/Ntheta  # Current angle\n",
    "        # The projection number to each pixel for the given angle\n",
    "        m = np.round(N + np.sqrt(2)*(x*np.cos(theta) + y*np.sin(theta)));\n",
    "        m = np.array(m, 'int')\n",
    "        # Compute a vector holding the number of pixels belonging to each\n",
    "        # of the Ndiag projections\n",
    "        M = np.zeros(Ndiag);\n",
    "        for i in range(0, int(N)):\n",
    "            for j in range(0, int(N)):\n",
    "                M[m[i, j] - 1] += 1\n",
    "        # Iterate through each pixel and add the corresponding projection\n",
    "        # value divided by the number of pixels in this projection\n",
    "        for i in range(0, int(N)):\n",
    "            for j in range(0, int(N)):\n",
    "                g[i][j] += p[m[i][j] - 1, k]/M[m[i][j] - 1]\n",
    "    # Divide by the number of projections, such that the total pixel value\n",
    "    # of the original image and the direct back projection are equal\n",
    "    g = g/Ntheta\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример – известное исходное изображение\n",
    "\n",
    "### Создание синограммы и прямой обратной проекции\n",
    "\n",
    "Теперь у нас есть необходимые инструменты для создания синограммы из (в оттенках серого) изображения $(N, N)$, где $N=2$. Давайте приведем пример со знаменитым фантомом Шеппа-Логана [[3]](#rsc). Изображение $128\\times 128$ можно найти [здесь](https://www.numfys.net/media/notebooks/images/phantom_128.png) и изображение $256 \\times 256$, можно найти [здесь](https://www.numfys.net/media/notebooks/images/phantom_256.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.imread('images/phantom_256.png', as_grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sinogram(f, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = back_projection(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original image\n",
    "plt.subplot(131)\n",
    "plt.imshow(f, cmap='gray', interpolation='nearest')\n",
    "plt.title('Original image, $f(x,y)$')\n",
    "\n",
    "# Plot sinogram\n",
    "plt.subplot(132)\n",
    "m, n = np.shape(p)\n",
    "plt.imshow(p, cmap='gray', aspect=n/m, interpolation='nearest')\n",
    "plt.title(r'Sinogram, $p(s,\\theta)$')\n",
    "\n",
    "# Plot direct back projection\n",
    "plt.subplot(133)\n",
    "plt.imshow(g, cmap='gray', interpolation='nearest')\n",
    "plt.title('Direct back projection, $g(x,y)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка погрешности\n",
    "\n",
    "Теперь, когда известно исходное изображение, мы можем оценить ошибку в прямой обратной проекции. Мы будем использовать *среднеквадратичное отклонение* (среднеквадратичное значение) в качестве оценки ошибки\n",
    "\n",
    "$$\n",
    "RMS=\\frac{1}{n}\\sqrt{\\sum_{\\{i,j\\}}^n\\left[f(i,j)-g(i,j)\\right]^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS(f, g):\n",
    "    \"\"\" Calculate the root mean square deviation of two N x N numpy arrays f and g. \"\"\"\n",
    "    return np.sqrt(np.sum((f - g)**2))/len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error estimate: RMS = %.5f%%' % (RMS(f, g)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока и ошибка, и визуальный результат довольно плохие, и трудно распознать какие-либо детали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация результата\n",
    "\n",
    "Теперь мы можем отфильтровать прямую обратную проекцию и попытаться получить более четкое изображение. Это может быть достигнуто с помощью инструментов, разработанных в вышеупомянутом блокноте [фильтрация изображений](https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/image_filtering_using_fourier_transform.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(image): return np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "def IFFT(spectrum): return np.fft.ifft2(np.fft.fftshift(spectrum))\n",
    "\n",
    "def filter_spectrum(spectrum, filter_type=None, val=50):\n",
    "    n, m = np.shape(spectrum)\n",
    "    y, x = np.meshgrid(np.arange(1, m + 1), np.arange(1, n + 1))\n",
    "    R2 = ((x - n/2)**2 + (y - m/2)**2)\n",
    "    if (filter_type == 'lowpass'):\n",
    "        return spectrum*(R2 <= val**2)\n",
    "    elif (filter_type == 'highpass'):\n",
    "        return spectrum*(R2 >= val**2)\n",
    "    elif (filter_type == 'gaussian_highpass'):\n",
    "        return spectrum*(1 - np.exp(-val*R2))\n",
    "    elif (filter_type == 'gaussian_lowpass'):\n",
    "        return spectrum*np.exp(-val*R2)\n",
    "    elif (filter_type != None):\n",
    "        raise ValueError('%s is not a valid filter!' % filter_type)\n",
    "    return spectrum\n",
    "\n",
    "def visualise(image, spectrum, title='', title_img='', title_spec='', cmap='gray'):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.title(title_img)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.log(abs(spectrum)), cmap=cmap)\n",
    "    plt.title(title_spec)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно использовать фильтр высоких частот на изображении, чтобы получить более четкий результат; например, идеальный фильтр высоких частот или фильтр высоких частот Гаусса. Последнее дает более плавный результат, поэтому мы используем его. Поиграйте с различными фильтрами (и добавьте новые) и постарайтесь получить лучший результат!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier transform of the back projection\n",
    "spectrum = FFT(g)\n",
    "\n",
    "# Visualise the result\n",
    "visualise(g, spectrum, title_img='Input image', title_spec='Spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_spectrum = filter_spectrum(spectrum, 'gaussian_highpass', 0.01)\n",
    "filtered_g = np.real(IFFT(filtered_spectrum))\n",
    "\n",
    "# As a trick, we set all pixels below a specific value to zero to get\n",
    "# a sharper result\n",
    "val = 0\n",
    "filtered_g = filtered_g*(filtered_g > val) + val*(filtered_g < val) - val\n",
    "\n",
    "# Visualise the result\n",
    "visualise(filtered_g, filtered_spectrum, title_img='Filtered image',\n",
    "          title_spec='Filtered spectrum')\n",
    "\n",
    "# \"Normalise\" the filtered image\n",
    "filtered_g = filtered_g*np.sum(f)/np.sum(filtered_g)\n",
    "# Print the error estimate\n",
    "print(RMS(f, filtered_g)*100)\n",
    "print('Error estimate: RMS = %.5f%%' % (RMS(f, filtered_g)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат намного лучше, чем прямая обратная проекция, как визуально, так и в отношении среднеквадратичного отклонения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример – неизвестное исходное изображение\n",
    "\n",
    "При реальной компьютерной томографии исходное изображение неизвестно, но синограмма есть. Теперь мы используем то, что мы узнали до сих пор, чтобы попытаться получить исходное изображение из синограммы. Мы сделали три синограммы доступными на нашем веб-сайте, чтобы вам было с чем поиграть: [sinogram_1.png](https://www.numfys.net/media/notebooks/images/sinogram_1.png), [sinogram_2.png](https://www.numfys.net/media/notebooks/images/sinogram_2.png), [sinogram_3.png](https://www.numfys.net/media/notebooks/images/sinogram_3.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = io.imread('images/sinogram_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.transpose(back_projection(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sinogram\n",
    "plt.subplot(121)\n",
    "m, n = np.shape(p)\n",
    "plt.imshow(p, cmap='gray', aspect=n/m, interpolation='nearest')\n",
    "plt.title(r'Sinogram, $p(s,\\theta)$')\n",
    "\n",
    "# Plot the direct back projection\n",
    "plt.subplot(122)\n",
    "plt.imshow(g, cmap='gray', interpolation='nearest')\n",
    "plt.title('Direct back projection, $g(x,y)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы видите, кто это? Давайте выполним ту же фильтрацию, что и ранее, и посмотрим, сможем ли мы получить более четкое изображение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier transform of the back projection\n",
    "spectrum = FFT(g)\n",
    "\n",
    "# Filter the spectrum\n",
    "filtered_spectrum = filter_spectrum(spectrum, 'gaussian_highpass', 0.01)\n",
    "\n",
    "# Inverse Fourier Transform\n",
    "filtered_g = np.real(IFFT(filtered_spectrum))\n",
    "\n",
    "# Set all pixels with a negative value to zero\n",
    "filtered_g = filtered_g*(filtered_g > 0)\n",
    "\n",
    "# Set all pixels with a value over a certain value to val\n",
    "val = 4\n",
    "filtered_g = filtered_g*(filtered_g <= val) + val*(filtered_g > val)\n",
    "\n",
    "# Visualise the result\n",
    "plt.imshow(filtered_g, cmap='gray', interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы видите, кто это?\n",
    "___\n",
    "\n",
    "## Дальнейшая работа и улучшения\n",
    "\n",
    "* Что такое *теорема о проекционном срезе*? Как ее можно использовать для аргументации того, как выглядят фильтры?\n",
    "* Как можно обобщить этот блокнот для работы с произвольным изображением $N \\times M$?\n",
    "* Как мы можем выполнить те же вычисления на круглом изображении?\n",
    "* Мы использовали простые и интуитивно понятные алгоритмы для вычисления синограммы и прямой обратной проекции. Попробуйте найти какие-нибудь более сложные алгоритмы. Найдите, например, *преобразование радона* или проверьте [TomoPy](https://github.com/tomopy/tomopy).\n",
    "\n",
    "<a id=\"rsc\"></a>\n",
    "## Источники и дальнейшее чтение\n",
    "\n",
    "<a>[1]</a> Project description in Norwegian, https://wiki.math.ntnu.no/_media/tma4320/2016v/tomografi.pdf, acquired: 2016-10-21.\n",
    "\n",
    "<a>[2]</a> A CT scan of an anonymous brain. Provided by Aaron G. Filler, MD, PhD. Image source: https://en.wikipedia.org/wiki/File:Brain_CT_scan.jpg\n",
    "\n",
    "<a>[3]</a> Shepp, Larry; B. F. Logan (1974). *The Fourier Reconstruction of a Head Section*. IEEE Transactions on Nuclear Science. NS-21 (3): 21–43. Figure downloaded from https://commons.wikimedia.org/wiki/File:SheppLogan_Phantom.svg [acquired 2 Nov, 2016]."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
