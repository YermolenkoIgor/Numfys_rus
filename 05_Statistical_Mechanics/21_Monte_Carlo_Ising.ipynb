{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>\n",
    "\n",
    "# Равновесное моделирование методом Монте - Карло двумерной модели Изинга\n",
    "\n",
    "## Examples - Statistical Mechanics\n",
    "<section class=\"post-meta\">\n",
    "By Niels Henrik Aase, Asle Sudbø, Eilif Sommer Øyre, and Jon Andreas Støvneng\n",
    "</section>\n",
    "Last edited: September 29nd 2019\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступление\n",
    "\n",
    "Модель Изинга, пожалуй, является наиболее тщательно исследованной моделью в статистической физике. Основными причинами этого являются ее простота и тот факт, что она имеет аналитическое решение на двумерной бесконечной квадратной решетке, что делает ее отличным эталоном для схем численных расчетов. Это решение [[1]](#rsc) было разработано Нобелевским лауреатом Ларсом Онсагером в 1944 году, бывшим студентом NTNU, что делает проект особенным для нас в NumFys. Модель Изинга является единственным нетривиальным примером фазового перехода, который может быть строго доказан [[2]](#rsc). Однако доказательство выходит далеко за рамки этого проекта.\n",
    "\n",
    "Любопытный читателя вывод удельной теплоты можно найти в статье Ларса Онсагера [[1]](#rsc). Выражение для спонтанной намагниченности также было найдено Онсагером, но вывод этого выражения никогда не публиковался. Онсагер просто заявил об этом на конференции в Корнельском университете в 1948 году, а четыре года спустя К. Н.Янг опубликовал вывод того же результата [[3]](#rsc).\n",
    "\n",
    "В этом блокноте мы будем использовать метод Монте-Карло, возможно, самый важный вычислительный статистический алгоритм во всей физике. Это хорошо согласуется с лежащей в основе физической системой, поскольку модель Изинга была одной из самых важных моделей в статистической физике в прошлом веке. Таким образом, это тема, в которой вы можете узнать много важных принципов, касающихся алгоритмов и вычислений, которые все еще очень актуальны сегодня!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Модель Изинга\n",
    "\n",
    "Модель Изинга уже обсуждалась в предыдущем [блокноте](https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/ising_model.ipynb), но некоторые результаты стоит повторить. Модель Изинга представляет магнитные дипольные моменты атомных спинов. Спины могут находиться в двух состояниях: +1 или -1. Спины взаимодействуют только со своим ближайшим соседом через параметр взаимодействия $J_{ij}$.\n",
    "\n",
    "Рассмотрим решетку $ N \\times N $, где $s_{i}$ обозначает спин на узле $i$. Мы допускаем различные взаимодействия вдоль столбцов и строк решетки, где мы обозначаем взаимодействие между спинами вдоль строк как $J$ и между спинами вдоль столбцов $J'$. Без потери общности мы предполагаем, что магнитное поле $\\vec{B}$ имеет вид $\\vec{B} = (0 ,0 , B)$ и что дипольные моменты имеют вид $s_i = (0, 0, \\pm 1)$. Тогда гамильтониан системы становится \n",
    "\n",
    "\\begin{equation}\n",
    "H = - \\sum_{<i,j>} J_{ij} s_i s_j - B\\sum_{i} s_i,\n",
    "\\label{Hamiltonian} \\quad(1)\n",
    "\\end{equation}\n",
    "где $B$ - магнитное поле. Первое суммирование выполняется по ближайшим соседям каждой точки решетки, в то время как второе суммирование выполняется по всем точкам решетки $N^2$. Взаимодействие между ближайшими соседями описывается с помощью $J$ и $J'$.\n",
    "\n",
    "Затем задается статфункция\n",
    "\\begin{equation}\n",
    "Z = \\sum_{\\{s_i\\}}  e^{-\\beta H},\n",
    "\\label{Partition} \\quad(2)\n",
    "\\end{equation}\n",
    "где суммирование происходит по возможным состояниям системы, а $\\beta$ - множитель Лагранжа, равный $\\frac{1}{k_B T}$. $k_B$ - постоянная Больцмана, а $T$ - температура. С этого момента мы устанавливаем $k_B = 1$, так что $\\beta$ - это просто обратная температура. Мы также предпочитаем в основном игнорировать единицы вычисляемых величин.\n",
    "\n",
    "Число возможных состояний увеличивается непостижимо быстро, когда мы увеличиваем размер решетки. Суммирование содержит $2^{N^2}$ членов, поэтому для $N=6$ нам нужно суммировать более 68 719 476 736 спиновых конфигураций. В предыдущем [блокноте модели Изинга](https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/ising_model.ipynb), сумма была рассчитана точно, и, используя высокоскоростной язык, такой как Fortran, можно смоделировать решетки $5 \\times 5$ за разумное время. Однако решение Онсагера справедливо только для решетки $N \\times \\infty$, поэтому нам нужен другой метод для моделирования более крупных систем, которые представляют больший интерес. В этом блокноте мы будем использовать метод Монте-Карло, а более конкретно алгоритм Метрополиса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм Метрополиса\n",
    "\n",
    "Алгоритм Метрополиса - это, пожалуй, самый известный алгоритм Монте-Карло. В нашем случае мы будем использовать его для аппроксимации математических ожиданий системы, т.е. макроскопических и измеримых значений, таких как удельная теплоемкость, $c$ или намагниченность, $m$. Мы разделим объяснение алгоритма на две части, сначала мы сосредоточимся на реализации одной развертки Монте-Карло, а затем объясним, как следует проводить измерения системы. Последняя, пожалуй, самая тонкая и продвинутая часть блокнота.\n",
    "\n",
    "#### Реализация\n",
    "\n",
    "1. Инициализация конфигурации вращения. В нашем случае начальная конфигурация спина будет случайной, соответствующей высокотемпературной начальной конфигурации.\n",
    "2. Вычисление энергии конфигурации, используя (1)\n",
    "3. Выбор случайного участка $i$ на решетке и вычисление энергии конфигурации, если $s_i \\rightarrow -s_i$. Затем вычисление изменения энергии всей конфигурации, $\\Delta E$.\n",
    "4. Если $\\Delta E$ отрицательна, принять изменение конфигурации спина, разрешив $s_i \\rightarrow -s_i$.\n",
    "5. Если $\\Delta E$ неотрицательна, сгенерировать случайное число $r \\in \\big \\langle 0, 1 \\big \\rangle$. Если $e^{-\\beta \\Delta E} > r$, изменить конфигурацию вращения, разрешив $s_i \\rightarrow -s_i$.\n",
    "6. Повторить процесс $N^2$ раз. Это определяет одну развертку Монте-Карло, $t$.\n",
    "\n",
    "Подводя итог, можно сказать, что *будет* принято действие, которое уменьшает энергию конфигурации спина, в то время как шаг, который увеличивает энергию, *может будет* принят.\n",
    "\n",
    "Важно отметить, что случайный, недетерминированный характер моделирования по методу Монте-Карло означает, что, хотя две модели имеют одинаковую начальную конфигурацию спина и внешние параметры, две модели будут развиваться по-разному, поэтому не волнуйтесь, если ваши результаты будут отличаться от моделирования к моделированию.\n",
    "\n",
    "Несмотря на то, что мы используем стохастическое суммирование, этот алгоритм будет требователен к вычислениям для более крупной системы, его сложность масштабируется как $N^2$. Общее время выполнения программы будет зависеть от выполнения огромного количества разверток Монте-Карло, в нашем случае в диапазоне до 600 000 разверток для $N=256$, что соответствует выполнению шагов 1-5 примерно $10^{11}$ раз! Если мы дополнительно моделируем для разных температур, мы запускаем самые основные части нашего алгоритма триллионы раз. Для этого требуется чрезвычайно эффективная функция развертки Монте-Карло. К счастью, есть некоторые вещи, которые мы можем сделать, чтобы улучшить время выполнения.\n",
    "\n",
    "Мы в основном занимаемся вычислением средней намагниченности на спин системы, $<m>$. \n",
    "\n",
    "$$ \n",
    "<m> = \\frac{1}{N^2} \\sum_{i}<s_i>, \n",
    "$$\n",
    "и удельная теплоемкость при постоянном поле $C_B$ на спин. Через классическую статистическую физику и термодинамику можно показать, что $C_B$ равна\n",
    "\n",
    "$$\n",
    "\\frac{C_B}{k_B} = \\big[ \\langle (\\beta H )^2 \\rangle - \\langle (\\beta H) \\rangle ^2 \\big] = \\mathrm{Var}[\\beta H]. \n",
    "$$\n",
    "\n",
    "Этот фантастический и удивительный результат показывает, что удельная теплоемкость полностью определяется флуктуациями энергии (т.е. дисперсией энергии системы)! Важно отличать математическое ожидание (обозначаемое $<m>$) намагниченности от фактической намагниченности данной конфигурации спина, $m$. К сожалению, эти два слова часто используются взаимозаменяемо. Это связано с тем, что средняя намагниченность - это макроскопическая величина, которую мы измеряем с помощью экспериментов, и хотя мы строго говорим о средней намагниченности $<m>$, мы часто просто обозначаем ее $m$. Это обозначение мы будем использовать для остальной части блокнота.\n",
    "\n",
    "Начнем с простейшего случая-средней намагниченности на спин $m$. Чтобы вычислить это, мы вычисляем намагниченность решетки после каждой развертки, а затем вычисляем среднее значение. Однако для этого требуется, чтобы сумма $\\sum_{i} s_i$ была рассчитана $N^2$ раз за развертку, что является слишком трудоемкой операцией. Эту операцию можно значительно упростить, отметив, что изменение $m$ зависит только от изменения спина на случайном сайте $k$, $s_k \\rightarrow-s_k$. Обозначая новое и старое состояние системы как $\\nu$ и $\\mu$, мы наблюдаем, что\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta m = m_{\\nu} - m_{\\mu} = \\sum_{i} s_i^{\\nu} - \\sum_{i} s_i^{\\mu} = s_k^{\\nu} - s_k^{\\mu} = 2 s_k^{\\nu}, \n",
    "\\label{Delta_m}\n",
    "\\end{equation}\n",
    "\n",
    "где $s_k^{\\nu}$ и $s_k^{\\mu}$ обозначают вращение на сайте $k$ после и до изменения вращения. Все остальные члены в двух суммациях отменяются (потому что $s_k$ - это единственный спин, который изменяется, когда система переходит из состояния $\\mu$ в состояние $\\nu$). Таким образом, нам нужно вычислить $m$ только один раз, а затем каждый раз, когда спин переворачивается, т.е. $s_k \\rightarrow-s_k$, мы находим обновленную намагниченность по \n",
    "\n",
    "$$\n",
    "m_{\\nu} = m_{\\mu} + 2 s_k^{\\nu}.\n",
    "$$\n",
    "\n",
    "Изменение энергии немного сложнее, но применяется тот же принцип: каждый раз, когда меняется спин, это влияет только на конфигурацию спина локально, нам не нужно пересматривать всю решетку. Из уравнения (1) мы можем вычислить изменение энергии\n",
    "\n",
    "$$\n",
    "\\Delta E = E_{\\nu} - E_{\\mu} = - \\sum_{<i,j>} J_{ij} s_i^{\\nu} s_j^{\\nu} - B\\sum_{i} s_i^{\\nu} + \\sum_{<i,j>} J_{ij} s_i^{\\mu} s_j^{\\mu} + B\\sum_{i} s_i^{\\mu} = - \\big( \\sum_{i \\, \\mathrm{ n.n\\, to } \\, k} J_{ik} s_i^{\\mu} (s_k^{\\nu} - s_k^{\\mu}) \\big) - 2 B s_k^{\\nu}, \n",
    "$$\n",
    "где мы использовали уравнение (2) для оценки суммирования с участием $B$. Взаимодействия с ближайшими соседями более сложны, но мы наблюдаем, что только ближайшие соседи сайта $k$ релевантны для вычисления $\\Delta E$, все остальные взаимодействия отменяются. Выражение можно еще больше сократить, отметив, что $(s_k^{\\nu} - s_k^{\\mu}) = - 2 s_k^{\\mu}$ и что $s_k^{\\mu}$ можно вытащить за пределы суммы. Окончательное выражение для $\\Delta E$ может быть выражено следующим образом \n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta E = s_k^{\\mu} \\big( \\sum_{i \\, \\mathrm{ n.n\\, to } \\, k} J_{ik} s_i^{\\mu}\\big) - 2 B s_k^{\\nu}.\n",
    "\\label{Delta_E}\n",
    "\\end{equation}\n",
    "\n",
    "Упрощения допустимы в любом количестве измерений, где количество измерений определяет количество членов в суммировании. В нашем случае, когда мы рассматриваем двумерную систему, суммирование содержит четыре члена.\n",
    "\n",
    "Вы можете заметить, что почти все вычисления включают только целые числа, единственными исключениями являются случайное число $r$ и экспоненты. Для данной комбинации $J$, $J'$ и $B$ существует конечное число возможных значений $\\Delta E$, таким образом, можно сохранить возможные экспоненциальные значения $e^{-\\beta \\Delta E}$ в начале моделирования, поэтому для любого $\\Delta E$ мы знаем $e^{-\\beta \\Delta E}$ без необходимости вычислять его! Это не делается в нашем коде, но это еще больше улучшит время выполнения, потому что все вычисления, за исключением $r$, будут включать только целые числа, которые обычно намного быстрее, чем вычисления с действительными числами.  \n",
    "\n",
    "Как упоминалось ранее, почти все время выполнения будет потрачено на запуск этого алгоритма до 600 000 раз. Алгоритм имеет временную сложность , которая масштабируется как $O(N2)$, поэтому код должен быть чрезвычайно эффективным. Именно поэтому мы решили запустить эту часть кода через Fortran, который обеспечивает превосходную вычислительную скорость, улучшая время выполнения в 200 раз. Для полноты картины мы также покажем, как можно было бы реализовать алгоритм на Python, так как легче понять, как алгоритм работает на языке высокого уровня, таком как Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация на Python\n",
    "\n",
    "Как мы увидим позже, существует только аналитическое решение для термодинамических величин на бесконечной решетке. Решение Ларса Онсагера справедливо только для $B = 0$, а аналитическое решение для $B \\neq 0$ еще не найдено. По этой причине мы решили установить $B=0$, а также установить $J = J' = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "%matplotlib inline\n",
    "\n",
    "newparams = {'figure.figsize': (15, 7), 'axes.grid': False,\n",
    "             'lines.markersize': 10, 'lines.linewidth': 2,\n",
    "             'font.size': 15, 'mathtext.fontset': 'stix',\n",
    "             'font.family': 'STIXGeneral', 'figure.dpi': 200}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamiltonian(S, B= 0, J_v= 1, J_p=1):\n",
    "    \"\"\"Given a lattice configuration (i.e. a spin matrix) S, and the parameters B, J_v and J_p, this functions\n",
    "     returns the energy of the lattice.\n",
    "        \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            E: Energy of the lattice\n",
    "    \"\"\"\n",
    "    B_contribution = B * np.sum(S) # Energy of the spin configuration resulting from an external magnetic field\n",
    "    \n",
    "    # Using np.roll here automatically satisifies the periodic boundary conditions (PBCs).\n",
    "    J_v_contribution = J_v * np.sum(S * np.roll(S, 1, axis= 0)) # Energy resulting from lattice interactions along columns\n",
    "    J_p_contribution = J_p * np.sum(S * np.roll(S, 1, axis= 1)) # Energy resulting from lattice interactions along rows\n",
    "    E = - (J_v_contribution + J_p_contribution + B_contribution)\n",
    "    return E\n",
    "\n",
    "\n",
    "def delta_Hamiltonian(S, i, k, N, B = 0, J_v = 1, J_p = 1):\n",
    "    \"\"\"Calculates the energy change of the lattice if lattice site S[i][k] changes it's spin, in accordance\n",
    "    to the simplifications in the theory part.\n",
    "        \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            i, k: indicates the lattice site\n",
    "            N: Number of columns and rows in the lattice\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            delta_E: The energy change\n",
    "        \"\"\"\n",
    "    # Here we use the modulo operator to accomodate the PBCs \n",
    "    nn = J_p * (S[(i + 1) % N][k] + S[i - 1][k]) + J_v * (S[i][(k + 1) % N] + S[i][k - 1])\n",
    "    delta_E = 2 * S[i][k] * (nn + B)\n",
    "    return delta_E\n",
    "\n",
    "\n",
    "def Attempt_flip(S, beta, i, k, N, r, B = 0, J_v = 1, J_p = 1):\n",
    "    \"\"\"The central part of the Metropolis algorithm. Calculates the energy change at a random lattice site, and\n",
    "    updates the spin of the lattice site in accordance to the rules of the Metropolis algorithm. Returns\n",
    "    True/False on whether the spin should flip as well as the change in energy.\n",
    "    \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            beta: Inverse temperature\n",
    "            i, k: indicates the lattice site\n",
    "            N: Number of columns and rows in the lattice\n",
    "            r: Random number between 0 and 1\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            delta_E: The energy change\n",
    "            flip : Boolean value on wheter the spin should be flipped.\n",
    "        \"\"\"\n",
    "    delta_E = delta_Hamiltonian(S, i, k, N, B, J_v, J_p)\n",
    "    if delta_E <= 0:\n",
    "        flip = True # If the energy change is negative, the spin flips\n",
    "        return flip, delta_E\n",
    "    else:\n",
    "        flip = np.exp(-beta * delta_E) > r # The flip might flip, depending on r and the temperature\n",
    "        return flip, delta_E\n",
    "\n",
    "\n",
    "\n",
    "def sweep(S, beta, N, B = 0, J_v = 1, J_p = 1):\n",
    "    \"\"\"A full Monte Carlo sweep. Runs the previous functions N ** 2 times, while always storing the updated change in\n",
    "    magnetization and energy. Returns the updated spin configuaration and the change in magnetization and\n",
    "    energy (with respect to the initial values).\n",
    "    \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            beta: Inverse temperature\n",
    "            N: Number of columns and rows in the lattice\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            S: Updated spin configuartion after one Monte Carlo sweep\n",
    "            delta_He_sweep: Change in energy after one Monte Carlo sweep\n",
    "            delta_m_sweep: Change in magnetization after one Monte Carlo sweep\n",
    "        \"\"\"\n",
    "    delta_m_sweep = 0\n",
    "    delta_He_sweep = 0\n",
    "    # Generating random numbers to genereate random lattice sites \n",
    "    rand_list_index_1 = np.random.randint(N, size=N ** 2)\n",
    "    rand_list_index_2 = np.random.randint(N, size=N ** 2)\n",
    "    # Generating N ** 2 random numbers between 0 and 1\n",
    "    rand_numbers = np.random.rand(N**2)\n",
    "    for l in range(N ** 2):\n",
    "        i = rand_list_index_1[l]\n",
    "        k = rand_list_index_2[l]\n",
    "        check, delta_E = Attempt_flip(S, beta, i, k, N, rand_numbers[l], B, J_v, J_p)\n",
    "        if check:\n",
    "            delta_m = (-2) * S[i][k] / (N ** 2)\n",
    "            S[i][k] *= (-1)\n",
    "        else:\n",
    "            delta_m = 0\n",
    "            delta_E = 0\n",
    "        delta_He_sweep += delta_E\n",
    "        delta_m_sweep += delta_m\n",
    "    return S, delta_He_sweep, delta_m_sweep\n",
    "\n",
    "\n",
    "\n",
    "def compute_quantities(S, beta, M, B = 0, J_v = 1, J_p = 1, show_time= False):\n",
    "    \"\"\"Given the number of wanted sweeps, M, the simulation is ran for M Monte Carlo sweeps. Returns arrays with\n",
    "    the values of magnetization and energy after each sweep.\n",
    "    \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            beta: Inverse temperature\n",
    "            M: Number of Monte Carlo sweeps\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            He_list: The energy after each sweep (Mx1) array\n",
    "            m_list : The magnetization after each sweep (Mx1) array\n",
    "        \"\"\"\n",
    "    start = time.time()\n",
    "    N = np.shape(S)[0]\n",
    "    He_list = np.zeros(M)\n",
    "    He_list[0] = Hamiltonian(S, B, J_v, J_p) # Initial energy of the lattice\n",
    "    m_list = np.zeros(M)\n",
    "    m_list[0] = np.sum(S) / N ** 2 # Iniitial magnetization of the lattice\n",
    "    for j in range(1, M):\n",
    "        S, delta_He_sweep, delta_m_sweep = sweep(S, beta, N, B, J_v, J_p)\n",
    "        He_list[j] = He_list[j-1] + delta_He_sweep # Storing the updated energy\n",
    "        m_list[j] = m_list[j-1] + delta_m_sweep # Storing the updated magnetization\n",
    "    if show_time:\n",
    "        print(\"Iteration time with T = %.2f: %.2f\" %(1 / beta, time.time() - start))\n",
    "    return He_list, m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "S = 2 * np.random.randint(2, size=(N, N))-1 # Quick way to generate a random initial spin configuration\n",
    "He_list, m_list = compute_quantities(S, 1, 1000, show_time= True)\n",
    "\n",
    "step_list = np.arange(0, 1000)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(step_list, He_list)\n",
    "plt.title(r\"Energy as a function of Monte Carlo sweeps with $N$ = {}\".format(N) + \" and $T$ = {}\".format(T) + \" K\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$E$\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(step_list, m_list)\n",
    "plt.title(r\"Magnetization as a function of Monte Carlo sweeps with $N$ = {}\".format(N) + \" and $T$ = {}\".format(T) + \" K\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$m$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация Fortran\n",
    "\n",
    "Как мы можем видеть выше, выполнение 1000 разверток на решетке $128 \\times 128$ занимает довольно много времени. Кроме того, намагниченность не стабилизируется в течение первых 1000 разверток, поэтому ясно, что нам нужно выполнить больше разверток. Существует дальнейшая оптимизация, которую можно выполнить с помощью кода, но мы просто реализуем ту же функциональность в Fortran, чтобы получить достаточную скорость вычислений.\n",
    "\n",
    "Код Фортрана можно найти в приложении. Для получения дополнительной информации о том, как вызывать скрипты Fortran из Python, ознакомьтесь с нашим руководством [здесь](https://www.numfys.net/howto/F2PY/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing that imported fortran code works\n",
    "import ising_Monte\n",
    "print(ising_Monte.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_sweep from Fortran replaces the former sweep function written in Python\n",
    "\n",
    "def compute_quantities_fortran(S, beta, M, B = 0, J_v = 1, J_p = 1, show_time = False):\n",
    "    \"\"\"Given the number of wanted sweeps, M, the simulation is ran for M Monte Carlo sweeps. Returns arrays with\n",
    "    the values of magnetization and energy after each sweep. Calls the function random_sweep from Fortran.\n",
    "    \n",
    "        Parameters:\n",
    "            S: Spin matrix, (NxN) array\n",
    "            beta: Inverse temperature\n",
    "            M: Number of Monte Carlo sweeps\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            He_list: The energy after each sweep (Mx1) array\n",
    "            m_list : The magnetization after each sweep (Mx1) array\n",
    "        \"\"\"\n",
    "    start = time.time()\n",
    "    N = np.shape(S)[0]\n",
    "    He_list = np.zeros(M)\n",
    "    He_list[0] = Hamiltonian(S, B, J_v, J_p)\n",
    "    m_list = np.zeros(M)\n",
    "    m_list[0] = np.sum(S) / N ** 2\n",
    "    S_f = np.copy(S)\n",
    "    for j in range(1, M):\n",
    "        rand_list_index1 = np.random.randint(1, N + 1, size= N ** 2) # Fortran is 1-indexed\n",
    "        rand_list_index2 = np.random.randint(1, N + 1, size= N ** 2)\n",
    "        rand_numbers = np.random.rand(N ** 2)\n",
    "        del_He_sweep, del_m_sweep, S_f = ising_Monte.random_sweep(S_f, beta, B, J_v, J_p, rand_numbers, rand_list_index1, rand_list_index2, N, N ** 2)\n",
    "        He_list[j] = He_list[j-1] + del_He_sweep\n",
    "        m_list[j] = m_list[j-1] + del_m_sweep\n",
    "    if show_time:\n",
    "        print(\"Iteration time with T = %.2f: %.2f\" %(1 / beta, time.time() - start), \", \\t # iterations: \", M, \", \\t N = \", N)\n",
    "    return He_list, m_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "S = 2 * np.random.randint(2, size=(N, N))-1\n",
    "T = 1\n",
    "He_list, m_list = compute_quantities_fortran(S, 1 / T, 1000, show_time=True)\n",
    "\n",
    "step_list = np.arange(0, 1000)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(step_list, He_list)\n",
    "plt.title(r\"Energy as a function of Monte Carlo sweeps with $N$ = {}\".format(N) + \" and $T$ = {}\".format(T) + \" K\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$E$\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(step_list, m_list)\n",
    "plt.title(r\"Magnetization as a function of Monte Carlo sweeps with $N$ = {}\".format(N) + \" and $T$ = {}\".format(T) + \" K\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$m$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время выполнения моделирования примерно в 200 раз быстрее, чем с Python, поэтому можно с уверенностью сказать, что наша функция Fortran является важным инструментом для выполнения больших симуляций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Измерения\n",
    "\n",
    "#### Время корреляции\n",
    "\n",
    "Прежде чем мы начнем вычислять интересные величины, нам нужно определить, как и когда мы должны проводить измерения системы. Нас интересуют математические ожидания $ <m>, <E> и <E^2>$, и для нахождения этих значений мы используем среднее значение в качестве оценки. Среднее значение является объективной оценкой, но для получения надежных результатов измерения должны быть независимыми. Если бы мы измерили намагниченность, а затем снова измерили ее только через одну развертку Монте-Карло, то ясно, что две конфигурации спинов будут коррелировать, значительная часть спинов не изменится. Поэтому нам нужно убедиться, что мы достаточно долго ждем между измерениями, чтобы убедиться, что конфигурация спина значительно отличается от состояния при первом измерении. Под значительными различиями мы подразумеваем, что количество спинов, которые являются такими же, как и в исходном состоянии, не превышает того, что вы ожидаете найти случайно [[4]](#rsc).\n",
    "\n",
    "Количество разверток Монте-Карло, которые занимает этот процесс, определяется как время корреляции $\\tau$. Это связано с корреляцией следующим образом. Пусть $\\chi(t)$ - автокорреляционная функция, она имеет максимальное значение 1, полученное при $t=0$, где измерения полностью коррелированы. $t$ представляет количество разверток Монте-Карло. Обратное было бы, если бы система была точно противоположна исходной конфигурации, делая $\\chi(t) = -1$. По мере увеличения $t$ корреляция будет уменьшаться по мере того, как текущее состояние (конфигурация спина) будет все меньше и меньше коррелировать с исходным состоянием. $\\tau$ связано с $\\chi(t)$ как \n",
    "\n",
    "\\begin{equation}\n",
    "\\chi(t) \\sim e^{- \\frac{t}{\\tau}}.\n",
    "\\label{corr_time} \\quad(2)\n",
    "\\end{equation}\n",
    "\n",
    "Таким образом, $\\tau$ является параметром подгонки, который мы можем использовать библиотеку scipy для определения оптимальной подгонки. Наиболее естественным определением статистических независимых измерений являются измерения, выполняемые каждые $2\\tau$ [[4]](#rsc). Если мы запустили $n$ развертки Монте-Карло, у нас будет $m = \\frac{n}{2\\tau}$ независимых измерений. Подходящая оценка для $\\chi$ для измеряемой величины $O$ задается \n",
    "\n",
    "\\begin{equation}\n",
    "\\chi_O(t) = \\frac{1}{\\chi_0} \\frac{1}{n - t} \\sum_{t' = 0}^{n - 1 -t} (O(t') - < O >_0 ) (O(t' + t) - < O >_t),\n",
    "\\label{corr_func} \\quad(3)\n",
    "\\end{equation}\n",
    "\n",
    "где $O(0), O(1), ..., O(n-1)$ - это $n$ измерений $O$, а $\\chi_0$ определяется таким образом, что $\\chi(0) = 1$. $< O >_t)$ и $< O >_0)$ определяются как\n",
    "\n",
    "\\begin{equation}\n",
    "< O >_0 = \\frac{1}{n - t} \\sum_{t' = 0}^{n - 1 -t} O(t') \\quad \\quad < O >_t = \\frac{1}{n - t} \\sum_{t' = 0}^{n - 1 -t} O(t' + t).\n",
    "\\label{help_sizes}\n",
    "\\end{equation}\n",
    "\n",
    "Комбинируя уравнения (2) и (3), т. е. используя нашу оценку времени корреляции $\\chi$ и находя оптимальное соответствие для $\\tau$, мы можем сделать хорошую оценку для $\\tau$. В нашем случае мы включаем только те измерения, которые имеют положительную автокорреляцию, такую что $\\chi_O(t) > 0$.\n",
    "Следует отметить, что даже если мы измеряем физические величины только каждые $2\\tau$, нам все равно нужно сделать много измерений, чтобы наша оценка была близка к истинному значению.\n",
    "\n",
    "\n",
    "Наконец, мы отмечаем, что при экстремально низких температурах почти не будет изменений в конфигурации спина, поскольку решетка получила самую низкую возможную энергию, и крайне маловероятно, что какие-либо спины перевернутся из-за тепловых возбуждений. В этом случае мы не вычисляем время корреляции, а просто используем каждое десятое измерение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_corr_func(t, tau):\n",
    "    \"\"\"Dummy function declariation that is needed to use the curve_fit function from the scipy library. \n",
    "    \n",
    "        Parameters:\n",
    "            t: The enumuration of the Monte Carlo sweeps \n",
    "            tau: Correlation time\n",
    "        Returns:\n",
    "            chi: exp(-t / tau)\n",
    "        \"\"\"\n",
    "    chi = np.exp(-t / tau)\n",
    "    return chi\n",
    "\n",
    "\n",
    "def correlation_time(arr):\n",
    "    \"\"\"Calculates the estimator for the autocorrelation function, chi, as a function of t. Stops the calculations\n",
    "    of chi when chi(t) becomes egative. Then calculates the correlation time by using the curve_fit\n",
    "    function from scipy-library.\n",
    "    \n",
    "        Parameters:\n",
    "            arr: The measurement series we want to determine the correlation time of\n",
    "        Returns:\n",
    "            tau: The correlation time\n",
    "            chi: The autocorrelation function as a function of # Monte Carlo sweeps. The size of the array varies.\n",
    "        \"\"\"\n",
    "    chi = np.zeros(0)\n",
    "    n = np.minimum(len(arr), 10000)\n",
    "    # Here we take the minimum of the length of the array, and 10000 to obtain a correlation time that is\n",
    "    # independant of the length of the array\n",
    "    for t in range(n):\n",
    "        frac = (1 / (n - t))\n",
    "        \n",
    "        # plus 1 to include last term\n",
    "        expectation_0 = frac * np.sum(arr[:(n - 1 - t) + 1])\n",
    "        expectation_t = frac * np.sum(np.roll(arr, - t)[:(n - 1 - t) + 1])\n",
    "        \n",
    "        temp = frac * np.sum((arr[:n - 1 - t + 1] - expectation_0) *\n",
    "                             (np.roll(arr, - t)[:n - 1 - t + 1] - expectation_t))\n",
    "        if temp < 0:\n",
    "            break\n",
    "        chi = np.append(chi, temp)\n",
    "    # Normalize the autocorrelation function\n",
    "    chi = chi / chi[0]\n",
    "    t = np.arange(0, len(chi))\n",
    "    # Calculates the correlation time with scipy\n",
    "    tau = scipy.optimize.curve_fit(auto_corr_func, t, chi)[0]\n",
    "    return tau[0], chi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поучительно посмотреть, как $\\tau$ изменяется в зависимости от температуры. Мы также увидим, насколько хорошо работает подгонка кривой. В этом случае измеренная величина $O$ соответствует $m$, но расчеты будут выполнены так же, как и при использовании $E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "S = 2 * np.random.randint(2, size=(N, N)) - 1\n",
    "T = 2.1\n",
    "m_list = compute_quantities_fortran(S, 1/T, 80000)[1]\n",
    "\n",
    "tau, chi = correlation_time(m_list[70000:])\n",
    "t = np.arange(len(chi))\n",
    "print(\"Tau is equal to \" + \"%.1f\" % tau + \" when T = \", T, \" K\" )\n",
    "plt.plot(t, np.exp(- t / tau), label= r\"$\\chi(t) \\sim e^{- \\frac{t}{\\tau}}$\")\n",
    "plt.plot(t, chi, label = \"Estimator for $\\chi(t)$\")\n",
    "plt.legend()\n",
    "plt.title(r\"Different estimators for the autocorrelation function $\\chi(t)$\")\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$\\chi(t)$\")\n",
    "plt.show()\n",
    "\n",
    "T_list = np.linspace(1.5, 4, 20)\n",
    "tau_list = np.zeros(0)\n",
    "for T in T_list:\n",
    "    S = 2 * np.random.randint(2, size=(N, N)) - 1\n",
    "    beta = 1 / T\n",
    "    # Why we differentiate cold and hot simulations is explained later\n",
    "    if T < 2.5:\n",
    "        m_list = compute_quantities_fortran(S, beta, 200000)[1]\n",
    "        # The reason we only use the last 20000 values of the list is explained later\n",
    "        tau, chi = correlation_time(m_list[180000:])\n",
    "\n",
    "        tau_list = np.append(tau_list, tau)\n",
    "    else:\n",
    "        m_list = compute_quantities_fortran(S, beta, 40000)[1]\n",
    "        # The reason we only use the last 20000 values of the list is explained later\n",
    "        tau, chi = correlation_time(m_list[20000:])\n",
    "        tau_list = np.append(tau_list, tau)\n",
    "\n",
    "plt.plot(T_list, tau_list)\n",
    "plt.title(r\"Correlation time, $\\tau$, as a function of temperature\")\n",
    "plt.xlabel(r\"$T$ [K]\")\n",
    "plt.ylabel(r\"$\\tau$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот рисунок иллюстрирует важность использования различных времен корреляции для разных температур. Обратите внимание на пик времени корреляции около $T=2,25$ K. Как мы увидим позже, эта температура является критической температурой для фазового перехода системы. Этот эффект называется \"критическим замедлением\". Эффект критического замедления может быть уменьшен путем настройки алгоритма метрополиса. Более подробную информацию по этой теме можно найти в главе 4 в [[3]](#rsc). Определяя $\\tau$ для каждого моделирования, мы можем извлечь из нашей системы как можно больше независимых измерений, тем самым минимизируя ошибки в наших результатах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Равновесное время\n",
    "\n",
    "Последняя величина, которую нам нужно получить, прежде чем мы сможем запустить полное моделирование Монте-Карло, - это время равновесия $\\tau_{\\mathrm{eq}} $. $\\tau_{\\mathrm{eq}} $ - это мера того, сколько разверток Монте-Карло необходимо, прежде чем система достигнет равновесия. К счастью, метод определения $\\tau_{\\mathrm{eq}} $ намного проще, чем определение $\\tau$. Мы можем просто запустить небольшое количество симуляций для одного и того же $T$ и посмотреть, когда указанное значение ($m$ или $E$) начнет стабилизироваться.\n",
    "\n",
    "Однако $\\tau_{\\mathrm{eq}} $ масштабируется с $N$ и варьируется от моделирования к моделированию. Всегда следует переоценивать $\\tau_{\\mathrm{eq}}$, потому что наши измерения действительны только тогда, когда система находится в равновесии, и начало измерений до этого момента сделало бы наши результаты бесполезными. Особенно при низких температурах $\\tau_{\\mathrm{eq}} $ может быть огромным (до 150 000 шагов Монте-Карло). Это происходит, когда система падает до локального энергетического минимума и не может еще больше снизить свою энергию. Важно отметить, что $\\tau_{\\mathrm{eq}} $ обычно будет низким для низких температур, но достижение равновесия может занять много времени, поэтому нам всегда нужно переоценивать $\\tau_{\\mathrm{eq}}$, чтобы быть в безопасности.\n",
    "\n",
    "Ниже мы построим график намагниченности в зависимости от развертки Монте-Карло, чтобы проиллюстрировать, как можно определить $\\tau_{\\mathrm{eq}} $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "S = 2 * np.random.randint(2, size=(N, N)) - 1\n",
    "\n",
    "# High temperature\n",
    "T = 5\n",
    "beta = 1 / T\n",
    "m_list = compute_quantities_fortran(S, beta, 30000)[1]\n",
    "step_list = np.arange(30000)\n",
    "plt.plot(step_list, m_list, label= \"High temperature\")\n",
    "\n",
    "\n",
    "# Medium temperature\n",
    "T = 2.2\n",
    "beta = 1 / T\n",
    "m_list = compute_quantities_fortran(S, beta, 30000)[1]\n",
    "plt.plot(step_list, m_list, label= \"Medium temperature\")\n",
    "\n",
    "# Low temperature\n",
    "T = 1\n",
    "beta = 1 / T\n",
    "m_list = compute_quantities_fortran(S, beta, 30000)[1]\n",
    "plt.plot(step_list, m_list, label= \"Low temperature\")\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$m$\")\n",
    "plt.title(r\"The development of the magnetization as a function of $t$, at different temperatures\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае высокой температуры мы видим, что система в основном находится в равновесии с самого начала моделирования, в то время как в случае средней температуры система достигает равновесия примерно через 8000 циклов. Мы также видим пример, когда системе требуется много времени, чтобы достичь равновесия. На самом деле, в случае низкой температуры система все еще не достигла равновесия после 30000 проходов. Это иллюстрирует важность использования высокого $\\tau_{\\mathrm{eq}} $. К счастью, в нашем распоряжении есть тонны вычислительной мощности, поэтому мы можем позволить себе иметь высокий $\\tau_{\\mathrm{eq}} $. Еще один важный момент заключается в том, что знак намагниченности не имеет никакого физического значения до тех пор, пока нет внешнего поля. Если намагниченность отрицательная, можно просто повернуть всю систему (перевернув ее вверх дном), чтобы получить положительную намагниченность. В дальнейшем мы будем говорить о намагниченности и $\\textit{величине}$ намагниченности взаимозаменяемо.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full simulations\n",
    "\n",
    "Давайте, наконец, объединим все наши вспомогательные функции и теорию в единую функцию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_simulation(K, N, sweeps, T_min = 1, T_max = 4, B = 0, J_v = 1, J_p = 1, show_time = False):\n",
    "    \"\"\"Runs the full Monte Carlo simulation and returns the magnetization and specific heat as a function of\n",
    "    temperature. The temperature interval is controlled by the user.\n",
    "    \n",
    "        Parameters:\n",
    "            K: Number of temperatures we want simulated\n",
    "            N: Number of columns and rows in the lattice\n",
    "            sweeps: Number of sweeps we want to run after the system has reached equlibrium\n",
    "            T_min: Minimum temperature of our simulation\n",
    "            T_max: Maximum temperature of our simulation\n",
    "            B, J_v, J_p: Interactation and external parameters\n",
    "        Returns:\n",
    "            m: The magnetization as a function of temperature, (Kx1) array\n",
    "            c: The specific heat as a function of temperature, (Kx1) array\n",
    "            T: List of the temperatures that was used in the simulation, (Kx1) array\n",
    "        \"\"\"\n",
    "    T = np.linspace(T_min, T_max, K)\n",
    "    betas = 1/T\n",
    "    m = np.zeros(K)\n",
    "    c = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        S = 2 * np.random.randint(2, size=(N, N)) - 1\n",
    "        # Seperating the two cases (High/Low tau_equil)\n",
    "        if 1/betas[i] < 2.5:\n",
    "            if N < 129: # Also seperating the biggest lattices from the smaller ones as they have a higher tau_eq\n",
    "                tau_equil = 60000\n",
    "                He_list, m_list = compute_quantities_fortran(S, betas[i], tau_equil + sweeps, B, J_v, J_p, show_time)\n",
    "            else:\n",
    "                tau_equil = 300000\n",
    "                He_list, m_list = compute_quantities_fortran(S, betas[i], tau_equil + sweeps, B, J_v, J_p, show_time)\n",
    "        else:\n",
    "            if N < 129: # Also seperating the biggest lattices from the smaller ones as they have a higher tau_eq\n",
    "                tau_equil = 10000\n",
    "                He_list, m_list = compute_quantities_fortran(S, betas[i], tau_equil + sweeps, B, J_v, J_p, show_time)\n",
    "            else:\n",
    "                tau_equil = 50000\n",
    "                He_list, m_list = compute_quantities_fortran(S, betas[i], tau_equil + sweeps, B, J_v, J_p, show_time)\n",
    "            \n",
    "        try: # If the system is too stable (i.e no notable changes during the simulations), the correlation_time\n",
    "            # function will not work. That is why we use a try/expect\n",
    "            tau_m = correlation_time(m_list[tau_equil:])[0] \n",
    "            step_size_m = int(2 * tau_m + 1)  # Independant magnetization values\n",
    "            \n",
    "            \n",
    "            # Same for E and c, we assume that they have same equilibrium time as m\n",
    "            tau_E = correlation_time(He_list[tau_equil:])[0]\n",
    "            step_size_E = int(2 * tau_E + 1)\n",
    "            \n",
    "        # At extremly low temperatures, there is no need to find the correlation time, because the lattice almost \n",
    "        # does not change. In that case, we just use step_size_m = 10, step_size_E = 10\n",
    "        except:\n",
    "            step_size_m = 10\n",
    "            step_size_E = 10\n",
    "\n",
    "            \n",
    "        # Calculating the average magnetization\n",
    "        m[i] = np.sum(m_list[tau_equil::step_size_m]) / len(m_list[tau_equil::step_size_m])\n",
    "\n",
    "\n",
    "        He_list_ind = He_list[tau_equil::step_size_E]\n",
    "        # Calculating the average energy and the average squared energy\n",
    "        He = np.sum(He_list_ind) / np.shape(He_list_ind)\n",
    "        E_squared = np.sum(np.power(He_list_ind, 2)) / np.shape(He_list_ind)\n",
    "        # Calculating the specific heat by determining the energy fluctuations (as mentioned in the theory)\n",
    "        c[i] = betas[i] ** 2 * (E_squared - He ** 2)\n",
    "    \n",
    "    # Sign of magnetization is not of physical importance\n",
    "    m = np.absolute(m)\n",
    "    \n",
    "    # Want the specific heat independant of the lattice size (i.e. the specific heat per lattice site)\n",
    "    c = c / (N ** 2)\n",
    "    return m, c, T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналитическое решение Онсагера\n",
    "\n",
    "Теперь, когда мы реализовали наше моделирование с достаточной вычислительной скоростью, мы можем, наконец, начать выполнять полное моделирование и сравнивать его с теоретическими результатами. Как упоминалось во введении, Ларс Онсагер нашел аналитическое решение для намагниченности и удельной теплоты. Для этого требуется решетка $N \\times \\infty$, но при использовании большого $N$ наше моделирование даст результаты, сопоставимые с результатами Ларса Онсагера. Решение Онсагера также требует периодических граничных условий, которые придают нашей решетке топологию тора и что магнитное поле $B = 0$. Производные следующих уравнений выводятся в [[1]](#rsc), [[2]](#rsc) и [[3]](#rsc), но для простоты результаты будут изложены без доказательств. \n",
    "\n",
    "Намагниченность принимает форму \n",
    "\n",
    "\\begin{equation}\n",
    "m = \\left\\{\n",
    "  \\begin{array}{lr}\n",
    "    0 & : T > T_c\\\\\n",
    "    \\big\\{1- \\big[ \\mathrm{sinh}(2 \\beta J) \\big]^{-4} \\big\\}^\\frac{1}{8} & : T < T_c\n",
    "  \\end{array}\n",
    "\\right.\n",
    "\\label{magnetization}\n",
    "\\end{equation}\n",
    "\n",
    "Мы предположили здесь, что $J=J'$. Это спонтанное намагничивание, которое возникает без индуцирования внешним полем.\n",
    "Выражение для удельной теплоты является более сложным и может быть выражено более элегантно путем введения\n",
    "\n",
    "\\begin{equation}\n",
    "\\kappa \\equiv \\frac{2 \\mathrm{sinh}(2 \\beta J)}{\\mathrm{cosh}^2(2 \\beta J) }, \\quad \\kappa ' \\equiv 2 \\mathrm{tanh}^2(2 \\beta J) - 1. \n",
    "\\label{kappas}\n",
    "\\end{equation}\n",
    "\n",
    "Нам также нужны выражения для полных эллиптических интегралов первого и второго рода, обозначаемых как $K_1(\\kappa)$ и $E_1(\\kappa)$ соответственно. Они представляют собой табличные функции, заданные\n",
    "\n",
    "\\begin{equation}\n",
    " K_1(\\kappa) \\equiv \\int_0^{\\frac{\\pi}{2}} \\frac{d\\phi}{\\sqrt{1- \\kappa^2 \\sin^2{\\phi}}}, \\quad E_1(\\kappa) \\equiv \\int_0^{\\frac{\\pi}{2}} d\\phi\\sqrt{1- \\kappa^2 \\sin^2{\\phi}}.\n",
    "\\label{eliptic_integrals}\n",
    "\\end{equation}\n",
    "\n",
    "Теперь мы можем, наконец, выразить удельную теплоту как \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{C_B}{N² k_B} = \\frac{2}{\\pi} (\\beta J \\mathrm{coth}(2 \\beta J) ^2 \\Big\\{ 2 K_1(\\kappa) - 2 E_1(\\kappa) - (1-\\kappa') \\big[\\frac{\\pi}{2} + \\kappa' K_1(\\kappa) \\big] \\Big\\}.\n",
    "\\label{C_B} \\quad(4)\n",
    "\\end{equation}\n",
    "\n",
    "Это уравнение имеет особенность при $\\kappa' = 0$, что соответствует критической температуре $T_c$. Решение $\\kappa' = 0$ для T дает следующую критическую температуру\n",
    "\\begin{equation}\n",
    "T_c = \\frac{2J}{\\ln({1 + \\sqrt{2})}} \\simeq 2.269 J. \n",
    "\\label{T_c}\n",
    "\\end{equation}\n",
    "\n",
    "Все термодинамические функции имеют сингулярность в той или иной форме при $T_c$. Такое поведение указывает на то, что у нас есть фазовый переход. Выше $T_c$ система находится в парамагнитной фазе, где средняя намагниченность равна нулю. Ниже $T_c$ система находится в ферромагнитной фазе, где она развивает спонтанное намагничивание. Для $T$ вблизи $T_c$ удельная теплота приближается к бесконечности логарифмически, как $|T-T_c| \\rightarrow 0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь помните, что решение Онсагера справедливо только для бесконечной решетки, поэтому мы ожидаем, что более крупные решетки будут лучше всего аппроксимировать его решения. Давайте начнем с использования малой, средней и большой решетки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small lattice\n",
    "N = 8\n",
    "m_s, c_s, T = full_simulation(20, N, 200000)\n",
    "\n",
    "# Medium lattice\n",
    "N = 32\n",
    "m_m, c_m, T = full_simulation(20, N, 200000)\n",
    "\n",
    "# Large lattice\n",
    "N = 128\n",
    "m_l, c_l, T = full_simulation(20, N, 200000)\n",
    "\n",
    "# The T is equal for all the simulations\n",
    "\n",
    "# Magnetization\n",
    "plt.scatter(T, m_s, label=r\"$N$ = 8\", marker='*')\n",
    "plt.scatter(T, m_m, label=r\"$N$ = 32\", marker='o')\n",
    "plt.scatter(T, m_l, label=r\"$N$ = 128\", marker='x')\n",
    "\n",
    "T_2 = np.linspace(1, 5, 10000)\n",
    "m_analytical = (1 - (np.sinh(2 / T_2)) ** (-4)) ** (1 / 8) # Onsager's analytical solution\n",
    "plt.plot(T_2, m_analytical, label = \"Analytic solution\")\n",
    "plt.axvline(2.269, ymax=0.4) # Adding vertical line to illustrate that the functions comes screaming down at T_c\n",
    "plt.legend()\n",
    "plt.title(r\"Comparison of the numerical and analytical results for the magnetization\")\n",
    "plt.xlabel(r\"$T$ [K]\")\n",
    "plt.ylabel(r\"$m$\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Specific heat\n",
    "plt.scatter(T, c_s, label=r\"$N$ = 8\", marker='*')\n",
    "plt.scatter(T, c_m, label=r\"$N$ = 32\", marker='o')\n",
    "plt.scatter(T, c_l, label=r\"$N$ = 128\", marker='x')\n",
    "\n",
    "plt.xlabel(r\"$T$ [K]\")\n",
    "plt.ylabel(r\"$c$\")\n",
    "plt.title(r\"Comparison of the numerical and analytical results for the specific heat\")\n",
    "beta = 1 / T_2\n",
    "# Assuming J_v = J_p = 1\n",
    "J_v = 1\n",
    "J_p = 1\n",
    "kappa_1 = 2 * np.sinh(2 * beta * J_v) / (np.cosh(2 * J_v * beta) ** 2 )\n",
    "kappa_2 = 2 * np.tanh(2 * beta * J_v) ** 2 - 1\n",
    "\n",
    "elliptical_first_kind = scipy.special.ellipk(kappa_1)\n",
    "elliptical_second_kind = scipy.special.ellipe(kappa_1)\n",
    "\n",
    "C_v_analytical = 2 / np.pi * (beta * J_v) ** 2 / np.tanh(2 * beta * J_v) ** 2 *(\n",
    "    2 * elliptical_first_kind - 2 * elliptical_second_kind -\n",
    "     (1 - kappa_2) * (np.pi / 2 + kappa_2 * elliptical_first_kind))\n",
    "plt.plot(T_2, C_v_analytical, label= \"Analytic solution\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из первого рисунка видно, что две самые большие решетки с $N=32$ и $N=128$ соответственно довольно хорошо воспроизводят аналитические решения для намагниченности на бесконечной решетке. Во всех трех симуляциях при температурах выше $T_c$ намагниченность равна нулю, т. е. спонтанной намагниченности нет. Однако мы наблюдаем превосходство самой большой решетки при измерении ближе к $T_c$. Здесь производная намагниченности бесконечна, поэтому, хотя кажется, что две меньшие решетки почти имеют правильное значение для $m$, отклонение на самом деле довольно велико, так как намагниченность падает до $T_c$. Пренебрегая измерением при $T_c$, мы видим, что можем использовать $N=32$ и примерно получить те же результаты, что и для более крупной решетки. Моделирование с $N=32$ выполняется в восемь раз быстрее, чем $N=128$, что является существенной разницей, поэтому мы приходим к выводу, что для намагничивания мы можем уйти, используя только $N=32$ за пределами критической области. Но для моделирования ближе к $T_c$ мы отмечаем, что чем больше решетка, тем лучше результат.\n",
    "\n",
    "Что касается теплоемкости, то мы наблюдаем аналогичную тенденцию. За пределами критической области все три решетки на самом деле преформируются одинаково хорошо, так как все они немного недооценивают теплоемкость. Поскольку $c$ логарифмически расходится при $T_c$, мы также наблюдаем резкое увеличение удельной теплоты при этой температуре для $N=32$ и $N=128$, причем большая решетка увеличивается больше всего.\n",
    "\n",
    "Основываясь на наших результатах, может показаться, что использование большого $N$ не нужно, так как результаты моделирования с $N=32$ почти идентичны моделированию с $N=128$. Это верно, но наш главный интерес заключается в фазовом переходе, который происходит при $T_c$. Таким образом, нам действительно нужно использовать большой $N$, чтобы изучить поведение системы, близкое к $T_c$, потому что $N$ существенно влияет на термодинамические величины в этой области. Мы рассмотрим критическую область более подробно позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ларс Онсагер действительно нашел формулу для удельной теплоты для общих $J$ и $J'$, но формула становится намного сложнее, чем уравнение (4). Поэтому мы позаимствуем одну из его цифр из его статьи, чтобы сравнить ее с нашим численным результатом. В этом случае мы используем $ J = 1$, в то время как $ J'$ будет принимать значения 1, 0,01 и 0. Здесь мы используем довольно большое $N$, потому что $J' = 0,01$ должен быть смоделирован с большой решеткой, чтобы получить результаты, сопоставимые с результатом Онсагера. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These simulations were run overnight, and are split up \n",
    "N = 256\n",
    "\n",
    "J_p = 1\n",
    "m_1, c_1, T_1 = full_simulation(30, N, 200000, T_min = 0.3, T_max = 3, J_p = J_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "\n",
    "J_p = 0.01\n",
    "m_2, c_2, T_2 = full_simulation(30, N, 200000, T_min = 0.3, T_max = 1.5, J_p = J_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "\n",
    "J_p = 0\n",
    "m_3, c_3, T_3 = full_simulation(30, N, 200000, T_min = 0.3, T_max = 1.5, J_p = J_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_p = 1\n",
    "plt.plot(T_1, c_1, label= \"$J'$ = {}\".format(J_p), linestyle = '-.')\n",
    "\n",
    "J_p = 0.01\n",
    "# Multiply the temperature with 2 to have it on the same format as Onsager \n",
    "plt.plot((T_2 * 2), c_2, label= \"$J'$ = {}\".format(J_p), linestyle = '-')\n",
    "\n",
    "J_p = 0\n",
    "# Multiply the temperature with 2.02 to have it on the same format as Onsager\n",
    "plt.plot((T_3 * 2.02), c_3, label= \"$J'$ = {}\".format(J_p), linestyle = '--')\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$\\frac{2}{H-H'}$ [K]\")\n",
    "plt.ylabel(r\"$c$\")\n",
    "plt.title(r\"Specific heat, $c$, with different values for $J'$. $N$ = {}\".format(N))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Onsager_figure.png](images\\Onsager_figure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ларс Онсагер использовал несколько иную нотацию, чем мы, когда он построил график теплоемкости против $\\frac{2}{H-H'}$, где $H = \\beta J$ и $H' = \\beta J'$. В случае анизотропного моделирования ($J \\neq J'$) мы можем преобразовать температуру в его единицу измерения, просто умножив температуру на $\\frac{2}{J-J'}$. При $J'=0$ мы наблюдаем, что заново открываем знаменитое решение Эрнста Изинга для теплоемкости одномерной цепи Изинга с периодическими граничными условиями (кольцо), поскольку у нас просто есть $N$ таких колец, которые не взаимодействуют. В изотропном случае мы снова обнаруживаем, что наше моделирование дает результаты, сопоставимые с (4), и поскольку мы использовали большую решетку, чем ранее, мы получаем еще лучшие результаты.\n",
    "\n",
    "Для $J'=0,01 J$ должен быть фазовый переход при $\\frac{2}{H-H'} = 1$, где температура равна $T_c'$, а теплоемкость расходится. Однако, как видно из рисунка Онсагера, это расхождение влияет только на температуры, очень близкие к критической температуре, поэтому, если мы не запустим наше моделирование при температуре, очень близкой к критической температуре, мы не увидим ничего похожего на расхождение. Качественно наши результаты для $J'=0,01 J$ очень хорошо согласуются с цифрой Онсагера. Мы видим, что теплоемкость начинает быть меньше, чем в случае $J'=0$, и непосредственно перед тем, как температура достигнет $T_c'$, происходит резкое увеличение с соответствующим быстрым уменьшением после $T_c'$. Это указывает на то, что в нашей системе при $T_c'$ происходит что-то радикальное, то есть указывает на фазовый переход. Для более высоких температур мы наблюдаем, что теплоемкость сходится к случаю $J'=0$, поскольку связь между взаимодействиями между столбцами слишком слаба, чтобы повлиять на систему. \n",
    "\n",
    "Теперь давайте для полноты картины проведем моделирование, имеющее внешнее магнитное поле, и посмотрим, как реагирует решетка. Помните, что, поскольку $B \\neq 0$, решение Онсагера больше недействительно, как упоминалось ранее, для этой проблемы нет известного аналитического решения. Тем не менее, мы все еще можем попытаться понять результаты с физической точки зрения и обосновать их обоснованность, основываясь на простых физических принципах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "m, c, T = full_simulation(45, N, 300000, B = 1, T_max = 10)\n",
    "\n",
    "plt.plot(T, m)\n",
    "plt.xlabel(r\"$T$ [K]\")\n",
    "plt.ylabel(r\"$m$\")\n",
    "plt.title(r\"Magnetization, $m$, with nonzero exernal magnetic field, $B=1$ and $N$ = {}\".format(N))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(T, c)\n",
    "plt.xlabel(r\"$T$ [K]\")\n",
    "plt.ylabel(r\"$c$\")\n",
    "plt.title(r\"Specific heat, $c$, with nonzero exernal magnetic field, $B=1$ and $N$ = {}\".format(N))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы видим, что у нас ненулевая намагниченность при гораздо более высоких температурах, чем раньше. Объяснение этому простое: чтобы минимизировать энергию системы, спины стараются указывать в том же направлении, что и $B$. Однако внешнее магнитное поле все еще слишком слабо, чтобы выровнять все спины при температурах выше 2 К. Как тепловые возбуждения системы, так и параметры взаимодействия $J$ и $J'$ работают против полного выравнивания спина.\n",
    "\n",
    "Удельная теплоемкость также иллюстрирует эту борьбу за власть между $B$ и его противниками. Чем более равномерно они будут согласованы, тем больше будет спиновых флуктуаций, и, следовательно, флуктуации энергии также увеличатся. Как мы видели ранее, удельная теплоемкость пропорциональна колебаниям энергии, поэтому, когда $c$ имеет максимум, это означает, что борьба за выравнивание наиболее интенсивна. При 4 К мы наблюдаем, что $c$ имеет максимум, поэтому мы приходим к выводу, что война между $B$ и $J$, $J'$ и тепловыми возбуждениями бушует в худшем случае при этой температуре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критические показатели\n",
    "\n",
    "Поскольку мы посвятили так много времени получению большой вычислительной мощности, мы хотим использовать нашу модель, чтобы найти один из критических показателей двумерной модели Изинга. Критические показатели описывают поведение термодинамических величин вблизи фазовых переходов. В более высоких измерениях, поскольку нет известных аналитических решений, была проделана большая численная работа по определению точных оценок критических показателей. Критические показатели чрезвычайно чувствительны к отклонениям от аналитического результата, поэтому теперь мы хотим довести нашу модель до ее пределов.\n",
    "\n",
    "Критический показатель степени $\\beta$ (не путать с обратной температурой, для обозначения которой мы до сих пор использовали $\\beta$) описывает, как намагниченность исчезает вблизи $T_c$. В этой температурной области намагниченность может быть записана как\n",
    "\n",
    "$$ \n",
    "m \\sim \\epsilon |T-T_C|^\\beta,\n",
    "$$\n",
    "где $\\epsilon$ - некоторая константа. Раскладывая аналитическое решение уравнения намагниченности в ряд Тейлора по $m$, можно обнаружить, что 2D-модель бесконечного Изинга имеет $\\beta = \\frac{1}{8}$. Давайте посмотрим, как работает наша модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_low_T(T, epsilon, beta):\n",
    "    \"\"\"Dummy function declariation that is needed to use the curve_fit function from the scipy library. \n",
    "    \n",
    "        Parameters:\n",
    "            T: Temperature\n",
    "            epsilon: Fitting parameter\n",
    "            beta: Fitting parameter, the critical exponent for magnetization with no external field\n",
    "        Returns:\n",
    "            m: epsilon * T ** beta\n",
    "        \"\"\"\n",
    "    m = epsilon * T ** beta\n",
    "    return m\n",
    "\n",
    "def critical_exponent(K, N, sweeps, T_low, show_time = False):\n",
    "    \"\"\"Function that calculates the critical exponent of the 2D Ising model with B=0, and J_v = J_p = 1. Runs a Monte\n",
    "    Carlo simulation with temperatures close to T_c and estimates the critical exponent, uses the simualtions with T\n",
    "    between T_low and T_c\n",
    "    \n",
    "        Parameters:\n",
    "            K: Number of temperatures we want simulated\n",
    "            N: Number of columns and rows in the lattice\n",
    "            T_low: The start of the temperature interval the simulations are ran with.\n",
    "        Returns:\n",
    "            m_list: The magnetization as a function of deviation from the critical temperature, (Kx1) array\n",
    "            c_list: The specific heat as a function of deviation from the critical temperature, (Kx1) array\n",
    "            T_list: Contains the temperatures the simulations are run with, more accurately how much they\n",
    "                    deviate from T_c, (Kx1) array\n",
    "        \"\"\"\n",
    "    T_c = 2.26918 # Can be derived from Onsager's equaitons\n",
    "        \n",
    "    T_list = np.linspace(T_low, T_c, K)\n",
    "    m_list = full_simulation(K, N, sweeps, T_low, T_c)[0]\n",
    "    deviation_from_T_c = np.absolute(T_list - T_c)\n",
    "    params = scipy.optimize.curve_fit(mag_low_T, deviation_from_T_c, m_list)[0]\n",
    "    beta = params[1]\n",
    "    epsilon = params[0]\n",
    "    print(\"N = \", N, \", \\t\", r\"beta = \", \"%.4f\" % beta)\n",
    "    return m_list, beta, deviation_from_T_c, epsilon\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again we split the simulations\n",
    "m_64, beta_64, T_list_64, epsilon_64 = critical_exponent(25, 64, 200000, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_128, beta_128, T_list_128, epsilon_128 = critical_exponent(25, 128, 600000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_256, beta_256, T_list_256, epsilon_256 = critical_exponent(25, 256, 300000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, критические показатели из нашего моделирования постепенно приближаются к $\\beta = \\frac{1}{8}=0.125$, по мере увеличения $N$. Самая маленькая решетка резко переоценивает $\\beta$, поэтому эти моделирования действительно иллюстрируют важность использования большой решетки при сравнении с результатами бесконечной решетки. Прелесть определения критических показателей заключается в том, что они не зависят от экспериментальных параметров, таких как $J$, они обычно зависят только от размерности системы. Поскольку $J$ практически невозможно надежно измерить, критические показатели гораздо важнее при описании фазового перехода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Создание собственной модели Изинга - отличное упражнение, особенно если оно заставляет вас поддерживать свой код чистым и эффективным. С современными компьютерами легко быть небрежным при написании кода, так как он, скорее всего, будет работать более чем достаточно быстро. Наш последний вызов функции запустил самые основные части кода триллион раз! Владение высокоскоростным языком, таким как Фортран, является отличным инструментом для вычислительного физика. Следует отметить, что некоторые из наиболее трудоемких симуляций (особенно с $N>128$) в этом ноутбуке выполнялись ночью, поэтому, хотя у нас было много вычислительной мощности, нам все еще требовалось время для получения надежных результатов. Мы настоятельно рекомендуем книгу Ньюмана и Баркемы [[4]](#rsc), если вы хотите изучить более сложные методы Монте-Карло, чем алгоритм Метрополиса, и продолжить изучение различных термодинамических величин модели Изинга, таких как, например, магнитная восприимчивость, $\\chi$ или если вы хотите расширить модель Изинга до трех измерений. С моделью Ising еще многое предстоит узнать и сделать!\n",
    "\n",
    "## Благодарности\n",
    "Особая благодарность проф. Асле Судбе за создание проекта, предоставление глубоких комментариев и за заимствование необходимой литературы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"rsc\"></a>\n",
    "## Resources and further reading\n",
    "<a>[1]</a>: L. Onsager, *Crystal Statistics. I. A Two-Dimensional Model with an Order-Disorder Transition*, American Physical Society, 1944. <br />\n",
    "<a>[2]</a>: K. Huang, *Statistical Mechanics*, John Wiley & Sons, 1987. <br />\n",
    "<a>[3]</a>: Yang, C. N, *The Spontaneous Magnetization of a Two-Dimensional Ising Model*, American Physical Society, 1952. <br />\n",
    "<a>[4]</a>: Newman, M. E. J & Barkema, G. T, *Monte Carlo methods in Statistical Physics*, Oxford University Press, 1999. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "We give the Fortran(90) subroutine below, which was converted into a Python Module with F2PY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` fortran\n",
    "! Author: Eilif Sommer Øyre and Niels Henrik Aase\n",
    "! Runs a single Monte Carlo sweep on a 2D Ising lattice\n",
    "! The boundary conditions are periodic.\n",
    "\n",
    "\n",
    "subroutine random_sweep(del_He_sweep, del_m_sweep, S, S_initial, beta, &\n",
    "  B, J_v, J_p, rand_numbers, rand_list_index1, rand_list_index2, N, N_squared)\n",
    "  \n",
    "  implicit none\n",
    "  ! Declearing arguments\n",
    "  integer ,intent(in)  :: N, N_squared\n",
    "  real    ,intent(in)  :: beta, B, J_v, J_p\n",
    "  real    ,intent(in)  :: rand_numbers(N_squared)\n",
    "  integer ,intent(in)  :: rand_list_index1(N_squared), rand_list_index2(N_squared)\n",
    "  integer ,intent(in)  :: S_initial(N,N)\n",
    "  ! Declearing private parameters\n",
    "  integer ,intent(out) :: S(N,N)\n",
    "  real    ,intent(out) :: del_He_sweep, del_m_sweep\n",
    "  real                 :: nn, del_E, del_m\n",
    "  logical              :: check\n",
    "  integer              :: j, k, l\n",
    "  integer              :: k_neighbour_under, k_neighbour_over\n",
    "  integer              :: l_neighbour_right, l_neighbour_left\n",
    "\n",
    "  del_He_sweep = 0\n",
    "  del_m_sweep = 0\n",
    "\n",
    "  S = S_initial\n",
    "\n",
    "  do j = 1,N_squared\n",
    "     l = rand_list_index2(j)\n",
    "     k = rand_list_index1(j)\n",
    "\n",
    "     ! Because of periodic boundary conditions nearest\n",
    "     ! neighbours indecies must be carefully examined.\n",
    "     ! If position (k, l) is on the bottom row:\n",
    "     if (k==N) then\n",
    "        k_neighbour_over = 1\n",
    "        k_neighbour_under = k - 1\n",
    "        ! If position (k, l) is on the top row:\n",
    "     elseif (k==1) then\n",
    "        k_neighbour_over = k + 1\n",
    "        k_neighbour_under = N\n",
    "     else\n",
    "        k_neighbour_over = k + 1\n",
    "        k_neighbour_under = k - 1\n",
    "     endif\n",
    "\n",
    "     ! If position (k, l) is on the righmost column:\n",
    "     if (l==N) then\n",
    "        l_neighbour_right = 1\n",
    "        l_neighbour_left = l - 1\n",
    "     ! If position (k, l) is on the leftmost column:\n",
    "     elseif (l==1) then\n",
    "        l_neighbour_right = l + 1\n",
    "        l_neighbour_left = N\n",
    "     else\n",
    "        l_neighbour_right = l + 1\n",
    "        l_neighbour_left = l - 1\n",
    "     endif\n",
    "\n",
    "     ! Calculating energy contribution from nearest neighbours\n",
    "     nn = J_v*(S(k_neighbour_under, l) + S(k_neighbour_over, l)) + J_p* &\n",
    "                      ( S(k, l_neighbour_right) + S(k, l_neighbour_left))\n",
    "     del_E = 2*S(k,l)*(nn + B)\n",
    "\n",
    "     if (del_E <= 0) then\n",
    "        check = .true.\n",
    "     else\n",
    "        check = (exp(-beta*del_E) > rand_numbers(j))\n",
    "     endif\n",
    "\n",
    "     if (check) then\n",
    "        del_m = -2*S(k,l)/ real(N**2)\n",
    "        S(k,l) = -1*S(k,l)\n",
    "\n",
    "     else\n",
    "        del_m = 0\n",
    "        del_E = 0\n",
    "     endif\n",
    "\n",
    "     del_He_sweep = del_He_sweep + del_E\n",
    "     del_m_sweep = del_m_sweep + del_m\n",
    "  enddo\n",
    "  return\n",
    "\n",
    "end subroutine random_sweep\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
